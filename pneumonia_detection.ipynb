{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (9.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.26.13)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MNIST Training using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using PyTorch.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-mnist\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16f2f26b-9b00-4409-8044-9c193055f637'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "metadata = json.load(open(\"/opt/ml/metadata/resource-metadata.json\",\"r\"))\n",
    "bucket = metadata[\"UserProfileName\"]\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16f2f26b-9b00-4409-8044-9c193055f637'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' change bucket to xray-mini for now'''\n",
    "bucket = \"xray-kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/NORMAL/IM-0001-0001.jpeg\n",
      "test/NORMAL/IM-0003-0001.jpeg\n",
      "test/NORMAL/IM-0005-0001.jpeg\n",
      "test/NORMAL/IM-0006-0001.jpeg\n",
      "test/NORMAL/IM-0007-0001.jpeg\n",
      "test/NORMAL/IM-0009-0001.jpeg\n",
      "test/NORMAL/IM-0010-0001.jpeg\n",
      "test/NORMAL/IM-0011-0001-0001.jpeg\n",
      "test/NORMAL/IM-0011-0001-0002.jpeg\n",
      "test/NORMAL/IM-0011-0001.jpeg\n",
      "test/NORMAL/IM-0013-0001.jpeg\n",
      "test/NORMAL/IM-0015-0001.jpeg\n",
      "test/NORMAL/IM-0016-0001.jpeg\n",
      "test/NORMAL/IM-0017-0001.jpeg\n",
      "test/NORMAL/IM-0019-0001.jpeg\n",
      "test/NORMAL/IM-0021-0001.jpeg\n",
      "test/NORMAL/IM-0022-0001.jpeg\n",
      "test/NORMAL/IM-0023-0001.jpeg\n",
      "test/NORMAL/IM-0025-0001.jpeg\n",
      "test/NORMAL/IM-0027-0001.jpeg\n",
      "test/NORMAL/IM-0028-0001.jpeg\n",
      "test/NORMAL/IM-0029-0001.jpeg\n",
      "test/NORMAL/IM-0030-0001.jpeg\n",
      "test/NORMAL/IM-0031-0001.jpeg\n",
      "test/NORMAL/IM-0033-0001-0001.jpeg\n",
      "test/NORMAL/IM-0033-0001-0002.jpeg\n",
      "test/NORMAL/IM-0033-0001.jpeg\n",
      "test/NORMAL/IM-0035-0001.jpeg\n",
      "test/NORMAL/IM-0036-0001.jpeg\n",
      "test/NORMAL/IM-0037-0001.jpeg\n",
      "test/NORMAL/IM-0039-0001.jpeg\n",
      "test/NORMAL/IM-0041-0001.jpeg\n",
      "test/NORMAL/IM-0043-0001.jpeg\n",
      "test/NORMAL/IM-0045-0001.jpeg\n",
      "test/NORMAL/IM-0046-0001.jpeg\n",
      "test/NORMAL/IM-0049-0001.jpeg\n",
      "test/NORMAL/IM-0050-0001.jpeg\n",
      "test/NORMAL/IM-0059-0001.jpeg\n",
      "test/NORMAL/IM-0061-0001.jpeg\n",
      "test/NORMAL/IM-0063-0001.jpeg\n",
      "test/NORMAL/IM-0065-0001.jpeg\n",
      "test/NORMAL/IM-0067-0001.jpeg\n",
      "test/NORMAL/IM-0069-0001.jpeg\n",
      "test/NORMAL/IM-0070-0001.jpeg\n",
      "test/NORMAL/IM-0071-0001.jpeg\n",
      "test/NORMAL/IM-0073-0001.jpeg\n",
      "test/NORMAL/IM-0075-0001.jpeg\n",
      "test/NORMAL/IM-0077-0001.jpeg\n",
      "test/NORMAL/IM-0079-0001.jpeg\n",
      "test/NORMAL/IM-0081-0001.jpeg\n",
      "test/NORMAL/IM-0083-0001.jpeg\n",
      "test/NORMAL/IM-0084-0001.jpeg\n",
      "test/NORMAL/IM-0085-0001.jpeg\n",
      "test/NORMAL/IM-0086-0001.jpeg\n",
      "test/NORMAL/IM-0087-0001.jpeg\n",
      "test/NORMAL/IM-0089-0001.jpeg\n",
      "test/NORMAL/IM-0091-0001.jpeg\n",
      "test/NORMAL/IM-0093-0001.jpeg\n",
      "test/NORMAL/IM-0095-0001.jpeg\n",
      "test/NORMAL/IM-0097-0001.jpeg\n",
      "test/NORMAL/IM-0099-0001.jpeg\n",
      "test/NORMAL/IM-0101-0001.jpeg\n",
      "test/NORMAL/IM-0102-0001.jpeg\n",
      "test/NORMAL/IM-0103-0001.jpeg\n",
      "test/NORMAL/IM-0105-0001.jpeg\n",
      "test/NORMAL/IM-0107-0001.jpeg\n",
      "test/NORMAL/IM-0109-0001.jpeg\n",
      "test/NORMAL/IM-0110-0001.jpeg\n",
      "test/NORMAL/IM-0111-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0007-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0012-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0013-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0019-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0023-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0027-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0028-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0029-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0030-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0033-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0035-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0041-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0045-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0051-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0052-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0058-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0059-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0060-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0066-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0072-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0073-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0079-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0081-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0086-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0092-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0095-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0096-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0098-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0102-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0105-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0107-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0110-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0111-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0112-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0117-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0120-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0123-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0129-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0130-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0131-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0132-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0135-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0139-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0141-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0145-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0146-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0150-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0171-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0173-0001-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0173-0001-0002.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0195-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0196-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0198-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0199-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0201-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0206-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0207-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0210-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0213-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0217-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0219-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0221-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0222-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0229-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0232-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0233-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0237-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0238-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0241-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0246-0001-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0246-0001-0002.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0246-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0249-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0251-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0252-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0256-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0259-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0267-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0271-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0272-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0273-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0274-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0275-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0276-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0277-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0278-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0279-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0280-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0281-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0282-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0283-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0285-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0286-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0287-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0288-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0289-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0290-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0292-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0294-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0297-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0300-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0301-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0302-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0303-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0304-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0305-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0307-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0309-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0310-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0311-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0312-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0313-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0315-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0316-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0317-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0319-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0321-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0322-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0323-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0325-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0326-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0327-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0328-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0329-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0330-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0331-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0332-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0333-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0335-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0336-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0337-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0338-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0339-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0340-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0341-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0343-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0345-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0346-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0347-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0348-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0349-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0350-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0351-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0352-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0353-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0354-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0357-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0359-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0360-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0361-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0362-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0364-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0366-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0368-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0369-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0370-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0372-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0373-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0374-0001-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0374-0001-0002.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0374-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0376-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0378-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0380-0001.jpeg\n",
      "test/NORMAL/NORMAL2-IM-0381-0001.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_475.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_477.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_478.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_479.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_480.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_481.jpeg\n",
      "test/PNEUMONIA/person100_bacteria_482.jpeg\n",
      "test/PNEUMONIA/person101_bacteria_483.jpeg\n",
      "test/PNEUMONIA/person101_bacteria_484.jpeg\n",
      "test/PNEUMONIA/person101_bacteria_485.jpeg\n",
      "test/PNEUMONIA/person101_bacteria_486.jpeg\n",
      "test/PNEUMONIA/person102_bacteria_487.jpeg\n",
      "test/PNEUMONIA/person103_bacteria_488.jpeg\n",
      "test/PNEUMONIA/person103_bacteria_489.jpeg\n",
      "test/PNEUMONIA/person103_bacteria_490.jpeg\n",
      "test/PNEUMONIA/person104_bacteria_491.jpeg\n",
      "test/PNEUMONIA/person104_bacteria_492.jpeg\n",
      "test/PNEUMONIA/person108_bacteria_504.jpeg\n",
      "test/PNEUMONIA/person108_bacteria_506.jpeg\n",
      "test/PNEUMONIA/person108_bacteria_507.jpeg\n",
      "test/PNEUMONIA/person108_bacteria_511.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_512.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_513.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_517.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_519.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_522.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_523.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_526.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_527.jpeg\n",
      "test/PNEUMONIA/person109_bacteria_528.jpeg\n",
      "test/PNEUMONIA/person10_virus_35.jpeg\n",
      "test/PNEUMONIA/person110_bacteria_531.jpeg\n",
      "test/PNEUMONIA/person111_bacteria_533.jpeg\n",
      "test/PNEUMONIA/person111_bacteria_534.jpeg\n",
      "test/PNEUMONIA/person111_bacteria_535.jpeg\n",
      "test/PNEUMONIA/person111_bacteria_536.jpeg\n",
      "test/PNEUMONIA/person111_bacteria_537.jpeg\n",
      "test/PNEUMONIA/person112_bacteria_538.jpeg\n",
      "test/PNEUMONIA/person112_bacteria_539.jpeg\n",
      "test/PNEUMONIA/person113_bacteria_540.jpeg\n",
      "test/PNEUMONIA/person113_bacteria_541.jpeg\n",
      "test/PNEUMONIA/person113_bacteria_542.jpeg\n",
      "test/PNEUMONIA/person113_bacteria_543.jpeg\n",
      "test/PNEUMONIA/person114_bacteria_544.jpeg\n",
      "test/PNEUMONIA/person114_bacteria_545.jpeg\n",
      "test/PNEUMONIA/person114_bacteria_546.jpeg\n",
      "test/PNEUMONIA/person117_bacteria_553.jpeg\n",
      "test/PNEUMONIA/person117_bacteria_556.jpeg\n",
      "test/PNEUMONIA/person117_bacteria_557.jpeg\n",
      "test/PNEUMONIA/person118_bacteria_559.jpeg\n",
      "test/PNEUMONIA/person118_bacteria_560.jpeg\n",
      "test/PNEUMONIA/person119_bacteria_565.jpeg\n",
      "test/PNEUMONIA/person119_bacteria_566.jpeg\n",
      "test/PNEUMONIA/person119_bacteria_567.jpeg\n",
      "test/PNEUMONIA/person119_bacteria_568.jpeg\n",
      "test/PNEUMONIA/person11_virus_38.jpeg\n",
      "test/PNEUMONIA/person120_bacteria_570.jpeg\n",
      "test/PNEUMONIA/person120_bacteria_571.jpeg\n",
      "test/PNEUMONIA/person120_bacteria_572.jpeg\n",
      "test/PNEUMONIA/person120_bacteria_573.jpeg\n",
      "test/PNEUMONIA/person121_bacteria_575.jpeg\n",
      "test/PNEUMONIA/person121_bacteria_576.jpeg\n",
      "test/PNEUMONIA/person121_bacteria_578.jpeg\n",
      "test/PNEUMONIA/person121_bacteria_579.jpeg\n",
      "test/PNEUMONIA/person121_bacteria_580.jpeg\n",
      "test/PNEUMONIA/person122_bacteria_581.jpeg\n",
      "test/PNEUMONIA/person122_bacteria_582.jpeg\n",
      "test/PNEUMONIA/person122_bacteria_583.jpeg\n",
      "test/PNEUMONIA/person122_bacteria_584.jpeg\n",
      "test/PNEUMONIA/person122_bacteria_585.jpeg\n",
      "test/PNEUMONIA/person122_bacteria_586.jpeg\n",
      "test/PNEUMONIA/person123_bacteria_587.jpeg\n",
      "test/PNEUMONIA/person124_bacteria_589.jpeg\n",
      "test/PNEUMONIA/person124_bacteria_590.jpeg\n",
      "test/PNEUMONIA/person124_bacteria_591.jpeg\n",
      "test/PNEUMONIA/person124_bacteria_592.jpeg\n",
      "test/PNEUMONIA/person125_bacteria_594.jpeg\n",
      "test/PNEUMONIA/person125_bacteria_595.jpeg\n",
      "test/PNEUMONIA/person126_bacteria_598.jpeg\n",
      "test/PNEUMONIA/person126_bacteria_599.jpeg\n",
      "test/PNEUMONIA/person126_bacteria_600.jpeg\n",
      "test/PNEUMONIA/person127_bacteria_602.jpeg\n",
      "test/PNEUMONIA/person127_bacteria_603.jpeg\n",
      "test/PNEUMONIA/person127_bacteria_604.jpeg\n",
      "test/PNEUMONIA/person128_bacteria_605.jpeg\n",
      "test/PNEUMONIA/person128_bacteria_606.jpeg\n",
      "test/PNEUMONIA/person128_bacteria_607.jpeg\n",
      "test/PNEUMONIA/person128_bacteria_608.jpeg\n",
      "test/PNEUMONIA/person130_bacteria_623.jpeg\n",
      "test/PNEUMONIA/person130_bacteria_625.jpeg\n",
      "test/PNEUMONIA/person130_bacteria_626.jpeg\n",
      "test/PNEUMONIA/person130_bacteria_627.jpeg\n",
      "test/PNEUMONIA/person130_bacteria_628.jpeg\n",
      "test/PNEUMONIA/person131_bacteria_629.jpeg\n",
      "test/PNEUMONIA/person132_bacteria_632.jpeg\n",
      "test/PNEUMONIA/person133_bacteria_633.jpeg\n",
      "test/PNEUMONIA/person133_bacteria_634.jpeg\n",
      "test/PNEUMONIA/person133_bacteria_635.jpeg\n",
      "test/PNEUMONIA/person133_bacteria_637.jpeg\n",
      "test/PNEUMONIA/person133_bacteria_638.jpeg\n",
      "test/PNEUMONIA/person134_bacteria_640.jpeg\n",
      "test/PNEUMONIA/person134_bacteria_641.jpeg\n",
      "test/PNEUMONIA/person134_bacteria_642.jpeg\n",
      "test/PNEUMONIA/person134_bacteria_643.jpeg\n",
      "test/PNEUMONIA/person134_bacteria_644.jpeg\n",
      "test/PNEUMONIA/person135_bacteria_646.jpeg\n",
      "test/PNEUMONIA/person135_bacteria_647.jpeg\n",
      "test/PNEUMONIA/person136_bacteria_648.jpeg\n",
      "test/PNEUMONIA/person136_bacteria_649.jpeg\n",
      "test/PNEUMONIA/person136_bacteria_650.jpeg\n",
      "test/PNEUMONIA/person136_bacteria_652.jpeg\n",
      "test/PNEUMONIA/person136_bacteria_654.jpeg\n",
      "test/PNEUMONIA/person137_bacteria_655.jpeg\n",
      "test/PNEUMONIA/person138_bacteria_657.jpeg\n",
      "test/PNEUMONIA/person138_bacteria_658.jpeg\n",
      "test/PNEUMONIA/person138_bacteria_659.jpeg\n",
      "test/PNEUMONIA/person139_bacteria_661.jpeg\n",
      "test/PNEUMONIA/person139_bacteria_662.jpeg\n",
      "test/PNEUMONIA/person139_bacteria_663.jpeg\n",
      "test/PNEUMONIA/person139_bacteria_664.jpeg\n",
      "test/PNEUMONIA/person139_bacteria_665.jpeg\n",
      "test/PNEUMONIA/person139_bacteria_666.jpeg\n",
      "test/PNEUMONIA/person140_bacteria_667.jpeg\n",
      "test/PNEUMONIA/person140_bacteria_668.jpeg\n",
      "test/PNEUMONIA/person141_bacteria_670.jpeg\n",
      "test/PNEUMONIA/person141_bacteria_676.jpeg\n",
      "test/PNEUMONIA/person141_bacteria_677.jpeg\n",
      "test/PNEUMONIA/person141_bacteria_678.jpeg\n",
      "test/PNEUMONIA/person141_bacteria_681.jpeg\n",
      "test/PNEUMONIA/person142_bacteria_682.jpeg\n",
      "test/PNEUMONIA/person142_bacteria_683.jpeg\n",
      "test/PNEUMONIA/person142_bacteria_684.jpeg\n",
      "test/PNEUMONIA/person143_bacteria_687.jpeg\n",
      "test/PNEUMONIA/person143_bacteria_688.jpeg\n",
      "test/PNEUMONIA/person143_bacteria_689.jpeg\n",
      "test/PNEUMONIA/person144_bacteria_690.jpeg\n",
      "test/PNEUMONIA/person145_bacteria_696.jpeg\n",
      "test/PNEUMONIA/person146_bacteria_700.jpeg\n",
      "test/PNEUMONIA/person146_bacteria_703.jpeg\n",
      "test/PNEUMONIA/person146_bacteria_704.jpeg\n",
      "test/PNEUMONIA/person147_bacteria_705.jpeg\n",
      "test/PNEUMONIA/person147_bacteria_706.jpeg\n",
      "test/PNEUMONIA/person147_bacteria_707.jpeg\n",
      "test/PNEUMONIA/person147_bacteria_711.jpeg\n",
      "test/PNEUMONIA/person149_bacteria_713.jpeg\n",
      "test/PNEUMONIA/person14_virus_44.jpeg\n",
      "test/PNEUMONIA/person150_bacteria_715.jpeg\n",
      "test/PNEUMONIA/person150_bacteria_716.jpeg\n",
      "test/PNEUMONIA/person150_bacteria_717.jpeg\n",
      "test/PNEUMONIA/person151_bacteria_718.jpeg\n",
      "test/PNEUMONIA/person152_bacteria_720.jpeg\n",
      "test/PNEUMONIA/person152_bacteria_721.jpeg\n",
      "test/PNEUMONIA/person152_bacteria_722.jpeg\n",
      "test/PNEUMONIA/person152_bacteria_723.jpeg\n",
      "test/PNEUMONIA/person152_bacteria_724.jpeg\n",
      "test/PNEUMONIA/person153_bacteria_725.jpeg\n",
      "test/PNEUMONIA/person153_bacteria_726.jpeg\n",
      "test/PNEUMONIA/person154_bacteria_728.jpeg\n",
      "test/PNEUMONIA/person155_bacteria_729.jpeg\n",
      "test/PNEUMONIA/person155_bacteria_730.jpeg\n",
      "test/PNEUMONIA/person155_bacteria_731.jpeg\n",
      "test/PNEUMONIA/person157_bacteria_735.jpeg\n",
      "test/PNEUMONIA/person157_bacteria_739.jpeg\n",
      "test/PNEUMONIA/person157_bacteria_740.jpeg\n",
      "test/PNEUMONIA/person158_bacteria_742.jpeg\n",
      "test/PNEUMONIA/person158_bacteria_743.jpeg\n",
      "test/PNEUMONIA/person158_bacteria_744.jpeg\n",
      "test/PNEUMONIA/person158_bacteria_745.jpeg\n",
      "test/PNEUMONIA/person159_bacteria_746.jpeg\n",
      "test/PNEUMONIA/person159_bacteria_747.jpeg\n",
      "test/PNEUMONIA/person15_virus_46.jpeg\n",
      "test/PNEUMONIA/person1608_virus_2786.jpeg\n",
      "test/PNEUMONIA/person1610_virus_2793.jpeg\n",
      "test/PNEUMONIA/person1612_virus_2797.jpeg\n",
      "test/PNEUMONIA/person1612_virus_2798.jpeg\n",
      "test/PNEUMONIA/person1613_virus_2799.jpeg\n",
      "test/PNEUMONIA/person1614_virus_2800.jpeg\n",
      "test/PNEUMONIA/person1615_virus_2801.jpeg\n",
      "test/PNEUMONIA/person1616_virus_2802.jpeg\n",
      "test/PNEUMONIA/person1618_virus_2805.jpeg\n",
      "test/PNEUMONIA/person1619_virus_2806.jpeg\n",
      "test/PNEUMONIA/person161_bacteria_757.jpeg\n",
      "test/PNEUMONIA/person161_bacteria_759.jpeg\n",
      "test/PNEUMONIA/person161_bacteria_762.jpeg\n",
      "test/PNEUMONIA/person1620_virus_2807.jpeg\n",
      "test/PNEUMONIA/person1622_virus_2810.jpeg\n",
      "test/PNEUMONIA/person1623_virus_2813.jpeg\n",
      "test/PNEUMONIA/person1625_virus_2817.jpeg\n",
      "test/PNEUMONIA/person1626_virus_2818.jpeg\n",
      "test/PNEUMONIA/person1627_virus_2819.jpeg\n",
      "test/PNEUMONIA/person1628_virus_2821.jpeg\n",
      "test/PNEUMONIA/person1628_virus_2822.jpeg\n",
      "test/PNEUMONIA/person1629_virus_2823.jpeg\n",
      "test/PNEUMONIA/person1631_virus_2826.jpeg\n",
      "test/PNEUMONIA/person1632_virus_2827.jpeg\n",
      "test/PNEUMONIA/person1633_virus_2829.jpeg\n",
      "test/PNEUMONIA/person1634_virus_2830.jpeg\n",
      "test/PNEUMONIA/person1635_virus_2831.jpeg\n",
      "test/PNEUMONIA/person1637_virus_2834.jpeg\n",
      "test/PNEUMONIA/person1640_virus_2839.jpeg\n",
      "test/PNEUMONIA/person1641_virus_2840.jpeg\n",
      "test/PNEUMONIA/person1642_virus_2842.jpeg\n",
      "test/PNEUMONIA/person1643_virus_2843.jpeg\n",
      "test/PNEUMONIA/person1644_virus_2844.jpeg\n",
      "test/PNEUMONIA/person1645_virus_2845.jpeg\n",
      "test/PNEUMONIA/person1647_virus_2848.jpeg\n",
      "test/PNEUMONIA/person1649_virus_2850.jpeg\n",
      "test/PNEUMONIA/person1650_virus_2852.jpeg\n",
      "test/PNEUMONIA/person1650_virus_2854.jpeg\n",
      "test/PNEUMONIA/person1651_virus_2855.jpeg\n",
      "test/PNEUMONIA/person1653_virus_2858.jpeg\n",
      "test/PNEUMONIA/person1653_virus_2859.jpeg\n",
      "test/PNEUMONIA/person1655_virus_2861.jpeg\n",
      "test/PNEUMONIA/person1656_virus_2862.jpeg\n",
      "test/PNEUMONIA/person1657_virus_2864.jpeg\n",
      "test/PNEUMONIA/person1659_virus_2867.jpeg\n",
      "test/PNEUMONIA/person1660_virus_2869.jpeg\n",
      "test/PNEUMONIA/person1661_virus_2872.jpeg\n",
      "test/PNEUMONIA/person1661_virus_2873.jpeg\n",
      "test/PNEUMONIA/person1662_virus_2875.jpeg\n",
      "test/PNEUMONIA/person1663_virus_2876.jpeg\n",
      "test/PNEUMONIA/person1664_virus_2877.jpeg\n",
      "test/PNEUMONIA/person1665_virus_2878.jpeg\n",
      "test/PNEUMONIA/person1667_virus_2881.jpeg\n",
      "test/PNEUMONIA/person1668_virus_2882.jpeg\n",
      "test/PNEUMONIA/person1669_virus_2884.jpeg\n",
      "test/PNEUMONIA/person1669_virus_2885.jpeg\n",
      "test/PNEUMONIA/person1670_virus_2886.jpeg\n",
      "test/PNEUMONIA/person1671_virus_2887.jpeg\n",
      "test/PNEUMONIA/person1672_virus_2888.jpeg\n",
      "test/PNEUMONIA/person1673_virus_2889.jpeg\n",
      "test/PNEUMONIA/person1674_virus_2890.jpeg\n",
      "test/PNEUMONIA/person1675_virus_2891.jpeg\n",
      "test/PNEUMONIA/person1676_virus_2892.jpeg\n",
      "test/PNEUMONIA/person1678_virus_2895.jpeg\n",
      "test/PNEUMONIA/person1679_virus_2896.jpeg\n",
      "test/PNEUMONIA/person1680_virus_2897.jpeg\n",
      "test/PNEUMONIA/person1682_virus_2899.jpeg\n",
      "test/PNEUMONIA/person1685_virus_2903.jpeg\n",
      "test/PNEUMONIA/person16_virus_47.jpeg\n",
      "test/PNEUMONIA/person171_bacteria_826.jpeg\n",
      "test/PNEUMONIA/person172_bacteria_827.jpeg\n",
      "test/PNEUMONIA/person172_bacteria_828.jpeg\n",
      "test/PNEUMONIA/person173_bacteria_829.jpeg\n",
      "test/PNEUMONIA/person173_bacteria_830.jpeg\n",
      "test/PNEUMONIA/person173_bacteria_831.jpeg\n",
      "test/PNEUMONIA/person174_bacteria_832.jpeg\n",
      "test/PNEUMONIA/person175_bacteria_833.jpeg\n",
      "test/PNEUMONIA/person175_bacteria_834.jpeg\n",
      "test/PNEUMONIA/person175_bacteria_835.jpeg\n",
      "test/PNEUMONIA/person17_virus_48.jpeg\n",
      "test/PNEUMONIA/person18_virus_49.jpeg\n",
      "test/PNEUMONIA/person19_virus_50.jpeg\n",
      "test/PNEUMONIA/person1_virus_11.jpeg\n",
      "test/PNEUMONIA/person1_virus_12.jpeg\n",
      "test/PNEUMONIA/person1_virus_13.jpeg\n",
      "test/PNEUMONIA/person1_virus_6.jpeg\n",
      "test/PNEUMONIA/person1_virus_7.jpeg\n",
      "test/PNEUMONIA/person1_virus_8.jpeg\n",
      "test/PNEUMONIA/person1_virus_9.jpeg\n",
      "test/PNEUMONIA/person20_virus_51.jpeg\n",
      "test/PNEUMONIA/person21_virus_52.jpeg\n",
      "test/PNEUMONIA/person21_virus_53.jpeg\n",
      "test/PNEUMONIA/person22_virus_54.jpeg\n",
      "test/PNEUMONIA/person22_virus_55.jpeg\n",
      "test/PNEUMONIA/person23_virus_56.jpeg\n",
      "test/PNEUMONIA/person24_virus_58.jpeg\n",
      "test/PNEUMONIA/person25_virus_59.jpeg\n",
      "test/PNEUMONIA/person26_virus_60.jpeg\n",
      "test/PNEUMONIA/person28_virus_62.jpeg\n",
      "test/PNEUMONIA/person28_virus_63.jpeg\n",
      "test/PNEUMONIA/person29_virus_64.jpeg\n",
      "test/PNEUMONIA/person30_virus_69.jpeg\n",
      "test/PNEUMONIA/person31_virus_70.jpeg\n",
      "test/PNEUMONIA/person32_virus_71.jpeg\n",
      "test/PNEUMONIA/person33_virus_72.jpeg\n",
      "test/PNEUMONIA/person34_virus_76.jpeg\n",
      "test/PNEUMONIA/person35_virus_80.jpeg\n",
      "test/PNEUMONIA/person36_virus_81.jpeg\n",
      "test/PNEUMONIA/person37_virus_82.jpeg\n",
      "test/PNEUMONIA/person38_virus_83.jpeg\n",
      "test/PNEUMONIA/person38_virus_84.jpeg\n",
      "test/PNEUMONIA/person39_virus_85.jpeg\n",
      "test/PNEUMONIA/person3_virus_15.jpeg\n",
      "test/PNEUMONIA/person3_virus_16.jpeg\n",
      "test/PNEUMONIA/person3_virus_17.jpeg\n",
      "test/PNEUMONIA/person40_virus_87.jpeg\n",
      "test/PNEUMONIA/person41_virus_88.jpeg\n",
      "test/PNEUMONIA/person42_virus_89.jpeg\n",
      "test/PNEUMONIA/person43_virus_92.jpeg\n",
      "test/PNEUMONIA/person44_virus_93.jpeg\n",
      "test/PNEUMONIA/person44_virus_94.jpeg\n",
      "test/PNEUMONIA/person45_virus_95.jpeg\n",
      "test/PNEUMONIA/person46_virus_96.jpeg\n",
      "test/PNEUMONIA/person47_virus_99.jpeg\n",
      "test/PNEUMONIA/person48_virus_100.jpeg\n",
      "test/PNEUMONIA/person49_virus_101.jpeg\n",
      "test/PNEUMONIA/person50_virus_102.jpeg\n",
      "test/PNEUMONIA/person51_virus_105.jpeg\n",
      "test/PNEUMONIA/person52_virus_106.jpeg\n",
      "test/PNEUMONIA/person53_virus_107.jpeg\n",
      "test/PNEUMONIA/person53_virus_108.jpeg\n",
      "test/PNEUMONIA/person54_virus_109.jpeg\n",
      "test/PNEUMONIA/person55_virus_110.jpeg\n",
      "test/PNEUMONIA/person56_virus_112.jpeg\n",
      "test/PNEUMONIA/person57_virus_113.jpeg\n",
      "test/PNEUMONIA/person59_virus_116.jpeg\n",
      "test/PNEUMONIA/person60_virus_117.jpeg\n",
      "test/PNEUMONIA/person61_virus_118.jpeg\n",
      "test/PNEUMONIA/person62_virus_119.jpeg\n",
      "test/PNEUMONIA/person63_virus_121.jpeg\n",
      "test/PNEUMONIA/person64_virus_122.jpeg\n",
      "test/PNEUMONIA/person65_virus_123.jpeg\n",
      "test/PNEUMONIA/person66_virus_125.jpeg\n",
      "test/PNEUMONIA/person67_virus_126.jpeg\n",
      "test/PNEUMONIA/person69_virus_129.jpeg\n",
      "test/PNEUMONIA/person70_virus_130.jpeg\n",
      "test/PNEUMONIA/person71_virus_131.jpeg\n",
      "test/PNEUMONIA/person71_virus_132.jpeg\n",
      "test/PNEUMONIA/person72_virus_133.jpeg\n",
      "test/PNEUMONIA/person74_virus_135.jpeg\n",
      "test/PNEUMONIA/person75_virus_136.jpeg\n",
      "test/PNEUMONIA/person76_virus_138.jpeg\n",
      "test/PNEUMONIA/person77_virus_139.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_378.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_380.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_381.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_382.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_384.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_385.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_386.jpeg\n",
      "test/PNEUMONIA/person78_bacteria_387.jpeg\n",
      "test/PNEUMONIA/person78_virus_140.jpeg\n",
      "test/PNEUMONIA/person79_virus_148.jpeg\n",
      "test/PNEUMONIA/person80_bacteria_389.jpeg\n",
      "test/PNEUMONIA/person80_bacteria_390.jpeg\n",
      "test/PNEUMONIA/person80_bacteria_391.jpeg\n",
      "test/PNEUMONIA/person80_bacteria_392.jpeg\n",
      "test/PNEUMONIA/person80_bacteria_393.jpeg\n",
      "test/PNEUMONIA/person81_bacteria_395.jpeg\n",
      "test/PNEUMONIA/person81_bacteria_396.jpeg\n",
      "test/PNEUMONIA/person81_bacteria_397.jpeg\n",
      "test/PNEUMONIA/person81_bacteria_398.jpeg\n",
      "test/PNEUMONIA/person82_bacteria_402.jpeg\n",
      "test/PNEUMONIA/person82_bacteria_403.jpeg\n",
      "test/PNEUMONIA/person82_bacteria_404.jpeg\n",
      "test/PNEUMONIA/person82_bacteria_405.jpeg\n",
      "test/PNEUMONIA/person83_bacteria_407.jpeg\n",
      "test/PNEUMONIA/person83_bacteria_409.jpeg\n",
      "test/PNEUMONIA/person83_bacteria_410.jpeg\n",
      "test/PNEUMONIA/person83_bacteria_411.jpeg\n",
      "test/PNEUMONIA/person83_bacteria_412.jpeg\n",
      "test/PNEUMONIA/person83_bacteria_414.jpeg\n",
      "test/PNEUMONIA/person85_bacteria_417.jpeg\n",
      "test/PNEUMONIA/person85_bacteria_419.jpeg\n",
      "test/PNEUMONIA/person85_bacteria_421.jpeg\n",
      "test/PNEUMONIA/person85_bacteria_422.jpeg\n",
      "test/PNEUMONIA/person85_bacteria_423.jpeg\n",
      "test/PNEUMONIA/person85_bacteria_424.jpeg\n",
      "test/PNEUMONIA/person86_bacteria_428.jpeg\n",
      "test/PNEUMONIA/person86_bacteria_429.jpeg\n",
      "test/PNEUMONIA/person87_bacteria_433.jpeg\n",
      "test/PNEUMONIA/person87_bacteria_434.jpeg\n",
      "test/PNEUMONIA/person88_bacteria_437.jpeg\n",
      "test/PNEUMONIA/person88_bacteria_438.jpeg\n",
      "test/PNEUMONIA/person88_bacteria_439.jpeg\n",
      "test/PNEUMONIA/person89_bacteria_440.jpeg\n",
      "test/PNEUMONIA/person8_virus_27.jpeg\n",
      "test/PNEUMONIA/person8_virus_28.jpeg\n",
      "test/PNEUMONIA/person90_bacteria_442.jpeg\n",
      "test/PNEUMONIA/person90_bacteria_443.jpeg\n",
      "test/PNEUMONIA/person91_bacteria_445.jpeg\n",
      "test/PNEUMONIA/person91_bacteria_446.jpeg\n",
      "test/PNEUMONIA/person91_bacteria_447.jpeg\n",
      "test/PNEUMONIA/person91_bacteria_448.jpeg\n",
      "test/PNEUMONIA/person91_bacteria_449.jpeg\n",
      "test/PNEUMONIA/person92_bacteria_450.jpeg\n",
      "test/PNEUMONIA/person92_bacteria_451.jpeg\n",
      "test/PNEUMONIA/person93_bacteria_453.jpeg\n",
      "test/PNEUMONIA/person93_bacteria_454.jpeg\n",
      "test/PNEUMONIA/person94_bacteria_456.jpeg\n",
      "test/PNEUMONIA/person94_bacteria_457.jpeg\n",
      "test/PNEUMONIA/person94_bacteria_458.jpeg\n",
      "test/PNEUMONIA/person95_bacteria_463.jpeg\n",
      "test/PNEUMONIA/person96_bacteria_464.jpeg\n",
      "test/PNEUMONIA/person96_bacteria_465.jpeg\n",
      "test/PNEUMONIA/person96_bacteria_466.jpeg\n",
      "test/PNEUMONIA/person97_bacteria_468.jpeg\n",
      "test/PNEUMONIA/person99_bacteria_473.jpeg\n",
      "test/PNEUMONIA/person99_bacteria_474.jpeg\n",
      "train/NORMAL/IM-0115-0001.jpeg\n",
      "train/NORMAL/IM-0117-0001.jpeg\n",
      "train/NORMAL/IM-0119-0001.jpeg\n",
      "train/NORMAL/IM-0122-0001.jpeg\n",
      "train/NORMAL/IM-0125-0001.jpeg\n",
      "train/NORMAL/IM-0127-0001.jpeg\n",
      "train/NORMAL/IM-0128-0001.jpeg\n",
      "train/NORMAL/IM-0129-0001.jpeg\n",
      "train/NORMAL/IM-0131-0001.jpeg\n",
      "train/NORMAL/IM-0133-0001.jpeg\n",
      "train/NORMAL/IM-0135-0001.jpeg\n",
      "train/NORMAL/IM-0137-0001.jpeg\n",
      "train/NORMAL/IM-0140-0001.jpeg\n",
      "train/NORMAL/IM-0141-0001.jpeg\n",
      "train/NORMAL/IM-0143-0001.jpeg\n",
      "train/NORMAL/IM-0145-0001.jpeg\n",
      "train/NORMAL/IM-0147-0001.jpeg\n",
      "train/NORMAL/IM-0149-0001.jpeg\n",
      "train/NORMAL/IM-0151-0001.jpeg\n",
      "train/NORMAL/IM-0152-0001.jpeg\n",
      "train/NORMAL/IM-0154-0001.jpeg\n",
      "train/NORMAL/IM-0156-0001.jpeg\n",
      "train/NORMAL/IM-0158-0001.jpeg\n",
      "train/NORMAL/IM-0160-0001.jpeg\n",
      "train/NORMAL/IM-0162-0001.jpeg\n",
      "train/NORMAL/IM-0164-0001.jpeg\n",
      "train/NORMAL/IM-0166-0001.jpeg\n",
      "train/NORMAL/IM-0168-0001.jpeg\n",
      "train/NORMAL/IM-0170-0001.jpeg\n",
      "train/NORMAL/IM-0172-0001.jpeg\n",
      "train/NORMAL/IM-0176-0001.jpeg\n",
      "train/NORMAL/IM-0177-0001.jpeg\n",
      "train/NORMAL/IM-0178-0001.jpeg\n",
      "train/NORMAL/IM-0180-0001.jpeg\n",
      "train/NORMAL/IM-0182-0001.jpeg\n",
      "train/NORMAL/IM-0183-0001.jpeg\n",
      "train/NORMAL/IM-0185-0001.jpeg\n",
      "train/NORMAL/IM-0187-0001.jpeg\n",
      "train/NORMAL/IM-0189-0001.jpeg\n",
      "train/NORMAL/IM-0191-0001.jpeg\n",
      "train/NORMAL/IM-0193-0001.jpeg\n",
      "train/NORMAL/IM-0195-0001.jpeg\n",
      "train/NORMAL/IM-0199-0001.jpeg\n",
      "train/NORMAL/IM-0201-0001.jpeg\n",
      "train/NORMAL/IM-0203-0001.jpeg\n",
      "train/NORMAL/IM-0205-0001.jpeg\n",
      "train/NORMAL/IM-0206-0001.jpeg\n",
      "train/NORMAL/IM-0207-0001.jpeg\n",
      "train/NORMAL/IM-0209-0001.jpeg\n",
      "train/NORMAL/IM-0210-0001.jpeg\n",
      "train/NORMAL/IM-0211-0001.jpeg\n",
      "train/NORMAL/IM-0213-0001.jpeg\n",
      "train/NORMAL/IM-0214-0001.jpeg\n",
      "train/NORMAL/IM-0215-0001.jpeg\n",
      "train/NORMAL/IM-0216-0001.jpeg\n",
      "train/NORMAL/IM-0217-0001.jpeg\n",
      "train/NORMAL/IM-0218-0001.jpeg\n",
      "train/NORMAL/IM-0219-0001.jpeg\n",
      "train/NORMAL/IM-0220-0001.jpeg\n",
      "train/NORMAL/IM-0221-0001.jpeg\n",
      "train/NORMAL/IM-0222-0001.jpeg\n",
      "train/NORMAL/IM-0223-0001.jpeg\n",
      "train/NORMAL/IM-0224-0001.jpeg\n",
      "train/NORMAL/IM-0225-0001.jpeg\n",
      "train/NORMAL/IM-0226-0001.jpeg\n",
      "train/NORMAL/IM-0227-0001.jpeg\n",
      "train/NORMAL/IM-0228-0001.jpeg\n",
      "train/NORMAL/IM-0229-0001.jpeg\n",
      "train/NORMAL/IM-0230-0001.jpeg\n",
      "train/NORMAL/IM-0231-0001.jpeg\n",
      "train/NORMAL/IM-0234-0001.jpeg\n",
      "train/NORMAL/IM-0235-0001.jpeg\n",
      "train/NORMAL/IM-0236-0001.jpeg\n",
      "train/NORMAL/IM-0237-0001.jpeg\n",
      "train/NORMAL/IM-0238-0001.jpeg\n",
      "train/NORMAL/IM-0239-0001.jpeg\n",
      "train/NORMAL/IM-0240-0001.jpeg\n",
      "train/NORMAL/IM-0241-0001.jpeg\n",
      "train/NORMAL/IM-0242-0001.jpeg\n",
      "train/NORMAL/IM-0243-0001.jpeg\n",
      "train/NORMAL/IM-0244-0001.jpeg\n",
      "train/NORMAL/IM-0245-0001.jpeg\n",
      "train/NORMAL/IM-0248-0001.jpeg\n",
      "train/NORMAL/IM-0249-0001.jpeg\n",
      "train/NORMAL/IM-0250-0001.jpeg\n",
      "train/NORMAL/IM-0251-0001.jpeg\n",
      "train/NORMAL/IM-0253-0001.jpeg\n",
      "train/NORMAL/IM-0255-0001.jpeg\n",
      "train/NORMAL/IM-0256-0001.jpeg\n",
      "train/NORMAL/IM-0257-0001.jpeg\n",
      "train/NORMAL/IM-0261-0001.jpeg\n",
      "train/NORMAL/IM-0262-0001.jpeg\n",
      "train/NORMAL/IM-0264-0001.jpeg\n",
      "train/NORMAL/IM-0265-0001.jpeg\n",
      "train/NORMAL/IM-0266-0001.jpeg\n",
      "train/NORMAL/IM-0268-0001.jpeg\n",
      "train/NORMAL/IM-0269-0001.jpeg\n",
      "train/NORMAL/IM-0270-0001.jpeg\n",
      "train/NORMAL/IM-0272-0001.jpeg\n",
      "train/NORMAL/IM-0273-0001.jpeg\n",
      "train/NORMAL/IM-0274-0001.jpeg\n",
      "train/NORMAL/IM-0275-0001.jpeg\n",
      "train/NORMAL/IM-0276-0001.jpeg\n",
      "train/NORMAL/IM-0277-0001.jpeg\n",
      "train/NORMAL/IM-0278-0001.jpeg\n",
      "train/NORMAL/IM-0279-0001.jpeg\n",
      "train/NORMAL/IM-0280-0001.jpeg\n",
      "train/NORMAL/IM-0282-0001.jpeg\n",
      "train/NORMAL/IM-0283-0001.jpeg\n",
      "train/NORMAL/IM-0285-0001.jpeg\n",
      "train/NORMAL/IM-0286-0001.jpeg\n",
      "train/NORMAL/IM-0288-0001.jpeg\n",
      "train/NORMAL/IM-0289-0001.jpeg\n",
      "train/NORMAL/IM-0290-0001.jpeg\n",
      "train/NORMAL/IM-0291-0001.jpeg\n",
      "train/NORMAL/IM-0292-0001.jpeg\n",
      "train/NORMAL/IM-0293-0001.jpeg\n",
      "train/NORMAL/IM-0294-0001.jpeg\n",
      "train/NORMAL/IM-0295-0001.jpeg\n",
      "train/NORMAL/IM-0297-0001.jpeg\n",
      "train/NORMAL/IM-0298-0001.jpeg\n",
      "train/NORMAL/IM-0299-0001.jpeg\n",
      "train/NORMAL/IM-0300-0001.jpeg\n",
      "train/NORMAL/IM-0301-0001.jpeg\n",
      "train/NORMAL/IM-0302-0001.jpeg\n",
      "train/NORMAL/IM-0303-0001.jpeg\n",
      "train/NORMAL/IM-0304-0001.jpeg\n",
      "train/NORMAL/IM-0305-0001.jpeg\n",
      "train/NORMAL/IM-0306-0001.jpeg\n",
      "train/NORMAL/IM-0307-0001.jpeg\n",
      "train/NORMAL/IM-0308-0001.jpeg\n",
      "train/NORMAL/IM-0309-0001.jpeg\n",
      "train/NORMAL/IM-0311-0001.jpeg\n",
      "train/NORMAL/IM-0312-0001.jpeg\n",
      "train/NORMAL/IM-0313-0001.jpeg\n",
      "train/NORMAL/IM-0314-0001.jpeg\n",
      "train/NORMAL/IM-0315-0001.jpeg\n",
      "train/NORMAL/IM-0316-0001.jpeg\n",
      "train/NORMAL/IM-0317-0001.jpeg\n",
      "train/NORMAL/IM-0318-0001.jpeg\n",
      "train/NORMAL/IM-0319-0001.jpeg\n",
      "train/NORMAL/IM-0320-0001.jpeg\n",
      "train/NORMAL/IM-0323-0001.jpeg\n",
      "train/NORMAL/IM-0324-0001.jpeg\n",
      "train/NORMAL/IM-0325-0001.jpeg\n",
      "train/NORMAL/IM-0326-0001.jpeg\n",
      "train/NORMAL/IM-0327-0001.jpeg\n",
      "train/NORMAL/IM-0329-0001.jpeg\n",
      "train/NORMAL/IM-0330-0001.jpeg\n",
      "train/NORMAL/IM-0331-0001.jpeg\n",
      "train/NORMAL/IM-0332-0001.jpeg\n",
      "train/NORMAL/IM-0333-0001.jpeg\n",
      "train/NORMAL/IM-0335-0001.jpeg\n",
      "train/NORMAL/IM-0337-0001.jpeg\n",
      "train/NORMAL/IM-0338-0001.jpeg\n",
      "train/NORMAL/IM-0339-0001.jpeg\n",
      "train/NORMAL/IM-0340-0001.jpeg\n",
      "train/NORMAL/IM-0341-0001.jpeg\n",
      "train/NORMAL/IM-0343-0001.jpeg\n",
      "train/NORMAL/IM-0345-0001.jpeg\n",
      "train/NORMAL/IM-0346-0001.jpeg\n",
      "train/NORMAL/IM-0347-0001.jpeg\n",
      "train/NORMAL/IM-0348-0001.jpeg\n",
      "train/NORMAL/IM-0349-0001.jpeg\n",
      "train/NORMAL/IM-0350-0001.jpeg\n",
      "train/NORMAL/IM-0351-0001.jpeg\n",
      "train/NORMAL/IM-0353-0001.jpeg\n",
      "train/NORMAL/IM-0354-0001.jpeg\n",
      "train/NORMAL/IM-0355-0001.jpeg\n",
      "train/NORMAL/IM-0356-0001.jpeg\n",
      "train/NORMAL/IM-0357-0001.jpeg\n",
      "train/NORMAL/IM-0358-0001.jpeg\n",
      "train/NORMAL/IM-0359-0001.jpeg\n",
      "train/NORMAL/IM-0361-0001.jpeg\n",
      "train/NORMAL/IM-0362-0001.jpeg\n",
      "train/NORMAL/IM-0363-0001.jpeg\n",
      "train/NORMAL/IM-0364-0001.jpeg\n",
      "train/NORMAL/IM-0365-0001.jpeg\n",
      "train/NORMAL/IM-0367-0001.jpeg\n",
      "train/NORMAL/IM-0368-0001.jpeg\n",
      "train/NORMAL/IM-0369-0001.jpeg\n",
      "train/NORMAL/IM-0370-0001.jpeg\n",
      "train/NORMAL/IM-0371-0001.jpeg\n",
      "train/NORMAL/IM-0372-0001.jpeg\n",
      "train/NORMAL/IM-0374-0001.jpeg\n",
      "train/NORMAL/IM-0375-0001.jpeg\n",
      "train/NORMAL/IM-0377-0001.jpeg\n",
      "train/NORMAL/IM-0379-0001.jpeg\n",
      "train/NORMAL/IM-0381-0001.jpeg\n",
      "train/NORMAL/IM-0382-0001.jpeg\n",
      "train/NORMAL/IM-0383-0001.jpeg\n",
      "train/NORMAL/IM-0384-0001.jpeg\n",
      "train/NORMAL/IM-0385-0001.jpeg\n",
      "train/NORMAL/IM-0386-0001.jpeg\n",
      "train/NORMAL/IM-0387-0001.jpeg\n",
      "train/NORMAL/IM-0388-0001.jpeg\n",
      "train/NORMAL/IM-0389-0001.jpeg\n",
      "train/NORMAL/IM-0391-0001.jpeg\n",
      "train/NORMAL/IM-0392-0001.jpeg\n",
      "train/NORMAL/IM-0393-0001.jpeg\n",
      "train/NORMAL/IM-0394-0001.jpeg\n",
      "train/NORMAL/IM-0395-0001.jpeg\n",
      "train/NORMAL/IM-0399-0001.jpeg\n",
      "train/NORMAL/IM-0400-0001.jpeg\n",
      "train/NORMAL/IM-0401-0001.jpeg\n",
      "train/NORMAL/IM-0403-0001.jpeg\n",
      "train/NORMAL/IM-0404-0001.jpeg\n",
      "train/NORMAL/IM-0405-0001.jpeg\n",
      "train/NORMAL/IM-0408-0001.jpeg\n",
      "train/NORMAL/IM-0409-0001.jpeg\n",
      "train/NORMAL/IM-0410-0001.jpeg\n",
      "train/NORMAL/IM-0411-0001.jpeg\n",
      "train/NORMAL/IM-0413-0001.jpeg\n",
      "train/NORMAL/IM-0414-0001.jpeg\n",
      "train/NORMAL/IM-0416-0001.jpeg\n",
      "train/NORMAL/IM-0417-0001.jpeg\n",
      "train/NORMAL/IM-0419-0001.jpeg\n",
      "train/NORMAL/IM-0420-0001.jpeg\n",
      "train/NORMAL/IM-0421-0001.jpeg\n",
      "train/NORMAL/IM-0423-0001.jpeg\n",
      "train/NORMAL/IM-0424-0001.jpeg\n",
      "train/NORMAL/IM-0425-0001.jpeg\n",
      "train/NORMAL/IM-0427-0001.jpeg\n",
      "train/NORMAL/IM-0428-0001.jpeg\n",
      "train/NORMAL/IM-0429-0001-0001.jpeg\n",
      "train/NORMAL/IM-0429-0001-0002.jpeg\n",
      "train/NORMAL/IM-0429-0001.jpeg\n",
      "train/NORMAL/IM-0430-0001.jpeg\n",
      "train/NORMAL/IM-0431-0001.jpeg\n",
      "train/NORMAL/IM-0432-0001.jpeg\n",
      "train/NORMAL/IM-0433-0001.jpeg\n",
      "train/NORMAL/IM-0434-0001.jpeg\n",
      "train/NORMAL/IM-0435-0001-0001.jpeg\n",
      "train/NORMAL/IM-0435-0001.jpeg\n",
      "train/NORMAL/IM-0437-0001-0001.jpeg\n",
      "train/NORMAL/IM-0437-0001-0002.jpeg\n",
      "train/NORMAL/IM-0437-0001.jpeg\n",
      "train/NORMAL/IM-0438-0001.jpeg\n",
      "train/NORMAL/IM-0439-0001-0001.jpeg\n",
      "train/NORMAL/IM-0439-0001-0002.jpeg\n",
      "train/NORMAL/IM-0439-0001.jpeg\n",
      "train/NORMAL/IM-0440-0001.jpeg\n",
      "train/NORMAL/IM-0441-0001.jpeg\n",
      "train/NORMAL/IM-0442-0001.jpeg\n",
      "train/NORMAL/IM-0444-0001.jpeg\n",
      "train/NORMAL/IM-0445-0001.jpeg\n",
      "train/NORMAL/IM-0446-0001.jpeg\n",
      "train/NORMAL/IM-0447-0001.jpeg\n",
      "train/NORMAL/IM-0448-0001.jpeg\n",
      "train/NORMAL/IM-0449-0001.jpeg\n",
      "train/NORMAL/IM-0450-0001.jpeg\n",
      "train/NORMAL/IM-0451-0001.jpeg\n",
      "train/NORMAL/IM-0452-0001.jpeg\n",
      "train/NORMAL/IM-0453-0001-0002.jpeg\n",
      "train/NORMAL/IM-0453-0001.jpeg\n",
      "train/NORMAL/IM-0455-0001.jpeg\n",
      "train/NORMAL/IM-0456-0001.jpeg\n",
      "train/NORMAL/IM-0457-0001.jpeg\n",
      "train/NORMAL/IM-0458-0001.jpeg\n",
      "train/NORMAL/IM-0459-0001.jpeg\n",
      "train/NORMAL/IM-0460-0001.jpeg\n",
      "train/NORMAL/IM-0461-0001.jpeg\n",
      "train/NORMAL/IM-0463-0001.jpeg\n",
      "train/NORMAL/IM-0464-0001.jpeg\n",
      "train/NORMAL/IM-0465-0001.jpeg\n",
      "train/NORMAL/IM-0466-0001.jpeg\n",
      "train/NORMAL/IM-0467-0001-0001.jpeg\n",
      "train/NORMAL/IM-0467-0001-0002.jpeg\n",
      "train/NORMAL/IM-0467-0001.jpeg\n",
      "train/NORMAL/IM-0469-0001.jpeg\n",
      "train/NORMAL/IM-0471-0001.jpeg\n",
      "train/NORMAL/IM-0472-0001.jpeg\n",
      "train/NORMAL/IM-0473-0001.jpeg\n",
      "train/NORMAL/IM-0474-0001.jpeg\n",
      "train/NORMAL/IM-0475-0001.jpeg\n",
      "train/NORMAL/IM-0476-0001.jpeg\n",
      "train/NORMAL/IM-0477-0001.jpeg\n",
      "train/NORMAL/IM-0478-0001.jpeg\n",
      "train/NORMAL/IM-0479-0001.jpeg\n",
      "train/NORMAL/IM-0480-0001.jpeg\n",
      "train/NORMAL/IM-0481-0001.jpeg\n",
      "train/NORMAL/IM-0482-0001.jpeg\n",
      "train/NORMAL/IM-0483-0001.jpeg\n",
      "train/NORMAL/IM-0484-0001.jpeg\n",
      "train/NORMAL/IM-0485-0001.jpeg\n",
      "train/NORMAL/IM-0486-0001.jpeg\n",
      "train/NORMAL/IM-0487-0001.jpeg\n",
      "train/NORMAL/IM-0488-0001.jpeg\n",
      "train/NORMAL/IM-0489-0001.jpeg\n",
      "train/NORMAL/IM-0490-0001.jpeg\n",
      "train/NORMAL/IM-0491-0001-0001.jpeg\n",
      "train/NORMAL/IM-0491-0001-0002.jpeg\n",
      "train/NORMAL/IM-0491-0001.jpeg\n",
      "train/NORMAL/IM-0492-0001.jpeg\n",
      "train/NORMAL/IM-0493-0001.jpeg\n",
      "train/NORMAL/IM-0494-0001.jpeg\n",
      "train/NORMAL/IM-0495-0001.jpeg\n",
      "train/NORMAL/IM-0496-0001.jpeg\n",
      "train/NORMAL/IM-0497-0001-0001.jpeg\n",
      "train/NORMAL/IM-0497-0001-0002.jpeg\n",
      "train/NORMAL/IM-0497-0001.jpeg\n",
      "train/NORMAL/IM-0499-0001-0001.jpeg\n",
      "train/NORMAL/IM-0499-0001-0002.jpeg\n",
      "train/NORMAL/IM-0499-0001.jpeg\n",
      "train/NORMAL/IM-0500-0001.jpeg\n",
      "train/NORMAL/IM-0501-0001-0001.jpeg\n",
      "train/NORMAL/IM-0501-0001-0002.jpeg\n",
      "train/NORMAL/IM-0501-0001.jpeg\n",
      "train/NORMAL/IM-0502-0001.jpeg\n",
      "train/NORMAL/IM-0503-0001.jpeg\n",
      "train/NORMAL/IM-0504-0001.jpeg\n",
      "train/NORMAL/IM-0505-0001-0001.jpeg\n",
      "train/NORMAL/IM-0505-0001-0002.jpeg\n",
      "train/NORMAL/IM-0505-0001.jpeg\n",
      "train/NORMAL/IM-0506-0001.jpeg\n",
      "train/NORMAL/IM-0507-0001.jpeg\n",
      "train/NORMAL/IM-0508-0001.jpeg\n",
      "train/NORMAL/IM-0509-0001-0001.jpeg\n",
      "train/NORMAL/IM-0509-0001-0002.jpeg\n",
      "train/NORMAL/IM-0509-0001.jpeg\n",
      "train/NORMAL/IM-0510-0001.jpeg\n",
      "train/NORMAL/IM-0511-0001-0001.jpeg\n",
      "train/NORMAL/IM-0511-0001-0002.jpeg\n",
      "train/NORMAL/IM-0511-0001.jpeg\n",
      "train/NORMAL/IM-0512-0001.jpeg\n",
      "train/NORMAL/IM-0513-0001.jpeg\n",
      "train/NORMAL/IM-0514-0001.jpeg\n",
      "train/NORMAL/IM-0515-0001.jpeg\n",
      "train/NORMAL/IM-0516-0001.jpeg\n",
      "train/NORMAL/IM-0517-0001-0001.jpeg\n",
      "train/NORMAL/IM-0517-0001.jpeg\n",
      "train/NORMAL/IM-0519-0001-0001.jpeg\n",
      "train/NORMAL/IM-0519-0001-0002.jpeg\n",
      "train/NORMAL/IM-0519-0001.jpeg\n",
      "train/NORMAL/IM-0520-0001.jpeg\n",
      "train/NORMAL/IM-0521-0001.jpeg\n",
      "train/NORMAL/IM-0522-0001.jpeg\n",
      "train/NORMAL/IM-0523-0001-0001.jpeg\n",
      "train/NORMAL/IM-0523-0001-0002.jpeg\n",
      "train/NORMAL/IM-0523-0001-0003.jpeg\n",
      "train/NORMAL/IM-0523-0001.jpeg\n",
      "train/NORMAL/IM-0524-0001.jpeg\n",
      "train/NORMAL/IM-0525-0001-0001.jpeg\n",
      "train/NORMAL/IM-0525-0001-0002.jpeg\n",
      "train/NORMAL/IM-0525-0001.jpeg\n",
      "train/NORMAL/IM-0526-0001.jpeg\n",
      "train/NORMAL/IM-0527-0001.jpeg\n",
      "train/NORMAL/IM-0528-0001.jpeg\n",
      "train/NORMAL/IM-0529-0001.jpeg\n",
      "train/NORMAL/IM-0530-0001.jpeg\n",
      "train/NORMAL/IM-0531-0001-0001.jpeg\n",
      "train/NORMAL/IM-0531-0001.jpeg\n",
      "train/NORMAL/IM-0532-0001.jpeg\n",
      "train/NORMAL/IM-0533-0001-0001.jpeg\n",
      "train/NORMAL/IM-0533-0001-0002.jpeg\n",
      "train/NORMAL/IM-0533-0001.jpeg\n",
      "train/NORMAL/IM-0534-0001.jpeg\n",
      "train/NORMAL/IM-0535-0001.jpeg\n",
      "train/NORMAL/IM-0536-0001.jpeg\n",
      "train/NORMAL/IM-0537-0001.jpeg\n",
      "train/NORMAL/IM-0538-0001.jpeg\n",
      "train/NORMAL/IM-0539-0001-0001.jpeg\n",
      "train/NORMAL/IM-0539-0001-0002.jpeg\n",
      "train/NORMAL/IM-0539-0001.jpeg\n",
      "train/NORMAL/IM-0540-0001.jpeg\n",
      "train/NORMAL/IM-0541-0001.jpeg\n",
      "train/NORMAL/IM-0542-0001.jpeg\n",
      "train/NORMAL/IM-0543-0001-0002.jpeg\n",
      "train/NORMAL/IM-0543-0001.jpeg\n",
      "train/NORMAL/IM-0544-0001.jpeg\n",
      "train/NORMAL/IM-0545-0001-0001.jpeg\n",
      "train/NORMAL/IM-0545-0001-0002.jpeg\n",
      "train/NORMAL/IM-0545-0001.jpeg\n",
      "train/NORMAL/IM-0546-0001.jpeg\n",
      "train/NORMAL/IM-0547-0001.jpeg\n",
      "train/NORMAL/IM-0548-0001.jpeg\n"
     ]
    }
   ],
   "source": [
    "from boto3 import client\n",
    "\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'PNEUMONIA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-96eb57138ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# os.mkdir(\"data\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# os.mkdir(\"labels\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PNEUMONIA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NORMAL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mBUCKET_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'PNEUMONIA'"
     ]
    }
   ],
   "source": [
    "# Downloading Data from S3\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from boto3 import client\n",
    "import os\n",
    "# os.mkdir(\"data\")\n",
    "# os.mkdir(\"labels\")\n",
    "os.mkdir(\"PNEUMONIA\")\n",
    "os.mkdir(\"NORMAL\")\n",
    "BUCKET_NAME = bucket\n",
    "c = 0\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])\n",
    "    KEY = key['Key']\n",
    "    s3 = boto3.resource('s3')\n",
    "    try:\n",
    "        s3.Bucket(BUCKET_NAME).download_file(KEY, f\"{key['Key']}\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise\n",
    "    c = c+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Converting downloaded data to png\n",
    "\n",
    "# Dcm to Png\n",
    "!pip install pydicom\n",
    "import pydicom as dicom\n",
    "import pydicom\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    try:\n",
    "        print(\"Converting to PNG .........................\")\n",
    "        dicom = dcmread(path, force=True)\n",
    "        print(dicom.SOPInstanceUID, \">>>>>>\", dicom.InstanceNumber, \">>>>>\", dicom.SeriesInstanceUID)\n",
    "        #if voi_lut:\n",
    "        if voi_lut and len(dicom.get(\"VOILUTSequence\", [])):\n",
    "            data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "        else:\n",
    "            data = dicom.pixel_array\n",
    "        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.amax(data) - data\n",
    "        data = data - np.min(data)\n",
    "        data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(e, \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        return \"corrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.rglob at 0x7f0a460dd250>\n",
      "data/8.40.878.3894.96486.151204.9863467.36445465827601201107183782728_2.89.458.6239.80654.657849.2429221.76912085147482001235113115490_5.70.817.2703.49758.291230.7795777.82738354396682743323689265917.dcm\n",
      "Converting to PNG .........................\n",
      "5.70.817.2703.49758.291230.7795777.82738354396682743323689265917 >>>>>> None >>>>> 2.89.458.6239.80654.657849.2429221.76912085147482001235113115490\n",
      "1 Done\n",
      "data/1.48.515.3545.18897.328545.6049716.21611614936186401392767068438_4.59.672.5221.45079.747162.3602189.16024474382543070697202423745_1.11.408.5405.96969.185346.7828467.86338934267437849897492950945.dcm\n",
      "Converting to PNG .........................\n",
      "1.11.408.5405.96969.185346.7828467.86338934267437849897492950945 >>>>>> None >>>>> 4.59.672.5221.45079.747162.3602189.16024474382543070697202423745\n",
      "2 Done\n",
      "data/9.33.680.2052.98882.767585.1119441.91176629656945193759387363974_1.82.190.4083.28678.124609.2680919.20486343947182279022202241823_9.20.620.8515.31105.940839.1523879.63760831490258556284943939307.dcm\n",
      "Converting to PNG .........................\n",
      "9.20.620.8515.31105.940839.1523879.63760831490258556284943939307 >>>>>> None >>>>> 1.82.190.4083.28678.124609.2680919.20486343947182279022202241823\n",
      "3 Done\n",
      "data/1.82.548.5697.68239.817863.9396319.16935878228600984547245240452_8.65.131.5211.10943.612195.7469189.64594968491759861067195506381_8.84.419.1021.56524.681538.4833718.62152682402197741179339668747.dcm\n",
      "Converting to PNG .........................\n",
      "8.84.419.1021.56524.681538.4833718.62152682402197741179339668747 >>>>>> None >>>>> 8.65.131.5211.10943.612195.7469189.64594968491759861067195506381\n",
      "4 Done\n",
      "data/2.85.286.3791.35949.753773.9880767.15429165451132577623158979749_8.89.212.4036.42151.157675.4535652.57605437788930293873315423443_7.37.605.1315.49717.499229.4874933.85139435507721810482764896598.dcm\n",
      "Converting to PNG .........................\n",
      "7.37.605.1315.49717.499229.4874933.85139435507721810482764896598 >>>>>> None >>>>> 8.89.212.4036.42151.157675.4535652.57605437788930293873315423443\n",
      "5 Done\n",
      "data/8.85.521.8835.76629.815666.1695031.32359719184716477789235126585_6.85.759.1880.78142.690026.9307749.23906050191084598636173426379_5.57.227.1097.63765.279894.2093212.49362100170287494469463263966.dcm\n",
      "Converting to PNG .........................\n",
      "5.57.227.1097.63765.279894.2093212.49362100170287494469463263966 >>>>>> None >>>>> 6.85.759.1880.78142.690026.9307749.23906050191084598636173426379\n",
      "6 Done\n",
      "data/1.14.764.1914.85188.383559.9801586.79428606583664236587800024293_1.15.254.3877.11461.113619.9505902.78281606105008178451517315551_5.84.698.7843.68776.385107.6232799.75098428005709452331214628525.dcm\n",
      "Converting to PNG .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.84.698.7843.68776.385107.6232799.75098428005709452331214628525 >>>>>> None >>>>> 1.15.254.3877.11461.113619.9505902.78281606105008178451517315551\n",
      "7 Done\n",
      "data/4.16.127.6493.28724.789873.2601794.77716663240110856937017188148_5.91.592.3643.13751.100780.8319578.96403197331969880005199284658_3.15.159.5991.17913.910685.6869332.71621726334320874493083157685.dcm\n",
      "Converting to PNG .........................\n",
      "3.15.159.5991.17913.910685.6869332.71621726334320874493083157685 >>>>>> None >>>>> 5.91.592.3643.13751.100780.8319578.96403197331969880005199284658\n",
      "8 Done\n",
      "data/1.19.162.8917.79598.343909.6273719.13778790522210060495265439021_7.18.371.4363.99246.969120.7173730.58348108426235352304328338948_9.10.131.1968.97602.173644.2714985.15129187318697535936642485798.dcm\n",
      "Converting to PNG .........................\n",
      "9.10.131.1968.97602.173644.2714985.15129187318697535936642485798 >>>>>> None >>>>> 7.18.371.4363.99246.969120.7173730.58348108426235352304328338948\n",
      "9 Done\n",
      "data/4.43.289.5957.15194.596855.8458467.55030428902744375304312611517_1.14.721.5405.69615.422080.5880883.12040752152862418815921240788_9.65.474.9496.97978.801355.5638011.92287657990904482575661940269.dcm\n",
      "Converting to PNG .........................\n",
      "9.65.474.9496.97978.801355.5638011.92287657990904482575661940269 >>>>>> None >>>>> 1.14.721.5405.69615.422080.5880883.12040752152862418815921240788\n",
      "10 Done\n",
      "data/6.48.150.3037.92427.989645.2456498.53023088902765570410952317025_8.88.534.8772.44528.621844.7025992.56073181069615824553460639352_5.39.240.9273.98783.524717.4961264.77692097229509065728647767648.dcm\n",
      "Converting to PNG .........................\n",
      "5.39.240.9273.98783.524717.4961264.77692097229509065728647767648 >>>>>> None >>>>> 8.88.534.8772.44528.621844.7025992.56073181069615824553460639352\n",
      "11 Done\n",
      "data/6.56.695.1043.19771.898820.2544443.53735454127317577078129896454_9.54.338.8973.31542.694685.8878100.32175153119531313760241328062_7.83.167.7585.97070.689798.4903641.89873301021692336822608065320.dcm\n",
      "Converting to PNG .........................\n",
      "7.83.167.7585.97070.689798.4903641.89873301021692336822608065320 >>>>>> None >>>>> 9.54.338.8973.31542.694685.8878100.32175153119531313760241328062\n",
      "12 Done\n",
      "data/3.49.619.5835.45353.865784.9181389.42912054307272713222529062205_2.48.263.2554.27965.584304.1757971.42041263969033139975344951977_3.99.526.4849.64469.269046.6063207.81664890846363798061222597518.dcm\n",
      "Converting to PNG .........................\n",
      "3.99.526.4849.64469.269046.6063207.81664890846363798061222597518 >>>>>> None >>>>> 2.48.263.2554.27965.584304.1757971.42041263969033139975344951977\n",
      "13 Done\n",
      "data/1.10.332.5540.70198.125047.6100892.77569484145273387074879042669_2.37.353.3043.44046.260515.2735724.40997716825361943557049047247_5.59.117.6843.54822.245619.9875204.56401775907583045968062940757.dcm\n",
      "Converting to PNG .........................\n",
      "5.59.117.6843.54822.245619.9875204.56401775907583045968062940757 >>>>>> None >>>>> 2.37.353.3043.44046.260515.2735724.40997716825361943557049047247\n",
      "14 Done\n",
      "data/1.64.176.1080.28286.797655.9332794.95802624735059046197977249904_8.34.925.5175.19598.724268.1926024.54667105444282280218209323400_2.41.683.4642.99640.976547.3092445.17334941979542688953324322840.dcm\n",
      "Converting to PNG .........................\n",
      "2.41.683.4642.99640.976547.3092445.17334941979542688953324322840 >>>>>> None >>>>> 8.34.925.5175.19598.724268.1926024.54667105444282280218209323400\n",
      "15 Done\n",
      "data/3.11.809.1798.13802.187665.7161578.91450437265827023072354500111_4.23.195.2811.37370.118983.3810485.75232512720396210694188283898_4.80.814.6684.59684.836695.7944705.67425020594716176384067450862.dcm\n",
      "Converting to PNG .........................\n",
      "4.80.814.6684.59684.836695.7944705.67425020594716176384067450862 >>>>>> None >>>>> 4.23.195.2811.37370.118983.3810485.75232512720396210694188283898\n",
      "16 Done\n",
      "data/6.34.366.1133.88196.752940.9384430.18794036866512583438686704863_9.63.759.6515.15550.178660.9581379.87691615633563283802919334961_8.89.189.9876.19200.656602.8226520.65064009630524696349355103756.dcm\n",
      "Converting to PNG .........................\n",
      "8.89.189.9876.19200.656602.8226520.65064009630524696349355103756 >>>>>> None >>>>> 9.63.759.6515.15550.178660.9581379.87691615633563283802919334961\n",
      "17 Done\n",
      "data/8.60.189.3205.97394.353947.3915258.25019571361723616585676660767_1.16.719.7145.72337.804544.6317706.18754671998408243740307902054_8.99.121.7504.36964.271349.1619341.64708198908601043204407995990.dcm\n",
      "Converting to PNG .........................\n",
      "8.99.121.7504.36964.271349.1619341.64708198908601043204407995990 >>>>>> None >>>>> 1.16.719.7145.72337.804544.6317706.18754671998408243740307902054\n",
      "18 Done\n",
      "data/2.92.926.3579.46327.694029.5805805.32858210505560596952778950985_1.52.604.1452.90243.293305.7688205.11684809959463808961858644100_3.60.629.8423.46169.455459.8568276.26504642382743517175463772306.dcm\n",
      "Converting to PNG .........................\n",
      "3.60.629.8423.46169.455459.8568276.26504642382743517175463772306 >>>>>> None >>>>> 1.52.604.1452.90243.293305.7688205.11684809959463808961858644100\n",
      "19 Done\n",
      "data/4.98.360.6967.94108.956825.4238495.38965443940537699442132093091_5.94.696.1583.40255.216137.5306539.93806536706830180921254058896_1.61.202.3149.11601.367694.1635311.68718006132493604503089828909.dcm\n",
      "Converting to PNG .........................\n",
      "1.61.202.3149.11601.367694.1635311.68718006132493604503089828909 >>>>>> None >>>>> 5.94.696.1583.40255.216137.5306539.93806536706830180921254058896\n",
      "20 Done\n",
      "data/4.20.212.2533.88386.539249.6140021.38494441169314680586153246795_3.11.435.3446.19236.961122.2547862.28286547516471004820751601103_3.96.512.4988.15148.791415.9960772.17958300113282110447148521373.dcm\n",
      "Converting to PNG .........................\n",
      "3.96.512.4988.15148.791415.9960772.17958300113282110447148521373 >>>>>> None >>>>> 3.11.435.3446.19236.961122.2547862.28286547516471004820751601103\n",
      "21 Done\n",
      "data/1.12.642.7331.43503.461473.1522014.12615216859043826431491484498_1.17.604.3471.76771.169376.9147500.81520267085463990490218312360_9.77.700.4476.86215.792653.2458789.17478155531857242704438425785.dcm\n",
      "Converting to PNG .........................\n",
      "9.77.700.4476.86215.792653.2458789.17478155531857242704438425785 >>>>>> None >>>>> 1.17.604.3471.76771.169376.9147500.81520267085463990490218312360\n",
      "22 Done\n",
      "data/4.86.948.1926.35187.155610.2953581.88401201784313503721449847233_1.12.280.6685.73208.866635.4566344.27374643763495570453387563902_6.49.279.1940.25906.169331.6437004.37935522697448657248181888762.dcm\n",
      "Converting to PNG .........................\n",
      "6.49.279.1940.25906.169331.6437004.37935522697448657248181888762 >>>>>> None >>>>> 1.12.280.6685.73208.866635.4566344.27374643763495570453387563902\n",
      "23 Done\n",
      "data/8.59.291.8976.17160.359728.3319065.53835329731996115299624983520_4.18.572.6733.87201.953359.5444956.72964313332334785658739063829_1.19.850.6764.35896.124661.8845021.30258234242075660815322117193.dcm\n",
      "Converting to PNG .........................\n",
      "1.19.850.6764.35896.124661.8845021.30258234242075660815322117193 >>>>>> None >>>>> 4.18.572.6733.87201.953359.5444956.72964313332334785658739063829\n",
      "24 Done\n",
      "data/9.66.631.6298.23092.413208.1635651.45641869682381025027188917726_1.15.288.7494.11546.871588.2113535.10227575550601829832437185805_1.14.890.2300.97366.347152.2286224.47170498808443981219277295703.dcm\n",
      "Converting to PNG .........................\n",
      "1.14.890.2300.97366.347152.2286224.47170498808443981219277295703 >>>>>> None >>>>> 1.15.288.7494.11546.871588.2113535.10227575550601829832437185805\n",
      "25 Done\n",
      "data/1.19.408.3509.51528.507295.5493967.39196860061706471291044962837_3.88.589.3613.50208.977572.4705145.14496901137495069320803092470_9.11.677.9282.92501.777115.3115080.52145884456301556995579847059.dcm\n",
      "Converting to PNG .........................\n",
      "9.11.677.9282.92501.777115.3115080.52145884456301556995579847059 >>>>>> None >>>>> 3.88.589.3613.50208.977572.4705145.14496901137495069320803092470\n",
      "26 Done\n",
      "data/5.57.668.8568.68570.851866.9353508.71041659288834301774276067909_2.46.712.5419.27723.996147.9969541.48840489519964695318764374574_7.89.439.3973.18372.709703.1617544.18792561151983123003969865921.dcm\n",
      "Converting to PNG .........................\n",
      "7.89.439.3973.18372.709703.1617544.18792561151983123003969865921 >>>>>> None >>>>> 2.46.712.5419.27723.996147.9969541.48840489519964695318764374574\n",
      "27 Done\n"
     ]
    }
   ],
   "source": [
    "files_ = Path(\"data\").rglob('*.dcm')\n",
    "print(files_)\n",
    "c = 0\n",
    "for i in files_:\n",
    "    try:\n",
    "        print(i)\n",
    "        img = read_xray(i)\n",
    "        with open(\"filename.pkl\", 'wb') as f:\n",
    "            pickle.dump(img, f)\n",
    "        ims = pickle.load(open(\"filename.pkl\", \"rb\"))\n",
    "        norm = (ims.astype(np.float) - ims.min()) * 255.0 / (ims.max() - ims.min())\n",
    "        Image.fromarray(norm.astype(np.uint8)).save(f\"training_data_png/{c}.png\")\n",
    "        c = c + 1\n",
    "        print(c, \"Done\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Getting the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-images-idx3-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfbe140c2554eab9adbb49f89fad239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-labels-idx1-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3552db244d481ea82160975d502f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a94508b31c9435b8fa3165ea2548c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e95ae6eec7447da49156eccd239f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "\n",
    "MNIST(\n",
    "    \"data\",\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `mnist.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of gpus available in the current container.\n",
    "* `SM_CURRENT_HOST`: The name of the current container on the container network.\n",
    "* `SM_HOSTS`: JSON encoded list containing all the hosts .\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (``if __name__=='__main__':``) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshlex\u001b[39;49;00m, \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\u001b[37m# def install(package):\u001b[39;49;00m\n",
      "\u001b[37m#     os.system(\"pip install \" +  package)\u001b[39;49;00m\n",
      "    \n",
      "\u001b[37m# install('pillow')\u001b[39;49;00m\n",
      "\u001b[37m# install('requests')\u001b[39;49;00m\n",
      "\u001b[37m# install('pydicom')\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpydicom\u001b[39;49;00m\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_pretrained_model\u001b[39;49;00m(model_name):\n",
      "    \u001b[33m\"\"\"Retrieve a pre-trained model from torchvision\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Params\u001b[39;49;00m\n",
      "\u001b[33m    -------\u001b[39;49;00m\n",
      "\u001b[33m        model_name (str): name of the model (currently only accepts vgg16 and resnet50)\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Return\u001b[39;49;00m\n",
      "\u001b[33m    --------\u001b[39;49;00m\n",
      "\u001b[33m        model (PyTorch model): cnn\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m model_name == \u001b[33m'\u001b[39;49;00m\u001b[33mvgg16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        model = models.vgg16(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[37m# Freeze early layers\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "            param.requires_grad = \u001b[34mFalse\u001b[39;49;00m\n",
      "        n_inputs = model.classifier[\u001b[34m6\u001b[39;49;00m].in_features\n",
      "\n",
      "        \u001b[37m# Add on classifier\u001b[39;49;00m\n",
      "        model.classifier[\u001b[34m6\u001b[39;49;00m] = nn.Sequential(\n",
      "            nn.Linear(n_inputs, \u001b[34m256\u001b[39;49;00m), nn.ReLU(), nn.Dropout(\u001b[34m0.2\u001b[39;49;00m),\n",
      "            nn.Linear(\u001b[34m256\u001b[39;49;00m, n_classes), nn.LogSoftmax(dim=\u001b[34m1\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34melif\u001b[39;49;00m model_name == \u001b[33m'\u001b[39;49;00m\u001b[33mresnet50\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        model = models.resnet50(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "            param.requires_grad = \u001b[34mFalse\u001b[39;49;00m\n",
      "\n",
      "        n_inputs = model.fc.in_features\n",
      "        model.fc = nn.Sequential(\n",
      "            nn.Linear(n_inputs, \u001b[34m256\u001b[39;49;00m), nn.ReLU(), nn.Dropout(\u001b[34m0.2\u001b[39;49;00m),\n",
      "            nn.Linear(\u001b[34m256\u001b[39;49;00m, n_classes), nn.LogSoftmax(dim=\u001b[34m1\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[37m# Move to gpu and parallelize\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m train_on_gpu:\n",
      "        model = model.to(\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m multi_gpu:\n",
      "        model = nn.DataParallel(model)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model,\n",
      "          criterion,\n",
      "          optimizer,\n",
      "          train_loader,\n",
      "          valid_loader,\n",
      "          save_file_name,\n",
      "          max_epochs_stop=\u001b[34m3\u001b[39;49;00m,\n",
      "          n_epochs=\u001b[34m20\u001b[39;49;00m,\n",
      "          print_every=\u001b[34m2\u001b[39;49;00m):\n",
      "    \u001b[33m\"\"\"Train a PyTorch Model\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Params\u001b[39;49;00m\n",
      "\u001b[33m    --------\u001b[39;49;00m\n",
      "\u001b[33m        model (PyTorch model): cnn to train\u001b[39;49;00m\n",
      "\u001b[33m        criterion (PyTorch loss): objective to minimize\u001b[39;49;00m\n",
      "\u001b[33m        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\u001b[39;49;00m\n",
      "\u001b[33m        train_loader (PyTorch dataloader): training dataloader to iterate through\u001b[39;49;00m\n",
      "\u001b[33m        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\u001b[39;49;00m\n",
      "\u001b[33m        save_file_name (str ending in '.pt'): file path to save the model state dict\u001b[39;49;00m\n",
      "\u001b[33m        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\u001b[39;49;00m\n",
      "\u001b[33m        n_epochs (int): maximum number of training epochs\u001b[39;49;00m\n",
      "\u001b[33m        print_every (int): frequency of epochs to print training stats\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Returns\u001b[39;49;00m\n",
      "\u001b[33m    --------\u001b[39;49;00m\n",
      "\u001b[33m        model (PyTorch model): trained cnn with best weights\u001b[39;49;00m\n",
      "\u001b[33m        history (DataFrame): history of train and validation loss and accuracy\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Early stopping intialization\u001b[39;49;00m\n",
      "    epochs_no_improve = \u001b[34m0\u001b[39;49;00m\n",
      "    valid_loss_min = np.Inf\n",
      "\n",
      "    valid_max_acc = \u001b[34m0\u001b[39;49;00m\n",
      "    history = []\n",
      "\n",
      "    \u001b[37m# Number of epochs already trained (if using loaded in model weights)\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mModel has been trained for: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel.epochs\u001b[33m}\u001b[39;49;00m\u001b[33m epochs.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mexcept\u001b[39;49;00m:\n",
      "        model.epochs = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mStarting Training from Scratch.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    overall_start = timer()\n",
      "\n",
      "    \u001b[37m# Main loop\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_epochs):\n",
      "\n",
      "        \u001b[37m# keep track of training and validation loss each epoch\u001b[39;49;00m\n",
      "        train_loss = \u001b[34m0.0\u001b[39;49;00m\n",
      "        valid_loss = \u001b[34m0.0\u001b[39;49;00m\n",
      "\n",
      "        train_acc = \u001b[34m0\u001b[39;49;00m\n",
      "        valid_acc = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# Set to training\u001b[39;49;00m\n",
      "        model.train()\n",
      "        start = timer()\n",
      "\n",
      "        \u001b[37m# Training loop\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m ii, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader):\n",
      "            \u001b[37m# Tensors to gpu\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m train_on_gpu:\n",
      "                data, target = data.cuda(), target.cuda()\n",
      "\n",
      "            \u001b[37m# Clear gradients\u001b[39;49;00m\n",
      "            optimizer.zero_grad()\n",
      "            \u001b[37m# Predicted outputs are log probabilities\u001b[39;49;00m\n",
      "            output = model(data)\n",
      "\n",
      "            \u001b[37m# Loss and backpropagation of gradients\u001b[39;49;00m\n",
      "            loss = criterion(output, target)\n",
      "            loss.backward()\n",
      "\n",
      "            \u001b[37m# Update the parameters\u001b[39;49;00m\n",
      "            optimizer.step()\n",
      "\n",
      "            \u001b[37m# Track train loss by multiplying average loss by number of examples in batch\u001b[39;49;00m\n",
      "            train_loss += loss.item() * data.size(\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "            \u001b[37m# Calculate accuracy by finding max log probability\u001b[39;49;00m\n",
      "            _, pred = torch.max(output, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
      "            correct = np.squeeze(correct_tensor.numpy()) \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m train_on_gpu \u001b[34melse\u001b[39;49;00m np.squeeze(correct_tensor.cpu().numpy())\n",
      "            \u001b[37m# calculate test accuracy for each object class\u001b[39;49;00m\n",
      "            \u001b[33m'''for i in range(batch_size):       \u001b[39;49;00m\n",
      "\u001b[33m                label = target.data[i]\u001b[39;49;00m\n",
      "\u001b[33m                class_correct[label] += correct[i].item()\u001b[39;49;00m\n",
      "\u001b[33m                class_total[label] += 1'''\u001b[39;49;00m\n",
      "                \n",
      "            \u001b[37m# Need to convert correct tensor from int to float to average\u001b[39;49;00m\n",
      "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
      "            \u001b[37m# Multiply average accuracy times the number of examples in batch\u001b[39;49;00m\n",
      "            train_acc += accuracy.item() * data.size(\u001b[34m0\u001b[39;49;00m)\n",
      "            \n",
      "            \u001b[37m# Track training progress\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m(\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch\u001b[33m}\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[34m100\u001b[39;49;00m * (ii + \u001b[34m1\u001b[39;49;00m) / \u001b[36mlen\u001b[39;49;00m(train_loader)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m% complete. \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtimer() - start\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m seconds elapsed in epoch.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                end=\u001b[33m'\u001b[39;49;00m\u001b[33m\\r\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[37m# After training loops ends, start validation\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            model.epochs += \u001b[34m1\u001b[39;49;00m\n",
      "\n",
      "            \u001b[37m# Don't need to keep track of gradients\u001b[39;49;00m\n",
      "            \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "                \u001b[37m# Set to evaluation mode\u001b[39;49;00m\n",
      "                model.eval()\n",
      "\n",
      "                \u001b[37m# Validation loop\u001b[39;49;00m\n",
      "                \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m valid_loader:\n",
      "                    \u001b[37m# Tensors to gpu\u001b[39;49;00m\n",
      "                    \u001b[34mif\u001b[39;49;00m train_on_gpu:\n",
      "                        data, target = data.cuda(), target.cuda()\n",
      "\n",
      "                    \u001b[37m# Forward pass\u001b[39;49;00m\n",
      "                    output = model(data)\n",
      "\n",
      "                    \u001b[37m# Validation loss\u001b[39;49;00m\n",
      "                    loss = criterion(output, target)\n",
      "                    \u001b[37m# Multiply average loss times the number of examples in batch\u001b[39;49;00m\n",
      "                    valid_loss += loss.item() * data.size(\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "                    \u001b[37m# Calculate validation accuracy\u001b[39;49;00m\n",
      "                    _, pred = torch.max(output, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
      "                    accuracy = torch.mean(\n",
      "                        correct_tensor.type(torch.FloatTensor))\n",
      "                    \u001b[37m# Multiply average accuracy times the number of examples\u001b[39;49;00m\n",
      "                    valid_acc += accuracy.item() * data.size(\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "                \u001b[37m# Calculate average losses\u001b[39;49;00m\n",
      "                train_loss = train_loss / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset)\n",
      "                valid_loss = valid_loss / \u001b[36mlen\u001b[39;49;00m(valid_loader.dataset)\n",
      "\n",
      "                \u001b[37m# Calculate average accuracy\u001b[39;49;00m\n",
      "                train_acc = train_acc / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset)\n",
      "                valid_acc = valid_acc / \u001b[36mlen\u001b[39;49;00m(valid_loader.dataset)\n",
      "\n",
      "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
      "\n",
      "                \u001b[37m# Print training and validation results\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m (epoch + \u001b[34m1\u001b[39;49;00m) % print_every == \u001b[34m0\u001b[39;49;00m:\n",
      "                    \u001b[36mprint\u001b[39;49;00m(\n",
      "                        \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mTraining Loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtrain_loss\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mValidation Loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvalid_loss\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                    )\n",
      "                    \u001b[36mprint\u001b[39;49;00m(\n",
      "                        \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mTraining Accuracy: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[34m100\u001b[39;49;00m * train_acc\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m Validation Accuracy: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[34m100\u001b[39;49;00m * valid_acc\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                    )\n",
      "\n",
      "                \u001b[37m# Save the model if validation loss decreases\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m valid_loss < valid_loss_min:\n",
      "                    \u001b[37m# Save model\u001b[39;49;00m\n",
      "                    torch.save(model.state_dict(), save_file_name)\n",
      "                    \u001b[37m# Track improvement\u001b[39;49;00m\n",
      "                    epochs_no_improve = \u001b[34m0\u001b[39;49;00m\n",
      "                    valid_loss_min = valid_loss\n",
      "                    valid_best_acc = valid_acc\n",
      "                    best_epoch = epoch\n",
      "\n",
      "                \u001b[37m# Otherwise increment count of epochs with no improvement\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m:\n",
      "                    epochs_no_improve += \u001b[34m1\u001b[39;49;00m\n",
      "                    \u001b[37m# Trigger early stopping\u001b[39;49;00m\n",
      "                    \u001b[34mif\u001b[39;49;00m epochs_no_improve >= max_epochs_stop:\n",
      "                        \u001b[36mprint\u001b[39;49;00m(\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mEarly Stopping! Total epochs: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch\u001b[33m}\u001b[39;49;00m\u001b[33m. Best epoch: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbest_epoch\u001b[33m}\u001b[39;49;00m\u001b[33m with loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvalid_loss_min\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m and acc: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[34m100\u001b[39;49;00m * valid_acc\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                        )\n",
      "                        total_time = timer() - overall_start\n",
      "                        \u001b[36mprint\u001b[39;49;00m(\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtotal_time\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m total seconds elapsed. \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtotal_time / (epoch+\u001b[34m1\u001b[39;49;00m)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m seconds per epoch.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                        )\n",
      "\n",
      "                        \u001b[37m# Load the best state dict\u001b[39;49;00m\n",
      "                        model.load_state_dict(torch.load(save_file_name))\n",
      "                        \u001b[37m# Attach the optimizer\u001b[39;49;00m\n",
      "                        model.optimizer = optimizer\n",
      "\n",
      "                        \u001b[37m# Format history\u001b[39;49;00m\n",
      "                        history = pd.DataFrame(\n",
      "                            history,\n",
      "                            columns=[\n",
      "                                \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvalid_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_acc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                \u001b[33m'\u001b[39;49;00m\u001b[33mvalid_acc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                            ])\n",
      "                        \u001b[34mreturn\u001b[39;49;00m model, history\n",
      "\n",
      "    \u001b[37m# Attach the optimizer\u001b[39;49;00m\n",
      "    model.optimizer = optimizer\n",
      "    \u001b[37m# Record overall time and print out stats\u001b[39;49;00m\n",
      "    total_time = timer() - overall_start\n",
      "\u001b[37m#     print(\u001b[39;49;00m\n",
      "\u001b[37m#         f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\u001b[39;49;00m\n",
      "\u001b[37m#     )\u001b[39;49;00m\n",
      "\u001b[37m#     print(\u001b[39;49;00m\n",
      "\u001b[37m#         f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\u001b[39;49;00m\n",
      "\u001b[37m#     )\u001b[39;49;00m\n",
      "    \u001b[37m# Format history\u001b[39;49;00m\n",
      "    history = pd.DataFrame(\n",
      "        history,\n",
      "        columns=[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvalid_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_acc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvalid_acc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \u001b[34mreturn\u001b[39;49;00m model, history\n",
      "\n",
      "\n",
      "model, history = train(\n",
      "    model,\n",
      "    criterion,\n",
      "    optimizer,\n",
      "    dataloaders[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "    dataloaders[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "    save_file_name=save_file_name,\n",
      "    max_epochs_stop=\u001b[34m5\u001b[39;49;00m,\n",
      "    n_epochs=\u001b[34m1\u001b[39;49;00m,\n",
      "    print_every=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_checkpoint\u001b[39;49;00m(model, path):\n",
      "    \u001b[33m\"\"\"Save a PyTorch model checkpoint\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Params\u001b[39;49;00m\n",
      "\u001b[33m    --------\u001b[39;49;00m\n",
      "\u001b[33m        model (PyTorch model): model to save\u001b[39;49;00m\n",
      "\u001b[33m        path (str): location to save model. Must start with `model_name-` and end in '.pth'\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Returns\u001b[39;49;00m\n",
      "\u001b[33m    --------\u001b[39;49;00m\n",
      "\u001b[33m        None, save the `model` to `path`\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    model_name = path.split(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)[\u001b[34m0\u001b[39;49;00m]\n",
      "    \u001b[34massert\u001b[39;49;00m (model_name \u001b[35min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mvgg16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mresnet50\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                           ]), \u001b[33m\"\u001b[39;49;00m\u001b[33mPath must have the correct model name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Basic details\u001b[39;49;00m\n",
      "    checkpoint = {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mclass_to_idx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.class_to_idx,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33midx_to_class\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.idx_to_class,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.epochs,\n",
      "    }\n",
      "\n",
      "    \u001b[37m# Extract the final classifier and the state dictionary\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m model_name == \u001b[33m'\u001b[39;49;00m\u001b[33mvgg16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[37m# Check to see if model was parallelized\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m multi_gpu:\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mclassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.module.classifier\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.module.state_dict()\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mclassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.classifier\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.state_dict()\n",
      "\n",
      "    \u001b[34melif\u001b[39;49;00m model_name == \u001b[33m'\u001b[39;49;00m\u001b[33mresnet50\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[34mif\u001b[39;49;00m multi_gpu:\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mfc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.module.fc\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.module.state_dict()\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mfc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.fc\n",
      "            checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.state_dict()\n",
      "\n",
      "    \u001b[37m# Add the optimizer\u001b[39;49;00m\n",
      "    checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33moptimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.optimizer\n",
      "    checkpoint[\u001b[33m'\u001b[39;49;00m\u001b[33moptimizer_state_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model.optimizer.state_dict()\n",
      "\n",
      "    \u001b[37m# Save the data to the path\u001b[39;49;00m\n",
      "    torch.save(checkpoint, path)\n",
      "    \n",
      "save_checkpoint(model, path=checkpoint_path)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_dataloader\u001b[39;49;00m():\n",
      "    image_transforms = {\n",
      "    \u001b[37m# Train uses data augmentation\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    transforms.Compose([\n",
      "        transforms.RandomResizedCrop(size=\u001b[34m256\u001b[39;49;00m, scale=(\u001b[34m0.8\u001b[39;49;00m, \u001b[34m1.0\u001b[39;49;00m)),\n",
      "        transforms.RandomRotation(degrees=\u001b[34m15\u001b[39;49;00m),\n",
      "        transforms.ColorJitter(),\n",
      "        transforms.RandomHorizontalFlip(),\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),  \u001b[37m# Image net standards\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m],\n",
      "                             [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])  \u001b[37m# Imagenet standards\u001b[39;49;00m\n",
      "    ]),\n",
      "    \u001b[37m# Validation does not use augmentation\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    transforms.Compose([\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\n",
      "        transforms.ToTensor(),\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\n",
      "    ]),\n",
      "    \u001b[37m# Test does not use augmentation\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    transforms.Compose([\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\n",
      "        transforms.ToTensor(),\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\n",
      "    ]),\n",
      "    \n",
      "    }\n",
      "    \n",
      "    \n",
      "    data = {\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    datasets.ImageFolder(root=traindir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    datasets.ImageFolder(root=validdir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    datasets.ImageFolder(root=testdir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    }\n",
      "\n",
      "    \u001b[37m# Dataloader iterators\u001b[39;49;00m\n",
      "    dataloaders = {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m),\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m),\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    }\n",
      "\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m dataloaders\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_models\u001b[39;49;00m():\n",
      "    model = models.vgg16(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "        param.requires_grad = \u001b[34mFalse\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters. In this case we are going to run our training job on 2 ```ml.c4.xlarge``` instances. But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)). The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the `mnist.py` script above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker==2.110.0 in /opt/conda/lib/python3.7/site-packages (2.110.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.3.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.0.1)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (21.4.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.1.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (3.20.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.3.5)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.7.5)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.26.24)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (20.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (4.13.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.2.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker==2.110.0) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.24 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker==2.110.0) (1.29.24)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker==2.110.0) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.110.0) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.110.0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.110.0) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.110.0) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.110.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.110.0) (2.8.2)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (0.3.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (1.7.6.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (0.70.14)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (0.3.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker==2.110.0) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.24->boto3<2.0,>=1.20.21->sagemaker==2.110.0) (1.26.13)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker==2.110.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.110.0\n"
     ]
    }
   ],
   "source": [
    "!pip show sagemaker | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"classifier.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.11.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    # instance_type=\"ml.g4dn.xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},\n",
    "    dependencies=['code/requirements.txt'],\n",
    "    source_dir = \"code\",\n",
    "    max_run=20,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-05 13:39:13 Starting - Starting the training job...\n",
      "2023-01-05 13:39:37 Starting - Preparing the instances for trainingProfilerReport-1672925952: InProgress\n",
      "......\n",
      "2023-01-05 13:40:37 Downloading - Downloading input data...\n",
      "2023-01-05 13:41:02 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:03,404 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:03,406 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:03,414 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:03,416 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:03,573 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[34mCollecting pydicom\u001b[0m\n",
      "\u001b[34mDownloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34m 2.0/2.0 MB 42.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.22.2)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary\u001b[0m\n",
      "\u001b[34mDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2022.9.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary, pydicom\u001b[0m\n",
      "\u001b[34mSuccessfully installed pydicom-2.3.1 torchsummary-1.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:06,006 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:06,006 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:06,008 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:06,017 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:06,027 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:06,034 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validating\": \"/opt/ml/input/data/validating\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validating\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2023-01-05-13-39-12-623\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-01-05-13-39-12-623/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"classifier\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"classifier.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=classifier.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validating\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\",\"validating\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=classifier\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-01-05-13-39-12-623/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\",\"validating\":\"/opt/ml/input/data/validating\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validating\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2023-01-05-13-39-12-623\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-01-05-13-39-12-623/source/sourcedir.tar.gz\",\"module_name\":\"classifier\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"classifier.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATING=/opt/ml/input/data/validating\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20221003-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 classifier.py --backend gloo --epochs 1\u001b[0m\n",
      "\u001b[34m********* inside run *************\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training/ , /opt/ml/input/data/testing/ , /opt/ml/input/data/validating/\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34m********* inside preops *************\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training/ , /opt/ml/input/data/testing/ , /opt/ml/input/data/validating/\u001b[0m\n",
      "\u001b[34m[2023-01-05 13:41:07.701 algo-1:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-01-05 13:41:08.011 algo-1:45 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-01-05 13:41:08.012 algo-1:45 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-01-05 13:41:08.013 algo-1:45 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-01-05 13:41:08.013 algo-1:45 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-01-05 13:41:08.013 algo-1:45 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mtorch.Size([20, 3, 224, 224]) torch.Size([20])\u001b[0m\n",
      "\u001b[34mThere are 2 different classes.\u001b[0m\n",
      "\u001b[34m2\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/528M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m4%|         | 20.5M/528M [00:00<00:02, 215MB/s]\u001b[0m\n",
      "\u001b[34m10%|         | 52.8M/528M [00:00<00:01, 288MB/s]\u001b[0m\n",
      "\u001b[34m16%|        | 82.1M/528M [00:00<00:01, 296MB/s]\u001b[0m\n",
      "\u001b[34m22%|       | 117M/528M [00:00<00:01, 322MB/s]\u001b[0m\n",
      "\u001b[34m29%|       | 151M/528M [00:00<00:01, 338MB/s]\u001b[0m\n",
      "\u001b[34m35%|      | 184M/528M [00:00<00:01, 338MB/s]\u001b[0m\n",
      "\u001b[34m41%|     | 219M/528M [00:00<00:00, 347MB/s]\u001b[0m\n",
      "\u001b[34m48%|     | 252M/528M [00:00<00:00, 334MB/s]\u001b[0m\n",
      "\u001b[34m54%|    | 285M/528M [00:00<00:00, 339MB/s]\u001b[0m\n",
      "\u001b[34m60%|    | 318M/528M [00:01<00:00, 338MB/s]\u001b[0m\n",
      "\u001b[34m66%|   | 350M/528M [00:01<00:00, 338MB/s]\u001b[0m\n",
      "\u001b[34m72%|  | 382M/528M [00:01<00:00, 308MB/s]\u001b[0m\n",
      "\u001b[34m78%|  | 412M/528M [00:01<00:00, 309MB/s]\u001b[0m\n",
      "\u001b[34m84%| | 442M/528M [00:01<00:00, 302MB/s]\u001b[0m\n",
      "\u001b[34m89%| | 471M/528M [00:01<00:00, 298MB/s]\u001b[0m\n",
      "\u001b[34m95%|| 502M/528M [00:01<00:00, 305MB/s]\u001b[0m\n",
      "\u001b[34m100%|| 528M/528M [00:01<00:00, 314MB/s]\u001b[0m\n",
      "\u001b[34m135,309,890 total parameters.\u001b[0m\n",
      "\u001b[34m1,049,346 training parameters.\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\u001b[0m\n",
      "\u001b[34m================================================================\u001b[0m\n",
      "\u001b[34mConv2d-1        [128, 64, 224, 224]           1,792\n",
      "              ReLU-2        [128, 64, 224, 224]               0\u001b[0m\n",
      "\u001b[34mConv2d-3        [128, 64, 224, 224]          36,928\n",
      "              ReLU-4        [128, 64, 224, 224]               0\n",
      "         MaxPool2d-5        [128, 64, 112, 112]               0\n",
      "            Conv2d-6       [128, 128, 112, 112]          73,856\n",
      "              ReLU-7       [128, 128, 112, 112]               0\n",
      "            Conv2d-8       [128, 128, 112, 112]         147,584\n",
      "              ReLU-9       [128, 128, 112, 112]               0\n",
      "        MaxPool2d-10         [128, 128, 56, 56]               0\n",
      "           Conv2d-11         [128, 256, 56, 56]         295,168\n",
      "             ReLU-12         [128, 256, 56, 56]               0\n",
      "           Conv2d-13         [128, 256, 56, 56]         590,080\u001b[0m\n",
      "\u001b[34mReLU-14         [128, 256, 56, 56]               0\n",
      "           Conv2d-15         [128, 256, 56, 56]         590,080\n",
      "             ReLU-16         [128, 256, 56, 56]               0\n",
      "        MaxPool2d-17         [128, 256, 28, 28]               0\n",
      "           Conv2d-18         [128, 512, 28, 28]       1,180,160\n",
      "             ReLU-19         [128, 512, 28, 28]               0\n",
      "           Conv2d-20         [128, 512, 28, 28]       2,359,808\n",
      "             ReLU-21         [128, 512, 28, 28]               0\n",
      "           Conv2d-22         [128, 512, 28, 28]       2,359,808\n",
      "             ReLU-23         [128, 512, 28, 28]               0\u001b[0m\n",
      "\u001b[34mMaxPool2d-24         [128, 512, 14, 14]               0\n",
      "           Conv2d-25         [128, 512, 14, 14]       2,359,808\n",
      "             ReLU-26         [128, 512, 14, 14]               0\n",
      "           Conv2d-27         [128, 512, 14, 14]       2,359,808\n",
      "             ReLU-28         [128, 512, 14, 14]               0\n",
      "           Conv2d-29         [128, 512, 14, 14]       2,359,808\n",
      "             ReLU-30         [128, 512, 14, 14]               0\n",
      "        MaxPool2d-31           [128, 512, 7, 7]               0\u001b[0m\n",
      "\u001b[34mAdaptiveAvgPool2d-32           [128, 512, 7, 7]               0\n",
      "           Linear-33                [128, 4096]     102,764,544\n",
      "             ReLU-34                [128, 4096]               0\u001b[0m\n",
      "\u001b[34mDropout-35                [128, 4096]               0\n",
      "           Linear-36                [128, 4096]      16,781,312\n",
      "             ReLU-37                [128, 4096]               0\n",
      "          Dropout-38                [128, 4096]               0\n",
      "           Linear-39                 [128, 256]       1,048,832\n",
      "             ReLU-40                 [128, 256]               0\n",
      "          Dropout-41                 [128, 256]               0\n",
      "           Linear-42                   [128, 2]             514\n",
      "       LogSoftmax-43                   [128, 2]               0\u001b[0m\n",
      "\u001b[34m================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 135,309,890\u001b[0m\n",
      "\u001b[34mTrainable params: 1,049,346\u001b[0m\n",
      "\u001b[34mNon-trainable params: 134,260,544\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mInput size (MB): 73.50\u001b[0m\n",
      "\u001b[34mForward/backward pass size (MB): 28003.75\u001b[0m\n",
      "\u001b[34mParams size (MB): 516.17\u001b[0m\n",
      "\u001b[34mEstimated Total Size (MB): 28593.42\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[(0, 'abnormal'), (1, 'normal')]\u001b[0m\n",
      "\u001b[34mtorch.Size([256, 4096])\u001b[0m\n",
      "\u001b[34mtorch.Size([256])\u001b[0m\n",
      "\u001b[34mtorch.Size([2, 256])\u001b[0m\n",
      "\u001b[34mtorch.Size([2])\u001b[0m\n",
      "\u001b[34mStarting Training from Scratch.\u001b[0m\n",
      "\u001b[34mEpoch: 0#011100.00% complete. 2.12 seconds elapsed in epoch.\u001b[0m\n",
      "\u001b[34mVGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "      (4): LogSoftmax(dim=1)\n",
      "    )\n",
      "  )\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34mtrain_loss  valid_loss  train_acc  valid_acc\u001b[0m\n",
      "\u001b[34m0    0.748893    0.690939        0.5        0.5\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:18,549 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:18,549 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-05 13:41:18,550 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-01-05 13:41:37 Uploading - Uploading generated training model\n",
      "2023-01-05 13:42:37 Completed - Training job completed\n",
      "Training seconds: 127\n",
      "Billable seconds: 127\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\":\"s3://xray-nano/nano/train/\" ,\"testing\":\"s3://xray-nano/nano/test/\",\"validating\":\"s3://xray-nano/nano/val/\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "### Create endpoint\n",
    "After training, we use the `PyTorch` estimator object to build and deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `mnist.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `mnist.py`. Here we will deploy the model to a single ```ml.m4.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'framework_version': '1.11.0',\n",
       " 'py_version': 'py38',\n",
       " 'role': 'arn:aws:iam::023180687239:role/service-role/AmazonSageMaker-ExecutionRole-20220906T142944',\n",
       " 'instance_count': 1,\n",
       " 'instance_type': 'ml.c5.2xlarge',\n",
       " 'keep_alive_period_in_seconds': None,\n",
       " 'instance_groups': None,\n",
       " 'volume_size': 30,\n",
       " 'volume_kms_key': None,\n",
       " 'max_run': 86400,\n",
       " 'input_mode': 'File',\n",
       " 'metric_definitions': None,\n",
       " 'model_uri': None,\n",
       " 'model_channel_name': 'model',\n",
       " 'code_uri': None,\n",
       " 'code_channel_name': 'code',\n",
       " 'source_dir': 'code',\n",
       " 'git_config': None,\n",
       " 'container_log_level': 20,\n",
       " '_hyperparameters': {'epochs': 1,\n",
       "  'backend': 'gloo',\n",
       "  'sagemaker_submit_directory': 's3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-01-04-12-17-05-462/source/sourcedir.tar.gz',\n",
       "  'sagemaker_program': 'classifier.py',\n",
       "  'sagemaker_container_log_level': 20,\n",
       "  'sagemaker_job_name': 'pytorch-training-2023-01-04-12-17-05-462',\n",
       "  'sagemaker_region': 'ap-south-1'},\n",
       " 'code_location': None,\n",
       " 'entry_point': 'classifier.py',\n",
       " 'dependencies': ['code/requirements.txt'],\n",
       " 'uploaded_code': UserCode(s3_prefix='s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-01-04-12-17-05-462/source/sourcedir.tar.gz', script_name='classifier.py'),\n",
       " 'tags': None,\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7f0a44b6db50>,\n",
       " 'base_job_name': 'pytorch-training',\n",
       " '_current_job_name': 'pytorch-training-2023-01-04-12-17-05-462',\n",
       " 'output_path': 's3://sagemaker-ap-south-1-023180687239/',\n",
       " 'output_kms_key': None,\n",
       " 'latest_training_job': <sagemaker.estimator._TrainingJob at 0x7f0a44a59d10>,\n",
       " 'jobs': [<sagemaker.estimator._TrainingJob at 0x7f0a44a59d10>],\n",
       " 'deploy_instance_type': None,\n",
       " '_compiled_models': {},\n",
       " 'subnets': None,\n",
       " 'security_group_ids': None,\n",
       " 'encrypt_inter_container_traffic': False,\n",
       " 'use_spot_instances': False,\n",
       " 'max_wait': None,\n",
       " 'checkpoint_s3_uri': None,\n",
       " 'checkpoint_local_path': None,\n",
       " 'rules': None,\n",
       " 'debugger_hook_config': <sagemaker.debugger.debugger.DebuggerHookConfig at 0x7f0a44badb90>,\n",
       " 'tensorboard_output_config': None,\n",
       " 'debugger_rule_configs': [],\n",
       " 'collection_configs': set(),\n",
       " 'enable_sagemaker_metrics': True,\n",
       " '_enable_network_isolation': False,\n",
       " 'profiler_config': <sagemaker.debugger.profiler_config.ProfilerConfig at 0x7f0a44badb10>,\n",
       " 'disable_profiler': False,\n",
       " 'environment': None,\n",
       " 'max_retry_attempts': None,\n",
       " 'profiler_rule_configs': [{'RuleConfigurationName': 'ProfilerReport-1672834625',\n",
       "   'RuleEvaluatorImage': '904829902805.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "   'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       " 'profiler_rules': [ProfilerRule(name='ProfilerReport-1672834625', image_uri='904829902805.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-debugger-rules:latest', instance_type=None, container_local_output_path=None, s3_output_path=None, volume_size_in_gb=None, rule_parameters={'rule_to_invoke': 'ProfilerReport'})],\n",
       " 'debugger_rules': [],\n",
       " 'image_uri': None,\n",
       " 'distribution': {}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.2xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "You can use the test images to evalute the endpoint. The accuracy of the model depends on how many it is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls data/MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "data_dir = \"data/MNIST/raw\"\n",
    "with gzip.open(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "mask = random.sample(range(len(images)), 16)  # randomly select some of the test images\n",
    "mask = np.array(mask, dtype=np.int)\n",
    "data = images[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2529, 8464, 9926, 3929, 6169,  392, 4305, 2118, 4274, 2184, 5513,\n",
       "       3174, 6799, 8376, 3933, 3165])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic = np.random.rand(1,28,28).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endpoint_name': 'pytorch-training-2023-01-03-19-54-01-587',\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7fa3e9d7d450>,\n",
       " 'serializer': <sagemaker.serializers.NumpySerializer at 0x7fa3f1ce0a10>,\n",
       " 'deserializer': <sagemaker.deserializers.NumpyDeserializer at 0x7fa3f1ce0f50>,\n",
       " '_endpoint_config_name': None,\n",
       " '_model_names': None,\n",
       " '_context': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name=predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.predict(pic.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-training-2023-01-04-12-21-19-248'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"'float' object is not subscriptable\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 142, in transform\n    result = self._run_handler_function(\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 276, in _run_handler_function\n    result = func(*argv_context)\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 261, in _default_transform_fn\n    result = self._run_handler_function(self._output_fn, *(prediction, accept))\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 272, in _run_handler_function\n    result = func(*argv)\n  File \"/opt/ml/model/code/classifier.py\", line 579, in output_fn\n    res = finding.numpy().tolist()[0][1] * 100\nTypeError: 'float' object is not subscriptable\n\". See https://ap-south-1.console.aws.amazon.com/cloudwatch/home?region=ap-south-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2023-01-04-07-50-38-935 in account 023180687239 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-62b680a47c51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mAccept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"'float' object is not subscriptable\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 142, in transform\n    result = self._run_handler_function(\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 276, in _run_handler_function\n    result = func(*argv_context)\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 261, in _default_transform_fn\n    result = self._run_handler_function(self._output_fn, *(prediction, accept))\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 272, in _run_handler_function\n    result = func(*argv)\n  File \"/opt/ml/model/code/classifier.py\", line 579, in output_fn\n    res = finding.numpy().tolist()[0][1] * 100\nTypeError: 'float' object is not subscriptable\n\". See https://ap-south-1.console.aws.amazon.com/cloudwatch/home?region=ap-south-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2023-01-04-07-50-38-935 in account 023180687239 for more information."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "custom_attributes = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.\n",
    "endpoint_name = predictor.endpoint_name                                        # Your endpoint name.\n",
    "content_type = \"application/json\"                                        # The MIME type of the input data in the request body.\n",
    "accept = \"application/json\"                                              # The desired MIME type of the inference in the response.\n",
    "payload = json.dumps({\"url\":\"https://storage.googleapis.com/kaggle-datasets-images/17810/23340/c8372ebbe20b0f671c2f3c501ba51412/dataset-cover.jpeg?t=2018-03-24-19-05-18\"})                                           # Payload for inference.\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    CustomAttributes=custom_attributes, \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=payload\n",
    "    )\n",
    "\n",
    "print(response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Body': <botocore.response.StreamingBody object at 0x7fa3f1248510>,\n",
      " 'ContentType': 'application/json',\n",
      " 'InvokedProductionVariant': 'AllTraffic',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '44',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'date': 'Wed, 04 Jan 2023 07:09:13 GMT',\n",
      "                                      'x-amzn-invoked-production-variant': 'AllTraffic',\n",
      "                                      'x-amzn-requestid': 'ae76167e-0d2e-4290-8b44-0ddba80d6efd'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'ae76167e-0d2e-4290-8b44-0ddba80d6efd',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = json.load(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.7822648286819458, -0.6113256812095642]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exp() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-96370e1c52a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: exp() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "torch.exp(torch.tensor(r), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, pred = torch.max(torch.tensor(r), dim=1)\n",
    "res = list(pred.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "result.append(\n",
    "    {\n",
    "        \"name\":\"class\",\n",
    "        \"probability\":int(res)\n",
    "    }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\": \"class\", \"probability\": 1}]'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.0102062225341797,\n",
       " -2.48018217086792,\n",
       " -1.5776013135910034,\n",
       " -2.6531476974487305,\n",
       " -3.039762020111084,\n",
       " -1.8981196880340576,\n",
       " -2.262784481048584,\n",
       " -4.358467102050781,\n",
       " -1.3877885341644287,\n",
       " -3.6531260013580322]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.FloatTensor(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic.astype(\"float32\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.tensor(pic, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image.open(req.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(request_body, content_type='application/json'):\n",
    "    logger.info('Deserializing the input data.')\n",
    "    import requests\n",
    "    import numpy as np\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        url = input_data['url']\n",
    "        logger.info(f'Image url: {url}')\n",
    "        # resp = requests.get(url, stream=True)\n",
    "        # raw_data = resp.raw\n",
    "        image_data = Image.open(requests.get(url, stream=True).raw)\n",
    "        \n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(size=28),\n",
    "        ])\n",
    "        # logger.debug(\"image_data - {}\",image_data)\n",
    "        # data = image_transform(image_data)\n",
    "        # # logger.debug(\"data - {}\",data)\n",
    "        # data = np.asarray(data)\n",
    "        # # logger.debug(\"data - {}\",data)\n",
    "        # data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "        # logger.debug(\"data - {}\",data)\n",
    "        return image_transform(image_data)\n",
    "    raise Exception(f'Requested unsupported ContentType in content_type {content_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging,sys\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image url: http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\n",
      "<PIL.Image.Image image mode=L size=353x370 at 0x7EFC7F3B8990>\n",
      "torch.Size([1, 28, 28])\n",
      "(1, 28, 28)\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "request_body = json.dumps({\"url\":\"http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\"})    \n",
    "input_data = json.loads(request_body)\n",
    "url = input_data['url']\n",
    "logger.info(f'Image url: {url}')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# resp = requests.get(url, stream=True)\n",
    "# raw_data = resp.raw\n",
    "image_data = Image.open(requests.get(url, stream=True).raw).convert('L')\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28,28)),\n",
    "])\n",
    "print(image_data)\n",
    "data = image_transform(image_data)\n",
    "print(data.shape)\n",
    "data = np.asarray(data)\n",
    "print(data.shape)\n",
    "data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=353x370>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-03 21:49:40--  https://storage.googleapis.com/kaggle-datasets-images/17810/23340/c8372ebbe20b0f671c2f3c501ba51412/dataset-cover.jpeg\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.199.144, 142.251.42.16, 142.250.192.144, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.199.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 93874 (92K) [application/octet-stream]\n",
      "Saving to: dataset-cover.jpeg\n",
      "\n",
      "dataset-cover.jpeg  100%[===================>]  91.67K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-01-03 21:49:41 (80.5 MB/s) - dataset-cover.jpeg saved [93874/93874]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/kaggle-datasets-images/17810/23340/c8372ebbe20b0f671c2f3c501ba51412/dataset-cover.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://storage.googleapis.com/kaggle-datasets-images/17810/23340/c8372ebbe20b0f671c2f3c501ba51412/dataset-cover.jpeg\"\n",
    "url = \"https://www.kaggleusercontent.com/kf/114432031/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..QDlIFpCmsY1lOtG3JjWYEg.3QqjXoq-eoCUdtbkMVC6T4ILiSZXRWGSTGisTiy3NlMEyG8DGeyh9wmbHIFapJjdr1o8ONPZ2dfi2oEpuwp4kw5QH5JQRa469N3JONkv6lSLAPrrSWjCR6aawsVvGxOKzFPkUha2POTddDeSfYq4qVM8RryXdbDq9fuyKIRs8ob51CkDKm5CIM-t3Nc0BgS_3rm7KvcbmL-n5c-SpRQFsKaQJiqvV2kiQ2C-SIKpbvjrlLGIm9Jt15PyzhNy2NGtbtPlUcUF5sA4-IzlGN30ADNDye2d0hr5yEnwfShofnsqiTzPyLT8_dT7WrLxACsgLGodRoPDTcdPvh8JUzBmxXAdKWqdQgzQrmda15Z_h1bMyhGkwRHQPDooazrGn3v-fXmd5hN7OXALNyiUA-N6p9tIp5HEsf8u_NtsmoUCP1CmPNvhrETxVrNDxgFWGwzhM89_VhvLGY8ZvNKrsq0NmZFjxNA1UHANEw6SmVlTuKOlCHqV0GcTF1EBngRHFs1eYVzOHc6m7XQsJwbQIbqbmO9CydppLjG4DDkdQNVr0HuWJx6hzGq62a7xKrpZmzv2iOrefGXP1FpvG9XWWv2sFTLz5TSDguSRiHKG7aJjwQm9mURYwtci_DKuASoLjGxJajECPN4OWrrK8ILu3OmcCA.PWMiCPeb81WNIwZCvhh9sQ/__results___files/__results___22_0.png\"\n",
    "image_data = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "# image_data = Image.open(\"./NORMAL/IM-0117-0001.jpeg\").convert(\"RGB\")\n",
    "# print(data.shape)\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data = image_transform(image_data)\n",
    "print(data.shape)\n",
    "print(data.shape)\n",
    "data = np.asarray(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150528"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224*224*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (default, Aug 18 2020, 06:24:24) \n[GCC 5.4.0 20160609]"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "vscode": {
   "interpreter": {
    "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
