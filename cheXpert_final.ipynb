{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheXpert : A Large Chest X-Ray Dataset and Competition\n",
    "\n",
    "This competition launched by the Stanford ML group aims at finding a prediction model which could perform as well as radiologist to find different pathologies thanks to chest X-Ray. The Dataset available to train our model is composed of 223,414 chest radiographs of 65,240 patients.\n",
    "\n",
    "<img src=\"view1_frontal.jpg\" title=\"X-Ray image of the dataset\" width = 320/>\n",
    "\n",
    "The website of the competition:\n",
    "https://stanfordmlgroup.github.io/competitions/chexpert/\n",
    "\n",
    "[Publication](https://arxiv.org/pdf/1901.07031.pdf) : Irvin, Jeremy, et al. \"CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison.\" arXiv preprint arXiv:1901.07031 (2019).\n",
    "\n",
    "Our goal is first to reproduce main results obtained in the related paper, published in January 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (9.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2023.5.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "we used this open source https://www.kaggle.com/code/dnik007/pneumonia-detection-using-pytorch notebook.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d8c743d9-fa39-401d-bc3f-068c4de0f4bc'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "metadata = json.load(open(\"/opt/ml/metadata/resource-metadata.json\",\"r\"))\n",
    "bucket = metadata[\"UserProfileName\"]\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d8c743d9-fa39-401d-bc3f-068c4de0f4bc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/032589a4-c0d1-4c0f-800a-c6fd1240dd3b.dcm\n",
      "data/040ff12f-69ad-4d1a-841b-c673ef6c5d2c.dcm\n",
      "data/0920549b-04a4-4498-b2b0-9332172d1f98.dcm\n",
      "data/18d72409-7efc-4474-a5fa-aa97af261294.dcm\n",
      "data/3a4ceefe-2221-47f7-a466-61a9ac4d64a8.dcm\n",
      "data/4eba5c9e-789b-4aa8-b00e-b0cc80fb63fb.dcm\n",
      "data/9ca7eb21-c0ed-4a70-b8ba-8c4b9feb6679.dcm\n",
      "data/c65463a8-2d58-4808-9f92-288e01e0c752.dcm\n",
      "data/fd18212d-fe44-42e5-9e44-ef187947ba09.dcm\n",
      "labels/labels.csv\n",
      "labels/rois.json\n"
     ]
    }
   ],
   "source": [
    "from boto3 import client\n",
    "\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/032589a4-c0d1-4c0f-800a-c6fd1240dd3b.dcm\n",
      "data/040ff12f-69ad-4d1a-841b-c673ef6c5d2c.dcm\n",
      "data/0920549b-04a4-4498-b2b0-9332172d1f98.dcm\n",
      "data/18d72409-7efc-4474-a5fa-aa97af261294.dcm\n",
      "data/3a4ceefe-2221-47f7-a466-61a9ac4d64a8.dcm\n",
      "data/4eba5c9e-789b-4aa8-b00e-b0cc80fb63fb.dcm\n",
      "data/9ca7eb21-c0ed-4a70-b8ba-8c4b9feb6679.dcm\n",
      "data/c65463a8-2d58-4808-9f92-288e01e0c752.dcm\n",
      "data/fd18212d-fe44-42e5-9e44-ef187947ba09.dcm\n",
      "labels/labels.csv\n",
      "labels/rois.json\n"
     ]
    }
   ],
   "source": [
    "# Downloading Data from S3\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from boto3 import client\n",
    "import os\n",
    "os.mkdir(\"data\")\n",
    "os.mkdir(\"labels\")\n",
    "\n",
    "BUCKET_NAME = bucket\n",
    "c = 0\n",
    "conn = client('s3') \n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])\n",
    "    KEY = key['Key']\n",
    "    s3 = boto3.resource('s3')\n",
    "    try:\n",
    "        s3.Bucket(BUCKET_NAME).download_file(KEY, f\"{key['Key']}\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise\n",
    "    c = c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Downloading pydicom-2.4.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "Successfully installed pydicom-2.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dcm to Png\n",
    "!pip install pydicom\n",
    "import pydicom as dicom\n",
    "import pydicom\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    try:\n",
    "        print(\"Converting to PNG .........................\")\n",
    "        dicom = dcmread(path, force=True)\n",
    "        print(dicom.SOPInstanceUID, \">>>>>>\", dicom.StudyInstanceUID, \">>>>>\", dicom.SeriesInstanceUID)\n",
    "        #if voi_lut:\n",
    "        if voi_lut and len(dicom.get(\"VOILUTSequence\", [])):\n",
    "            data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "        else:\n",
    "            data = dicom.pixel_array\n",
    "        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.amax(data) - data\n",
    "        data = data - np.min(data)\n",
    "        data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data,dicom.PatientName\n",
    "    except Exception as e:\n",
    "        print(e, \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        return \"corrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/4eba5c9e-789b-4aa8-b00e-b0cc80fb63fb.dcm', 'data/0920549b-04a4-4498-b2b0-9332172d1f98.dcm', 'data/9ca7eb21-c0ed-4a70-b8ba-8c4b9feb6679.dcm', 'data/3a4ceefe-2221-47f7-a466-61a9ac4d64a8.dcm', 'data/fd18212d-fe44-42e5-9e44-ef187947ba09.dcm', 'data/040ff12f-69ad-4d1a-841b-c673ef6c5d2c.dcm', 'data/c65463a8-2d58-4808-9f92-288e01e0c752.dcm', 'data/032589a4-c0d1-4c0f-800a-c6fd1240dd3b.dcm', 'data/18d72409-7efc-4474-a5fa-aa97af261294.dcm']\n",
      "\n",
      ">>>  data/4eba5c9e-789b-4aa8-b00e-b0cc80fb63fb.dcm\n",
      "Converting to PNG .........................\n",
      "7.75.127.2213.34985.182878.2238976.92445292603243981835950856844 >>>>>> 2.26.561.4315.38258.861765.1698238.79971011959563664463723573308 >>>>> 6.34.865.9031.65036.876305.5576424.64805983867070419757851484197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> filename 4eba5c9e-789b-4aa8-b00e-b0cc80fb63fb.dcm\n",
      "1 Done\n",
      "\n",
      ">>>  data/0920549b-04a4-4498-b2b0-9332172d1f98.dcm\n",
      "Converting to PNG .........................\n",
      "3.10.595.5462.33591.213904.9243936.83355519274813503168608186305 >>>>>> 5.41.642.2793.11955.920385.3813713.65744642995283665667428017730 >>>>> 2.71.812.1365.33274.551984.8630413.87459922697791443883158205808\n",
      "\n",
      ">> filename 0920549b-04a4-4498-b2b0-9332172d1f98.dcm\n",
      "2 Done\n",
      "\n",
      ">>>  data/9ca7eb21-c0ed-4a70-b8ba-8c4b9feb6679.dcm\n",
      "Converting to PNG .........................\n",
      "7.20.175.9078.56360.275266.3358278.57849115639277914288215926872 >>>>>> 1.86.711.5694.23884.235814.2324468.17132268458518492307196413739 >>>>> 1.39.761.9041.15678.376046.9093818.94498639667639194474579560833\n",
      "\n",
      ">> filename 9ca7eb21-c0ed-4a70-b8ba-8c4b9feb6679.dcm\n",
      "3 Done\n",
      "\n",
      ">>>  data/3a4ceefe-2221-47f7-a466-61a9ac4d64a8.dcm\n",
      "Converting to PNG .........................\n",
      "9.36.180.4531.75556.414590.4094866.31964101540721378913635535495 >>>>>> 7.39.190.7770.15802.706866.7064726.62775422404349927760160375739 >>>>> 9.74.593.5199.96755.799600.2905466.28857734540301808647298242481\n",
      "\n",
      ">> filename 3a4ceefe-2221-47f7-a466-61a9ac4d64a8.dcm\n",
      "4 Done\n",
      "\n",
      ">>>  data/fd18212d-fe44-42e5-9e44-ef187947ba09.dcm\n",
      "Converting to PNG .........................\n",
      "8.51.134.4009.28449.114862.9753855.87844830351920371638636570758 >>>>>> 6.47.433.5951.69303.740620.5024974.86325227258561545619631609345 >>>>> 4.93.876.9773.44775.888514.7473518.88577814296687332892431048513\n",
      "\n",
      ">> filename fd18212d-fe44-42e5-9e44-ef187947ba09.dcm\n",
      "5 Done\n",
      "\n",
      ">>>  data/040ff12f-69ad-4d1a-841b-c673ef6c5d2c.dcm\n",
      "Converting to PNG .........................\n",
      "8.46.805.1658.93243.739812.1950527.52767969944417107544682544821 >>>>>> 3.25.639.9624.60891.908848.1133013.29224464766735133525506823554 >>>>> 7.88.440.3091.88587.358555.1927038.13161765214780355033207153143\n",
      "\n",
      ">> filename 040ff12f-69ad-4d1a-841b-c673ef6c5d2c.dcm\n",
      "6 Done\n",
      "\n",
      ">>>  data/c65463a8-2d58-4808-9f92-288e01e0c752.dcm\n",
      "Converting to PNG .........................\n",
      "1.67.355.8835.11836.344493.5709976.38071397966598555607909175232 >>>>>> 5.30.143.2195.51539.564465.4182368.38009059141895062105270273634 >>>>> 4.34.850.2310.88017.304763.7364900.98988340040472327424492887326\n",
      "\n",
      ">> filename c65463a8-2d58-4808-9f92-288e01e0c752.dcm\n",
      "7 Done\n",
      "\n",
      ">>>  data/032589a4-c0d1-4c0f-800a-c6fd1240dd3b.dcm\n",
      "Converting to PNG .........................\n",
      "1.26.156.2806.65717.873202.5176341.38799230901738109657213828823 >>>>>> 6.42.185.8295.15199.978388.6046825.48050093409996582574005321569 >>>>> 8.69.758.7064.66779.385911.9434388.74896316936080873585778997341\n",
      "\n",
      ">> filename 032589a4-c0d1-4c0f-800a-c6fd1240dd3b.dcm\n",
      "8 Done\n",
      "\n",
      ">>>  data/18d72409-7efc-4474-a5fa-aa97af261294.dcm\n",
      "Converting to PNG .........................\n",
      "4.41.940.1632.32863.341769.6852011.43731798152302026947913225320 >>>>>> 3.73.860.9192.16202.831749.3290149.62853582098330515541855997407 >>>>> 5.39.535.9644.58192.153962.4748727.18836796559220484131335689531\n",
      "\n",
      ">> filename 18d72409-7efc-4474-a5fa-aa97af261294.dcm\n",
      "9 Done\n"
     ]
    }
   ],
   "source": [
    "# convert dicoms to png and store in training_data_png\n",
    "\n",
    "from glob import glob\n",
    "files_ = glob('data/*.dcm',recursive=True)\n",
    "try:\n",
    "    os.mkdir(\"training_data_png\")\n",
    "except:\n",
    "    pass\n",
    "print(files_)\n",
    "c = 0\n",
    "for i in files_:\n",
    "    try:\n",
    "        print(\"\\n>>> \",i)\n",
    "        img,patientname = read_xray(i)\n",
    "        with open(\"filename.pkl\", 'wb') as f:\n",
    "            pickle.dump(img, f)\n",
    "        ims = pickle.load(open(\"filename.pkl\", \"rb\"))\n",
    "        norm = (ims.astype(np.float) - ims.min()) * 255.0 / (ims.max() - ims.min())\n",
    "        filename = str(i).split(\"/\")[1].split(\"_\")[0]\n",
    "        print(\"\\n>> filename\",filename)\n",
    "        Image.fromarray(norm.astype(np.uint8)).save(f\"training_data_png/{filename}.png\")\n",
    "        c = c + 1\n",
    "        print(c, \"Done\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Case Number Patient ID Patient Name  \\\n",
      "0  1  Case 10375  ssss-0006    ssss-0006   \n",
      "1  2  Case 10377  ssss-0008    ssss-0008   \n",
      "2  3  Case 10378  ssss-0009    ssss-0009   \n",
      "3  4  Case 10374  ssss-0005    ssss-0005   \n",
      "4  5  Case 10373  ssss-0004    ssss-0004   \n",
      "5  6  Case 10370       Anon        AA001   \n",
      "6  7  Case 10371  ssss-0002    ssss-0002   \n",
      "7  8  Case 10376  ssss-0007    ssss-0007   \n",
      "8  9  Case 10372  ssss-0003    ssss-0003   \n",
      "\n",
      "                                    StudyInstanceUID           User  Comments  \\\n",
      "0  3.73.860.9192.16202.831749.3290149.62853582098...  sudo@carpl.ai       NaN   \n",
      "1  1.86.711.5694.23884.235814.2324468.17132268458...  sudo@carpl.ai       NaN   \n",
      "2  6.42.185.8295.15199.978388.6046825.48050093409...  sudo@carpl.ai       NaN   \n",
      "3  3.25.639.9624.60891.908848.1133013.29224464766...  sudo@carpl.ai       NaN   \n",
      "4  7.39.190.7770.15802.706866.7064726.62775422404...  sudo@carpl.ai       NaN   \n",
      "5  1.2.840.113619.2.203.4.2147483647.1474011852.1...  sudo@carpl.ai       NaN   \n",
      "6  5.30.143.2195.51539.564465.4182368.38009059141...  sudo@carpl.ai       NaN   \n",
      "7  5.41.642.2793.11955.920385.3813713.65744642995...  sudo@carpl.ai       NaN   \n",
      "8  6.47.433.5951.69303.740620.5024974.86325227258...  sudo@carpl.ai       NaN   \n",
      "\n",
      "  test  \n",
      "0  yes  \n",
      "1   no  \n",
      "2  yes  \n",
      "3  yes  \n",
      "4   no  \n",
      "5  yes  \n",
      "6   no  \n",
      "7   no  \n",
      "8  yes  \n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "labels = pd.read_csv(\"./labels/labels.csv\",header=1)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_ = glob('training_data_png/*.png',recursive=True)\n",
    "\n",
    "for file in files_:\n",
    "    sagemaker_session.upload_data(path=file  , bucket=bucket, key_prefix=\"data/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `classifier.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of gpus available in the current container.\n",
    "* `SM_CURRENT_HOST`: The name of the current container on the container network.\n",
    "* `SM_HOSTS`: JSON encoded list containing all the hosts .\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (``if __name__=='__main__':``) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcv2\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbackends\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcudnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mcudnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtransforms\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtransforms\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtfunc\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dataset\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdataset\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m random_split\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlr_scheduler\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ReduceLROnPlateau\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mfunc\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m roc_auc_score\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmetrics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mcopy\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m deepcopy\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m cuda\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtimeit\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m default_timer \u001b[34mas\u001b[39;49;00m timer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms, models\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader, sampler\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshlex\u001b[39;49;00m, \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchsummary\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m summary\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpydicom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m densenet121\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "class_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mNo Finding\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEnlarged Cardiomediastinum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCardiomegaly\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Opacity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Lesion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEdema\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mConsolidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumonia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAtelectasis\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumothorax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Effusion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Other\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mFracture\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSupport Devices\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "nnClassCount = \u001b[34m14\u001b[39;49;00m \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mfind_file_path\u001b[39;49;00m(filename):\u001b[37m\u001b[39;49;00m\n",
      "    file_path = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m path \u001b[35min\u001b[39;49;00m glob.glob(\u001b[33m'\u001b[39;49;00m\u001b[33m**/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + filename, recursive=\u001b[34mTrue\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m file_path \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            file_path = os.path.abspath(path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mbreak\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m file_path\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[33m''' INFERENCING'''\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_json\u001b[39;49;00m(coord,og_img_size):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# final_coord = [[(coord[x]+16)*(og_img_size[0]/256),(coord[y]+16)*(og_img_size[1]/256)] for x,y in zip(list(range(0,len(coord),2)),list(range(1,len(coord),2)))]\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    final_coord = [[coord[x],coord[y]] \u001b[34mfor\u001b[39;49;00m x,y \u001b[35min\u001b[39;49;00m \u001b[36mzip\u001b[39;49;00m(\u001b[36mlist\u001b[39;49;00m(\u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m,\u001b[36mlen\u001b[39;49;00m(coord),\u001b[34m2\u001b[39;49;00m)),\u001b[36mlist\u001b[39;49;00m(\u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m,\u001b[36mlen\u001b[39;49;00m(coord),\u001b[34m2\u001b[39;49;00m)))]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#final_coord = np.array(final_coord)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m(final_coord)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_coord_dict\u001b[39;49;00m(cont_new):\u001b[37m\u001b[39;49;00m\n",
      "    final_pairs = get_pairs(cont_new)\u001b[37m\u001b[39;49;00m\n",
      "    line_list = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m,\u001b[36mlen\u001b[39;49;00m(final_pairs)):\u001b[37m\u001b[39;49;00m\n",
      "        coord_cur,coord_after = final_pairs[i][\u001b[34m0\u001b[39;49;00m],final_pairs[i][\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        z = {\u001b[33m'\u001b[39;49;00m\u001b[33mactive\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mhighlight\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mlines\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [{\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_after[\u001b[34m0\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_after[\u001b[34m1\u001b[39;49;00m]}],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_cur[\u001b[34m0\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_cur[\u001b[34m1\u001b[39;49;00m]}\u001b[37m\u001b[39;49;00m\n",
      "        line_list.append(z)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m line_list\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_1D_coord\u001b[39;49;00m(contours):\u001b[37m\u001b[39;49;00m\n",
      "    global_list=[]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m contour_id \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(contours)):\u001b[37m\u001b[39;49;00m\n",
      "        local_list=[]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m point_idx \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(contours[contour_id].shape[\u001b[34m0\u001b[39;49;00m]):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m(point_idx==\u001b[34m0\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                X_0= contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                Y_0 = contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            X = contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            Y = contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            local_list.append(X)\u001b[37m\u001b[39;49;00m\n",
      "            local_list.append(Y)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# If the last point is reached, then append the first point\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m(point_idx == contours[contour_id].shape[\u001b[34m0\u001b[39;49;00m]-\u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                local_list.append(X_0)\u001b[37m\u001b[39;49;00m\n",
      "                local_list.append(Y_0)\u001b[37m\u001b[39;49;00m\n",
      "        global_list.append(deepcopy(local_list))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m(global_list)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mthreshold\u001b[39;49;00m(minimum,maximum,image,binary=\u001b[34mTrue\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m(binary): \u001b[37m# If binary is True, then the image is converted to binary\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image<minimum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image>maximum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[(image>\u001b[34m0\u001b[39;49;00m)]=\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m: \u001b[37m# If binary is False, then the image is converted to grayscale\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image<minimum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image>maximum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m image\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_pairs\u001b[39;49;00m(cont_new):\u001b[37m\u001b[39;49;00m\n",
      "    pairs=[]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m,cont_new.shape[\u001b[34m0\u001b[39;49;00m]):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m (i < (cont_new.shape[\u001b[34m0\u001b[39;49;00m]-\u001b[34m1\u001b[39;49;00m)):\u001b[37m\u001b[39;49;00m\n",
      "            pairs.append((cont_new[i],cont_new[i+\u001b[34m1\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            pairs.append((cont_new[i],cont_new[\u001b[34m0\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m(pairs)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m densenet121\u001b[37m\u001b[39;49;00m\n",
      "    IMAGENET_MEAN = np.array([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    IMAGENET_STD = np.array([\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    model =  ChexNet()\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    f = \u001b[33m\"\u001b[39;49;00m\u001b[33mmodele.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m>>>>>>>>>>>>>>> model dir >>>>>>>>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(model_dir)\u001b[37m\u001b[39;49;00m\n",
      "    model_def_path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.isfile(model_def_path):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mfile not found in \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_def_path\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMissing the model definition file\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# model = torch.nn.DataParallel(model)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    modelCheckpoint = torch.load(model_def_path)\u001b[37m\u001b[39;49;00m\n",
      "    model.load_state_dict(modelCheckpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    model.eval()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    torch.save(model, path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:    \u001b[37m\u001b[39;49;00m\n",
      "        input_data = json.loads(request_body)\u001b[37m\u001b[39;49;00m\n",
      "        url = input_data[\u001b[33m'\u001b[39;49;00m\u001b[33murl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mImage url: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00murl\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        image_data = Image.open(requests.get(url, stream=\u001b[34mTrue\u001b[39;49;00m).raw).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        image_transform = transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "            transforms.Resize(size=\u001b[34m224\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "            transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        ])\u001b[37m\u001b[39;49;00m\n",
      "        data = image_transform(image_data)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[36mstr\u001b[39;49;00m(data.shape))\u001b[37m\u001b[39;49;00m\n",
      "        data = torch.tensor(data, dtype=torch.float32, device=device).unsqueeze(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[36mstr\u001b[39;49;00m(data.shape))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m [data, image_data.size]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcontent_type\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_object, model):\u001b[37m\u001b[39;49;00m\n",
      "    input_object, og_img_size = input_object\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[36mstr\u001b[39;49;00m(input_object.shape))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# logger.info(model.classifier)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        output = model.backbone(input_object)\u001b[37m\u001b[39;49;00m\n",
      "        l = model.forward(input_object)\u001b[37m\u001b[39;49;00m\n",
      "        l = torch.sigmoid(l)\u001b[37m\u001b[39;49;00m\n",
      "        heatmap = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        weights = \u001b[36mlist\u001b[39;49;00m(model.backbone.parameters())[-\u001b[34m2\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m (\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(weights)):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mmap\u001b[39;49;00m = output[\u001b[34m0\u001b[39;49;00m,i,:,:]\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m i == \u001b[34m0\u001b[39;49;00m: \u001b[37m\u001b[39;49;00m\n",
      "                heatmap = weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m: \u001b[37m\u001b[39;49;00m\n",
      "                heatmap += weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            npHeatmap = heatmap.cpu().data.numpy()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m [output,l,npHeatmap, og_img_size]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(predictions, content_type):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34massert\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    output,l,npHeatmap,og_img_size = predictions\u001b[37m\u001b[39;49;00m\n",
      "    heatmap = npHeatmap\u001b[37m\u001b[39;49;00m\n",
      "    heatmap = ((heatmap - heatmap.min()) * (\u001b[34m1\u001b[39;49;00m / (heatmap.max() - heatmap.min())) * \u001b[34m255\u001b[39;49;00m).astype(np.uint8)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# cam = npHeatmap / np.max(npHeatmap)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    cam = cv2.resize(heatmap, og_img_size)\u001b[37m\u001b[39;49;00m\n",
      "    heatmap = cam\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- Blend original and heatmap \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    temp = heatmap.copy()\u001b[37m\u001b[39;49;00m\n",
      "    img = temp\u001b[37m#[:,:,0]\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# img = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(img.min())\u001b[37m\u001b[39;49;00m\n",
      "    img = (img/\u001b[34m1\u001b[39;49;00m).astype(\u001b[33m'\u001b[39;49;00m\u001b[33muint8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    binary = threshold(\u001b[34m220\u001b[39;49;00m,img.max(),img)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# binary = binary.astype(np.int32)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    contours, _ = cv2.findContours(binary,cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE) \u001b[37m\u001b[39;49;00m\n",
      "    sorted_contours = \u001b[36msorted\u001b[39;49;00m(contours, key=cv2.contourArea, reverse=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    contours = sorted_contours[:\u001b[34m4\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    coords = get_1D_coord(contours)\u001b[37m\u001b[39;49;00m\n",
      "    data_final = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m coord \u001b[35min\u001b[39;49;00m coords:\u001b[37m\u001b[39;49;00m\n",
      "        data_final.append(get_json(coord,og_img_size))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mFINAL JSON\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    output = response_converter(l.tolist(),data_final)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(output)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mresponse_converter\u001b[39;49;00m(labels,coords):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(labels,coords)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    THIS IS A CUSTOM RESPONSE CCONVERTER\u001b[39;49;00m\n",
      "\u001b[33m    CARPL EXPECTS OUTPUT IN THIS FORMAT:\u001b[39;49;00m\n",
      "\u001b[33m    {\u001b[39;49;00m\n",
      "\u001b[33m        \"response\": {\u001b[39;49;00m\n",
      "\u001b[33m            \"findings\":[\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_A\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_A\u001b[39;49;00m\n",
      "\u001b[33m                },\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_B\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_B\u001b[39;49;00m\n",
      "\u001b[33m                }\u001b[39;49;00m\n",
      "\u001b[33m            ],\u001b[39;49;00m\n",
      "\u001b[33m            \"rois\":[\u001b[39;49;00m\n",
      "\u001b[33m                    {\u001b[39;49;00m\n",
      "\u001b[33m                        \"finding_name\":\"class1\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"type\":\"Rectangle\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"points\":[\u001b[39;49;00m\n",
      "\u001b[33m                            [50,300],\u001b[39;49;00m\n",
      "\u001b[33m                            [100,200]\u001b[39;49;00m\n",
      "\u001b[33m                        ]\u001b[39;49;00m\n",
      "\u001b[33m                    },\u001b[39;49;00m\n",
      "\u001b[33m                    {\u001b[39;49;00m\n",
      "\u001b[33m                        \"finding_name\":\"class2\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"type\":\"Freehand\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"points\":[\u001b[39;49;00m\n",
      "\u001b[33m                            [500,300],\u001b[39;49;00m\n",
      "\u001b[33m                            [500,320],\u001b[39;49;00m\n",
      "\u001b[33m                            [500,420],\u001b[39;49;00m\n",
      "\u001b[33m                            [800,420],\u001b[39;49;00m\n",
      "\u001b[33m                            [800,370],\u001b[39;49;00m\n",
      "\u001b[33m                            [800,320]\u001b[39;49;00m\n",
      "\u001b[33m                        ]\u001b[39;49;00m\n",
      "\u001b[33m                    }\u001b[39;49;00m\n",
      "\u001b[33m                ]\u001b[39;49;00m\n",
      "\u001b[33m        }\u001b[39;49;00m\n",
      "\u001b[33m    }\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    class_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mNo Finding\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEnlarged Cardiomediastinum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCardiomegaly\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Opacity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Lesion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEdema\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mConsolidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumonia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAtelectasis\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumothorax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Effusion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Other\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mFracture\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSupport Devices\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mresponse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m : {\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mfindings\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:[{\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:class_names[e],\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprobability\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:l\u001b[37m\u001b[39;49;00m\n",
      "                } \u001b[34mfor\u001b[39;49;00m e,l \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(labels[\u001b[34m0\u001b[39;49;00m])],\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mrois\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:[\u001b[37m\u001b[39;49;00m\n",
      "                    {\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mfinding_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mAbnormality\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mFreehand\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mpoints\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:coords[e],\u001b[37m\u001b[39;49;00m\n",
      "                    } \u001b[34mfor\u001b[39;49;00m e,l \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(coords)\u001b[37m\u001b[39;49;00m\n",
      "                ]\u001b[37m\u001b[39;49;00m\n",
      "            }\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mCheXpertDataSet\u001b[39;49;00m(Dataset):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, image_list_file, transform=\u001b[34mNone\u001b[39;49;00m, policy=\u001b[33m\"\u001b[39;49;00m\u001b[33mones\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        image_list_file: path to the file containing images with corresponding labels.\u001b[39;49;00m\n",
      "\u001b[33m        transform: optional transform to be applied on a sample.\u001b[39;49;00m\n",
      "\u001b[33m        Upolicy: name the policy with regard to the uncertain labels\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image_names = glob.glob(image_list_file+\u001b[33m\"\u001b[39;49;00m\u001b[33m/*.png\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,recursive = \u001b[34mTrue\u001b[39;49;00m )\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m\u001b[39;49;00m\n",
      "        labels = np.ones((\u001b[36mlen\u001b[39;49;00m(image_names),nnClassCount))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.image_names = image_names\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.labels = labels\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.transform = transform\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, index):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"Take the index of item and returns the image and its labels\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        image_name = \u001b[36mself\u001b[39;49;00m.image_names[index]\u001b[37m\u001b[39;49;00m\n",
      "        image = Image.open(image_name).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        label = \u001b[36mself\u001b[39;49;00m.labels[index]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.transform \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            image = \u001b[36mself\u001b[39;49;00m.transform(image)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m image, torch.FloatTensor(label)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__len__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.image_names)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mCheXpertTrainer\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m (model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, launchTimestamp, checkpoint, save_path):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#SETTINGS: OPTIMIZER & SCHEDULER\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        optimizer = optim.Adam (model.parameters(), lr=\u001b[34m0.0001\u001b[39;49;00m, betas=(\u001b[34m0.9\u001b[39;49;00m, \u001b[34m0.999\u001b[39;49;00m), eps=\u001b[34m1e-08\u001b[39;49;00m, weight_decay=\u001b[34m1e-5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#SETTINGS: LOSS\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        loss = torch.nn.CrossEntropyLoss()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#LOAD CHECKPOINT \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m checkpoint != \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            state_dict = torch.load(checkpoint)\u001b[37m\u001b[39;49;00m\n",
      "            model.load_state_dict(state_dict)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m>>>>>>>>>>>>>>>>>>> MODEL LOADED SUCCESSFULLY >>>>>>>>>>>>>>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#TRAIN THE NETWORK\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        lossMIN = \u001b[34m100000\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        epochID = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        lossMIN = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        torch.save({\u001b[33m'\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epochID + \u001b[34m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.state_dict(), \u001b[33m'\u001b[39;49;00m\u001b[33mbest_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: lossMIN, \u001b[33m'\u001b[39;49;00m\u001b[33moptimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m : optimizer.state_dict()}, save_path +  \u001b[33m\"\u001b[39;49;00m\u001b[33m/model.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m epochID \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m, trMaxEpoch):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            timestampTime = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampDate = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampSTART = timestampDate + \u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampTime\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            batchs, losst, losse = CheXpertTrainer.epochTrain(model, dataLoaderTrain, dataLoaderVal, optimizer, trMaxEpoch, nnClassCount, loss)\u001b[37m\u001b[39;49;00m\n",
      "            lossVal = CheXpertTrainer.epochVal(model, dataLoaderVal, optimizer, trMaxEpoch, nnClassCount, loss)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            timestampTime = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampDate = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampEND = timestampDate + \u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampTime\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m lossVal < lossMIN:\u001b[37m\u001b[39;49;00m\n",
      "                lossMIN = lossVal    \u001b[37m\u001b[39;49;00m\n",
      "                torch.save({\u001b[33m'\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epochID + \u001b[34m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.state_dict(), \u001b[33m'\u001b[39;49;00m\u001b[33mbest_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: lossMIN, \u001b[33m'\u001b[39;49;00m\u001b[33moptimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m : optimizer.state_dict()}, save_path +  \u001b[33m\"\u001b[39;49;00m\u001b[33m/model_base.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m (\u001b[33m'\u001b[39;49;00m\u001b[33mEpoch [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(epochID + \u001b[34m1\u001b[39;49;00m) + \u001b[33m'\u001b[39;49;00m\u001b[33m] [save] [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampEND + \u001b[33m'\u001b[39;49;00m\u001b[33m] loss= \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(lossVal))\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# save_model(model, save_path)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m (\u001b[33m'\u001b[39;49;00m\u001b[33mEpoch [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(epochID + \u001b[34m1\u001b[39;49;00m) + \u001b[33m'\u001b[39;49;00m\u001b[33m] [----] [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampEND + \u001b[33m'\u001b[39;49;00m\u001b[33m] loss= \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(lossVal))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m batchs, losst, losse        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#-------------------------------------------------------------------------------- \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "       \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mepochTrain\u001b[39;49;00m(model, dataLoaderTrain, dataLoaderVal, optimizer, trMaxEpoch, classCount, loss):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        batch = []\u001b[37m\u001b[39;49;00m\n",
      "        losstrain = []\u001b[37m\u001b[39;49;00m\n",
      "        losseval = []\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model.train()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batchID, (varInput, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataLoaderTrain):\u001b[37m\u001b[39;49;00m\n",
      "            use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                varTarget = target.cuda(non_blocking = \u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                varTarget = target\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m#varTarget = target.cuda()         \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            varOutput = model(varInput)\u001b[37m\u001b[39;49;00m\n",
      "            lossvalue = loss(varOutput, varTarget)\u001b[37m\u001b[39;49;00m\n",
      "                       \u001b[37m\u001b[39;49;00m\n",
      "            optimizer.zero_grad()\u001b[37m\u001b[39;49;00m\n",
      "            lossvalue.backward()\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.step()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            l = lossvalue.item()\u001b[37m\u001b[39;49;00m\n",
      "            losstrain.append(l)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m batchID%\u001b[34m35\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(batchID//\u001b[34m35\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m batches computed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m#Fill three arrays to see the evolution of the loss\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "                batch.append(batchID)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "                le = CheXpertTrainer.epochVal(model, dataLoaderVal, optimizer, trMaxEpoch, classCount, loss).item()\u001b[37m\u001b[39;49;00m\n",
      "                losseval.append(le)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(batchID)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(l)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(le)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m batch, losstrain, losseval\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#-------------------------------------------------------------------------------- \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mepochVal\u001b[39;49;00m(model, dataLoaderVal, optimizer, epochMax, classCount, loss):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        lossVal = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        lossValNorm = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i, (varInput, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataLoaderVal):\u001b[37m\u001b[39;49;00m\n",
      "                use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target.cuda(non_blocking = \u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m\u001b[39;49;00m\n",
      "                varOutput = model(varInput)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "                losstensor = loss(varOutput, target)\u001b[37m\u001b[39;49;00m\n",
      "                lossVal += losstensor\u001b[37m\u001b[39;49;00m\n",
      "                lossValNorm += \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "        outLoss = lossVal / lossValNorm\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m outLoss\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#--------------------------------------------------------------------------------     \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- Computes area under ROC curve \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- dataGT - ground truth data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- dataPRED - predicted data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- classCount - number of classes\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcomputeAUROC\u001b[39;49;00m (dataGT, dataPRED, classCount):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        outAUROC = []\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        datanpGT = dataGT.cpu().numpy()\u001b[37m\u001b[39;49;00m\n",
      "        datanpPRED = dataPRED.cpu().numpy()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(classCount):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mexcept\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mpass\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m outAUROC\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#-------------------------------------------------------------------------------- \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, dataLoaderTest, nnClassCount, checkpoint, class_names):   \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        cudnn.benchmark = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m checkpoint != \u001b[34mNone\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            modelCheckpoint = torch.load(checkpoint)\u001b[37m\u001b[39;49;00m\n",
      "            model.load_state_dict(modelCheckpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            outGT = torch.FloatTensor().cuda()\u001b[37m\u001b[39;49;00m\n",
      "            outPRED = torch.FloatTensor().cuda()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            outGT = torch.FloatTensor()\u001b[37m\u001b[39;49;00m\n",
      "            outPRED = torch.FloatTensor()\u001b[37m\u001b[39;49;00m\n",
      "       \u001b[37m\u001b[39;49;00m\n",
      "        model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i, (\u001b[36minput\u001b[39;49;00m, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataLoaderTest):\u001b[37m\u001b[39;49;00m\n",
      "                use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target.cuda()\u001b[37m\u001b[39;49;00m\n",
      "                    outGT = torch.cat((outGT, target), \u001b[34m0\u001b[39;49;00m).cuda()\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target\u001b[37m\u001b[39;49;00m\n",
      "                    outGT = torch.cat((outGT, target), \u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "                bs, c, h, w = \u001b[36minput\u001b[39;49;00m.size()\u001b[37m\u001b[39;49;00m\n",
      "                varInput = \u001b[36minput\u001b[39;49;00m.view(-\u001b[34m1\u001b[39;49;00m, c, h, w)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "                out = model(varInput)\u001b[37m\u001b[39;49;00m\n",
      "                outPRED = torch.cat((outPRED, out), \u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        aurocIndividual = CheXpertTrainer.computeAUROC(outGT, outPRED, nnClassCount)\u001b[37m\u001b[39;49;00m\n",
      "        aurocMean = np.array(aurocIndividual).mean()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m (\u001b[33m'\u001b[39;49;00m\u001b[33mAUROC mean \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, aurocMean)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m (\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(aurocIndividual)):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m (class_names[i], \u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, aurocIndividual[i])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m outGT, outPRED\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mFlatten\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\n",
      "        x = x.view(x.size()[\u001b[34m0\u001b[39;49;00m], -\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "IMAGENET_MEAN = np.array([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "IMAGENET_STD = np.array([\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m densenet121\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mChexNet\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m densenet121\u001b[37m\u001b[39;49;00m\n",
      "    tfm = transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize((\u001b[34m224\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m)),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m().\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.backbone = densenet121(\u001b[34mFalse\u001b[39;49;00m).features\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.head = nn.Sequential(nn.AdaptiveAvgPool2d(\u001b[34m1\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "                                 Flatten(),\u001b[37m\u001b[39;49;00m\n",
      "                                 nn.Linear(\u001b[34m1024\u001b[39;49;00m, \u001b[34m14\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.head(\u001b[36mself\u001b[39;49;00m.backbone(x))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mpredict\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, image):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        input: PIL image (w, h, c)\u001b[39;49;00m\n",
      "\u001b[33m        output: prob np.array\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image = V(\u001b[36mself\u001b[39;49;00m.tfm(image)[\u001b[34mNone\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        image=image.cpu()\u001b[37m\u001b[39;49;00m\n",
      "        py = torch.sigmoid(\u001b[36mself\u001b[39;49;00m(image))\u001b[37m\u001b[39;49;00m\n",
      "        prob = py.detach().cpu().numpy()[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m prob\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_dataloader\u001b[39;49;00m(traindir,testdir,validdir,batch_size=\u001b[34m128\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    image_transforms = {\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Train uses data augmentation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m), \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# transforms.RandomHorizontalFlip(),\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "                             [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])  \u001b[37m# Imagenet standards\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    ])\u001b[37m\u001b[39;49;00m\n",
      "        ,\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Validation does not use augmentation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    ]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Test does not use augmentation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    ]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    data = {\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    datasets.ImageFolder(root=traindir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    datasets.ImageFolder(root=validdir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    datasets.ImageFolder(root=testdir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Dataloader iterators\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    dataloaders = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m data,dataloaders\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpreops\u001b[39;49;00m(traindir,testdir,validdir):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m********* inside preops *************\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtraindir\u001b[33m}\u001b[39;49;00m\u001b[33m , \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtestdir\u001b[33m}\u001b[39;49;00m\u001b[33m , \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvaliddir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Empty lists\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    categories = []\u001b[37m\u001b[39;49;00m\n",
      "    img_categories = []\u001b[37m\u001b[39;49;00m\n",
      "    n_train = []\u001b[37m\u001b[39;49;00m\n",
      "    n_valid = []\u001b[37m\u001b[39;49;00m\n",
      "    n_test = []\u001b[37m\u001b[39;49;00m\n",
      "    hs = []\u001b[37m\u001b[39;49;00m\n",
      "    ws = []\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Iterate through each category\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m d \u001b[35min\u001b[39;49;00m os.listdir(traindir):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m d.startswith(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            categories.append(d)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# Number of each image\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            train_imgs = os.listdir(traindir + d)\u001b[37m\u001b[39;49;00m\n",
      "            valid_imgs = os.listdir(validdir + d)\u001b[37m\u001b[39;49;00m\n",
      "            test_imgs = os.listdir(testdir + d)\u001b[37m\u001b[39;49;00m\n",
      "            n_train.append(\u001b[36mlen\u001b[39;49;00m(train_imgs))\u001b[37m\u001b[39;49;00m\n",
      "            n_valid.append(\u001b[36mlen\u001b[39;49;00m(valid_imgs))\u001b[37m\u001b[39;49;00m\n",
      "            n_test.append(\u001b[36mlen\u001b[39;49;00m(test_imgs))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# Find stats for train images\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m train_imgs:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m i.startswith(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                    img_categories.append(d)\u001b[37m\u001b[39;49;00m\n",
      "                    img = Image.open(traindir + d + \u001b[33m'\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + i).convert(\u001b[33m\"\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                    img_array = np.array(img)\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m# Shape\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                    hs.append(img_array.shape[\u001b[34m0\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "                    ws.append(img_array.shape[\u001b[34m1\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Dataframe of categories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    cat_df = pd.DataFrame({\u001b[33m'\u001b[39;49;00m\u001b[33mcategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: categories,\u001b[37m\u001b[39;49;00m\n",
      "                           \u001b[33m'\u001b[39;49;00m\u001b[33mn_train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: n_train,\u001b[37m\u001b[39;49;00m\n",
      "                           \u001b[33m'\u001b[39;49;00m\u001b[33mn_valid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: n_valid, \u001b[33m'\u001b[39;49;00m\u001b[33mn_test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: n_test}).\\\n",
      "        sort_values(\u001b[33m'\u001b[39;49;00m\u001b[33mcategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Dataframe of training images\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    image_df = pd.DataFrame({\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mcategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: img_categories,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mheight\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: hs,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mwidth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: ws\u001b[37m\u001b[39;49;00m\n",
      "    })\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m cat_df\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mHeatmapGenerator\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m, pathModel=\u001b[34mNone\u001b[39;49;00m, nnClassCount=\u001b[34m14\u001b[39;49;00m, transCrop=\u001b[34m224\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model = DenseNet121(nnClassCount)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        use_gpu = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model = torch.load(pathModel)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model.load_state_dict(modelCheckpoint['state_dict'])\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model = model\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Initialize the weights\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.weights = \u001b[36mlist\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.model.module.densenet121.features.parameters())[-\u001b[34m2\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Initialize the image transform\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        normalize = transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        transformList = []\u001b[37m\u001b[39;49;00m\n",
      "        transformList.append(transforms.Resize((transCrop, transCrop)))\u001b[37m\u001b[39;49;00m\n",
      "        transformList.append(transforms.ToTensor())\u001b[37m\u001b[39;49;00m\n",
      "        transformList.append(normalize)  \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.transformSequence = transforms.Compose(transformList)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#--------------------------------------------------------------------------------\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mgenerate\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m, pathImageFile, pathOutputFile, transCrop):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Load image, transform, convert \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            use_gpu = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      " \u001b[37m\u001b[39;49;00m\n",
      "            imageData = Image.open(pathImageFile).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            imageData = \u001b[36mself\u001b[39;49;00m.transformSequence(imageData)\u001b[37m\u001b[39;49;00m\n",
      "            imageData = imageData.unsqueeze_(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                imageData = imageData\u001b[37m\u001b[39;49;00m\n",
      "            l = \u001b[36mself\u001b[39;49;00m.model(imageData)\u001b[37m\u001b[39;49;00m\n",
      "            output = \u001b[36mself\u001b[39;49;00m.model.module.densenet121.features(imageData)\u001b[37m\u001b[39;49;00m\n",
      "            label = class_names[torch.max(l,\u001b[34m1\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]]\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m#---- Generate heatmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            heatmap = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m (\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.weights)):\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mmap\u001b[39;49;00m = output[\u001b[34m0\u001b[39;49;00m,i,:,:]\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m i == \u001b[34m0\u001b[39;49;00m: heatmap = \u001b[36mself\u001b[39;49;00m.weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m: heatmap += \u001b[36mself\u001b[39;49;00m.weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                npHeatmap = heatmap.cpu().data.numpy()\u001b[37m\u001b[39;49;00m\n",
      "        cam = npHeatmap / np.max(npHeatmap)\u001b[37m\u001b[39;49;00m\n",
      "        cam = cv2.resize(cam, (transCrop, transCrop))\u001b[37m\u001b[39;49;00m\n",
      "        heatmap = cv2.applyColorMap(np.uint8(\u001b[34m255\u001b[39;49;00m*cam), cv2.COLORMAP_JET)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Blend original and heatmap \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        temp = heatmap.copy()\u001b[37m\u001b[39;49;00m\n",
      "        img = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(img.min())\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# print(img.shape)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        img = (img/\u001b[34m1\u001b[39;49;00m).astype(\u001b[33m'\u001b[39;49;00m\u001b[33muint8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        binary = threshold(\u001b[34m200\u001b[39;49;00m,\u001b[34m255\u001b[39;49;00m,img)\u001b[37m\u001b[39;49;00m\n",
      "        binary = binary.astype(np.int32)\u001b[37m\u001b[39;49;00m\n",
      "        contours, _ = cv2.findContours(binary,cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE) \u001b[37m\u001b[39;49;00m\n",
      "        multi_data = []\u001b[37m\u001b[39;49;00m\n",
      "        multidata_dict={}\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mROIFormat.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m json_file:\u001b[37m\u001b[39;49;00m\n",
      "            data_orig = json.load(json_file)\u001b[37m\u001b[39;49;00m\n",
      "        coords = get_1D_coord(contours)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m coord \u001b[35min\u001b[39;49;00m coords:\u001b[37m\u001b[39;49;00m\n",
      "            data_final = get_json(data = data_orig, coord=coord)\u001b[37m\u001b[39;49;00m\n",
      "            multi_data.append(deepcopy(data_final[\u001b[33m'\u001b[39;49;00m\u001b[33mallTools\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "        multidata_dict[\u001b[33m'\u001b[39;49;00m\u001b[33mallTools\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = multi_data\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mFINAL JSON\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(multidata_dict)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         imgOriginal = cv2.imread(pathImageFile, 1)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         imgOriginal = cv2.resize(imgOriginal, (transCrop, transCrop))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         img = cv2.addWeighted(imgOriginal,1,heatmap,0.35,0)            \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.title(label)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.imshow(img)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.plot()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.axis('off')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.savefig(pathOutputFile)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.show()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mfind_file_path\u001b[39;49;00m(filename):\u001b[37m\u001b[39;49;00m\n",
      "    file_path = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m path \u001b[35min\u001b[39;49;00m glob.glob(\u001b[33m'\u001b[39;49;00m\u001b[33m**/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + filename, recursive=\u001b[34mTrue\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m file_path \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            file_path = os.path.abspath(path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mbreak\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m file_path\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mrun\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    batch_size = \u001b[34m128\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    traindir = args.data_dir_train + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#datadir + '/train/'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    validdir = args.data_dir_val + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#datadir + '/val/'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    testdir = args.data_dir_test + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#datadir + '/test/'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "    pathFileTrain = args.data_dir_train\u001b[37m\u001b[39;49;00m\n",
      "    pathFileValid = args.data_dir_val\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Neural network parameters:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    nnIsTrained = \u001b[34mFalse\u001b[39;49;00m                 \u001b[37m#pre-trained using ImageNet\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    nnClassCount = \u001b[34m14\u001b[39;49;00m                   \u001b[37m#dimension of the output\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Training settings: batch size, maximum number of epochs\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trBatchSize = \u001b[34m64\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trMaxEpoch = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Parameters related to image transforms: size of the down-scaled image, cropped image\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    imgtransResize = (\u001b[34m320\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    imgtransCrop = \u001b[34m224\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Class names\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    class_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mNo Finding\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEnlarged Cardiomediastinum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCardiomegaly\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Opacity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mLung Lesion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEdema\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mConsolidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumonia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAtelectasis\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumothorax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Effusion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Other\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mFracture\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSupport Devices\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#TRANSFORM DATA\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    normalize = transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    transformList = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#transformList.append(transforms.Resize(imgtransCrop))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(transforms.RandomResizedCrop(imgtransCrop))\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(transforms.RandomHorizontalFlip())\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(transforms.ToTensor())\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(normalize)      \u001b[37m\u001b[39;49;00m\n",
      "    transformSequence=transforms.Compose(transformList)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#LOAD DATASET\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# cat_df = preops(traindir,testdir,validdir)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    nnClassCount = \u001b[36mlen\u001b[39;49;00m(class_names)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# data,dataloaders = create_dataloader(traindir,testdir,validdir,batch_size)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    dataset = CheXpertDataSet(pathFileTrain ,transformSequence, policy=\u001b[33m\"\u001b[39;49;00m\u001b[33mones\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# datasetTest, datasetTrain = random_split(dataset, [len(dataset), len(dataset)])\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    datasetTest = dataset\u001b[37m\u001b[39;49;00m\n",
      "    datasetTrain = dataset\u001b[37m\u001b[39;49;00m\n",
      "    datasetValid = CheXpertDataSet(pathFileValid, transformSequence)            \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# dataLoaderTrain = dataloaders[\"train\"]#DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=24, pin_memory=True)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# dataLoaderVal = dataloaders[\"val\"]#DataLoader(dataset=datasetValid, batch_size=trBatchSize, shuffle=False, num_workers=24, pin_memory=True)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# dataLoaderTest = dataloaders[\"test\"]#DataLoader(dataset=datasetTest, num_workers=24, pin_memory=True)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=\u001b[34mTrue\u001b[39;49;00m,  num_workers=\u001b[34m24\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dataLoaderVal = DataLoader(dataset=datasetValid, batch_size=trBatchSize, shuffle=\u001b[34mFalse\u001b[39;49;00m, num_workers=\u001b[34m24\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dataLoaderTest = DataLoader(dataset=datasetTest, num_workers=\u001b[34m24\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# initialize and load the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "        model = ChexNet().cuda()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model = torch.nn.DataParallel(model).cuda()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        model = ChexNet()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model = torch.nn.DataParallel(model)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    timestampTime = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    timestampDate = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    timestampLaunch = timestampDate + \u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampTime\u001b[37m\u001b[39;49;00m\n",
      "    save_path = args.model_dir\u001b[37m\u001b[39;49;00m\n",
      "    path = find_file_path(\u001b[33m'\u001b[39;49;00m\u001b[33mchexnet.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    batch, losst, losse = CheXpertTrainer.train(model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, timestampLaunch, path, save_path)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel trained\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    losstn = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(losst), \u001b[34m35\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        losstn.append(np.mean(losst[i:i+\u001b[34m35\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(losstn)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(losse)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m64\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m1000\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "   \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m100\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir-train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir-test\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TESTING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir-val\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    args = parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    run(args)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters. In this case we are going to run our training job on 2 ```ml.c4.xlarge``` instances. But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)). The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the `classifier.py` script above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==2.152.0\n",
      "  Downloading sagemaker-2.152.0.tar.gz (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.1/751.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs<23,>=20.3.0 (from sagemaker==2.152.0)\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.26.154)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.21.6)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (3.20.3)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.0.1)\n",
      "Collecting importlib-metadata<5.0,>=1.4.0 (from sagemaker==2.152.0)\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.3.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.7.5)\n",
      "Collecting PyYAML==5.4.1 (from sagemaker==2.152.0)\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (3.5.3)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.154 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.152.0) (1.29.154)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.152.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.152.0) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.152.0) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.152.0) (4.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.152.0) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.152.0) (1.14.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker==2.152.0) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker==2.152.0) (65.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.152.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.152.0) (2019.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker==2.152.0) (0.6.0.post1)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.30.0,>=1.29.154->boto3<2.0,>=1.26.28->sagemaker==2.152.0)\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.152.0-py2.py3-none-any.whl size=1007493 sha256=216b07cc60177c0696d086adf718e6914c841e68308da52b74cc3318d073a2f7\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/5b/a4/ad61c362425ff3ffeb666f9dc85274cb0d6271f7d897c976df\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: urllib3, PyYAML, importlib-metadata, attrs, sagemaker\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.3\n",
      "    Uninstalling urllib3-2.0.3:\n",
      "      Successfully uninstalled urllib3-2.0.3\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.6.0\n",
      "    Uninstalling importlib-metadata-6.6.0:\n",
      "      Successfully uninstalled importlib-metadata-6.6.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.165.0\n",
      "    Uninstalling sagemaker-2.165.0:\n",
      "      Successfully uninstalled sagemaker-2.165.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "awscli 1.27.154 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
      "python-language-server 0.31.7 requires jedi<0.16,>=0.14.1, but you have jedi 0.18.2 which is incompatible.\n",
      "python-language-server 0.31.7 requires ujson<=1.35; platform_system != \"Windows\", but you have ujson 5.7.0 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.18.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-5.4.1 attrs-22.2.0 importlib-metadata-4.13.0 sagemaker-2.152.0 urllib3-1.26.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker==2.152.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.152.0\n"
     ]
    }
   ],
   "source": [
    "!pip show sagemaker | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"classifier.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.12.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    # instance_type=\"ml.g4dn.xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},\n",
    "    dependencies=['code/requirements.txt'],\n",
    "    source_dir = \"code\",\n",
    "    max_run=20,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-06-26-07-59-27-442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-26 07:59:29 Starting - Starting the training job...\n",
      "2023-06-26 07:59:44 Starting - Preparing the instances for training......\n",
      "2023-06-26 08:00:32 Downloading - Downloading input data...\n",
      "2023-06-26 08:01:12 Training - Downloading the training image...\n",
      "2023-06-26 08:01:58 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:03,171 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:03,174 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:03,182 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:03,185 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:03,974 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[34mCollecting pydicom\u001b[0m\n",
      "\u001b[34mDownloading pydicom-2.4.1-py3-none-any.whl (1.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 54.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.22.2)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary\u001b[0m\n",
      "\u001b[34mDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.4.3)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless\u001b[0m\n",
      "\u001b[34mDownloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.2/49.2 MB 34.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (3.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 7)) (2022.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 7)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary, pydicom, opencv-python-headless\u001b[0m\n",
      "\u001b[34mSuccessfully installed opencv-python-headless-4.7.0.72 pydicom-2.4.1 torchsummary-1.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.1.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:08,417 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:08,417 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:08,421 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:08,432 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:08,443 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:08,452 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validating\": \"/opt/ml/input/data/validating\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validating\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2023-06-26-07-59-27-442\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"classifier\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"classifier.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=classifier.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validating\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\",\"validating\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=classifier\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\",\"validating\":\"/opt/ml/input/data/validating\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validating\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2023-06-26-07-59-27-442\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/source/sourcedir.tar.gz\",\"module_name\":\"classifier\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"classifier.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATING=/opt/ml/input/data/validating\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 classifier.py --backend gloo --epochs 1\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:559: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m>>>>>>>>>>>>>>>>>>> MODEL LOADED SUCCESSFULLY >>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[2023-06-26 08:02:11.371 algo-1:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-06-26 08:02:11.543 algo-1:39 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-06-26 08:02:11.545 algo-1:39 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-06-26 08:02:11.545 algo-1:39 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-06-26 08:02:11.546 algo-1:39 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-06-26 08:02:11.546 algo-1:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\n",
      "2023-06-26 08:02:28 Uploading - Uploading generated training model\u001b[34m0 % batches computed\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:559: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[34m0\u001b[0m\n",
      "\u001b[34m52.01844787597656\u001b[0m\n",
      "\u001b[34m66.25244140625\u001b[0m\n",
      "\u001b[34mEpoch [1] [----] [26062023-080222] loss= tensor(63.3274)\u001b[0m\n",
      "\u001b[34mModel trained\u001b[0m\n",
      "\u001b[34m[52.01844787597656]\u001b[0m\n",
      "\u001b[34m[66.25244140625]\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:22,690 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:22,691 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-26 08:02:22,691 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-06-26 08:02:44 Completed - Training job completed\n",
      "Training seconds: 131\n",
      "Billable seconds: 131\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    {\n",
    "        \"training\":\"s3://\"+bucket+\"/data/train\" ,\n",
    "        \"testing\":\"s3://\"+bucket+\"/data/train\",\n",
    "        \"validating\":\"s3://\"+bucket+\"/data/train\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Host your model in Sagemaker\n",
    "### Create endpoint\n",
    "After training, we use the `PyTorch` estimator object to build and deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `classifier.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `classifier.py`. Here we will deploy the model to a single ```ml.m4.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'framework_version': '1.12.0',\n",
       " 'py_version': 'py38',\n",
       " 'instance_count': 1,\n",
       " 'instance_type': 'ml.m5.large',\n",
       " 'keep_alive_period_in_seconds': None,\n",
       " 'instance_groups': None,\n",
       " 'volume_size': 30,\n",
       " 'max_run': 20,\n",
       " 'input_mode': 'File',\n",
       " 'metric_definitions': None,\n",
       " 'model_uri': None,\n",
       " 'model_channel_name': 'model',\n",
       " 'code_uri': None,\n",
       " 'code_channel_name': 'code',\n",
       " 'source_dir': 'code',\n",
       " 'git_config': None,\n",
       " 'container_log_level': 20,\n",
       " '_hyperparameters': {'epochs': 1,\n",
       "  'backend': 'gloo',\n",
       "  'sagemaker_submit_directory': 's3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/source/sourcedir.tar.gz',\n",
       "  'sagemaker_program': 'classifier.py',\n",
       "  'sagemaker_container_log_level': 20,\n",
       "  'sagemaker_job_name': 'pytorch-training-2023-06-26-07-59-27-442',\n",
       "  'sagemaker_region': 'ap-south-1'},\n",
       " 'code_location': None,\n",
       " 'entry_point': 'classifier.py',\n",
       " 'dependencies': ['code/requirements.txt'],\n",
       " 'uploaded_code': UploadedCode(s3_prefix='s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/source/sourcedir.tar.gz', script_name='classifier.py'),\n",
       " 'tags': None,\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7f217d58f390>,\n",
       " 'base_job_name': 'pytorch-training',\n",
       " '_current_job_name': 'pytorch-training-2023-06-26-07-59-27-442',\n",
       " 'output_path': 's3://sagemaker-ap-south-1-023180687239/',\n",
       " 'latest_training_job': <sagemaker.estimator._TrainingJob at 0x7f215d7155d0>,\n",
       " 'jobs': [<sagemaker.estimator._TrainingJob at 0x7f215d7155d0>],\n",
       " 'deploy_instance_type': 'ml.c5.2xlarge',\n",
       " '_compiled_models': {},\n",
       " 'role': 'arn:aws:iam::023180687239:role/service-role/AmazonSageMaker-ExecutionRole-20220906T142944',\n",
       " 'output_kms_key': None,\n",
       " 'volume_kms_key': None,\n",
       " 'subnets': None,\n",
       " 'security_group_ids': None,\n",
       " 'training_repository_access_mode': None,\n",
       " 'training_repository_credentials_provider_arn': None,\n",
       " 'encrypt_inter_container_traffic': False,\n",
       " 'use_spot_instances': False,\n",
       " 'max_wait': None,\n",
       " 'checkpoint_s3_uri': None,\n",
       " 'checkpoint_local_path': None,\n",
       " 'rules': None,\n",
       " 'debugger_hook_config': <sagemaker.debugger.debugger.DebuggerHookConfig at 0x7f217cf1cdd0>,\n",
       " 'tensorboard_output_config': None,\n",
       " 'debugger_rule_configs': [],\n",
       " 'collection_configs': set(),\n",
       " 'enable_sagemaker_metrics': True,\n",
       " '_enable_network_isolation': False,\n",
       " 'profiler_config': <sagemaker.debugger.profiler_config.ProfilerConfig at 0x7f217cf1cd50>,\n",
       " 'disable_profiler': False,\n",
       " 'environment': None,\n",
       " 'max_retry_attempts': None,\n",
       " 'profiler_rule_configs': [],\n",
       " 'profiler_rules': [],\n",
       " 'debugger_rules': [],\n",
       " '_is_output_path_set_from_default_bucket_and_prefix': True,\n",
       " 'image_uri': None,\n",
       " 'distribution': {},\n",
       " 'compiler_config': None}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_job_name = estimator._hyperparameters[\"sagemaker_job_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/output/model.tar.gz), script artifact (s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-07-59-27-442/source/sourcedir.tar.gz), and dependencies (['code/requirements.txt']) into single tar.gz file located at s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-26-08-03-12-222/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-training-2023-06-26-08-03-12-222\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-2023-06-26-08-03-12-222\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2023-06-26-08-03-12-222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.2xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "You can use the test images to evalute the endpoint. The accuracy of the model depends on how many it is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endpoint_name': 'pytorch-training-2023-06-26-08-03-12-222',\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7f217d58f390>,\n",
       " 'serializer': <sagemaker.base_serializers.NumpySerializer at 0x7f215d0cc050>,\n",
       " 'deserializer': <sagemaker.base_deserializers.NumpyDeserializer at 0x7f215d0cc090>,\n",
       " '_endpoint_config_name': None,\n",
       " '_model_names': None,\n",
       " '_context': None,\n",
       " '_content_type': None,\n",
       " '_accept': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-training-2023-06-26-08-03-12-222'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Invoke endpoint and test your model in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '32229c9d-a9cd-4d3d-b0d2-27e28eb65ee5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '32229c9d-a9cd-4d3d-b0d2-27e28eb65ee5', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Mon, 26 Jun 2023 08:05:49 GMT', 'content-type': 'application/json', 'content-length': '4412', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7f217cd6b110>}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "custom_attributes = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.\n",
    "endpoint_name = predictor.endpoint_name                                        # Your endpoint name.\n",
    "content_type = \"application/json\"                                        # The MIME type of the input data in the request body.\n",
    "accept = \"application/json\"                                              # The desired MIME type of the inference in the response.\n",
    "payload = json.dumps({\"url\":\"https://storage.googleapis.com/kaggle-datasets-images/17810/23340/c8372ebbe20b0f671c2f3c501ba51412/dataset-cover.jpeg?t=2018-03-24-19-05-18\"})                                           # Payload for inference.\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    CustomAttributes=custom_attributes, \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=payload\n",
    "    )\n",
    "\n",
    "print(response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Body': <botocore.response.StreamingBody object at 0x7f217cd6b110>,\n",
      " 'ContentType': 'application/json',\n",
      " 'InvokedProductionVariant': 'AllTraffic',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
      "                                      'content-length': '4412',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'date': 'Mon, 26 Jun 2023 08:05:49 GMT',\n",
      "                                      'x-amzn-invoked-production-variant': 'AllTraffic',\n",
      "                                      'x-amzn-requestid': '32229c9d-a9cd-4d3d-b0d2-27e28eb65ee5'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '32229c9d-a9cd-4d3d-b0d2-27e28eb65ee5',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = json.load(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': {'findings': [{'name': 'No Finding',\n",
       "    'probability': 0.15899339318275452},\n",
       "   {'name': 'Enlarged Cardiomediastinum', 'probability': 0.05995656177401543},\n",
       "   {'name': 'Cardiomegaly', 'probability': 0.29158324003219604},\n",
       "   {'name': 'Lung Opacity', 'probability': 0.4886914789676666},\n",
       "   {'name': 'Lung Lesion', 'probability': 0.08378386497497559},\n",
       "   {'name': 'Edema', 'probability': 0.21401825547218323},\n",
       "   {'name': 'Consolidation', 'probability': 0.13959090411663055},\n",
       "   {'name': 'Pneumonia', 'probability': 0.47525912523269653},\n",
       "   {'name': 'Atelectasis', 'probability': 0.21938934922218323},\n",
       "   {'name': 'Pneumothorax', 'probability': 0.3522780239582062},\n",
       "   {'name': 'Pleural Effusion', 'probability': 0.2807219922542572},\n",
       "   {'name': 'Pleural Other', 'probability': 0.03510424494743347},\n",
       "   {'name': 'Fracture', 'probability': 0.08782097697257996},\n",
       "   {'name': 'Support Devices', 'probability': 0.034316133707761765},\n",
       "   {'name': 'ROIS', 'probability': '1'}],\n",
       "  'rois': [{'finding_name': 'Abnormality',\n",
       "    'type': 'Freehand',\n",
       "    'points': [[1269.0, 199.0],\n",
       "     [1268.0, 200.0],\n",
       "     [1247.0, 200.0],\n",
       "     [1246.0, 201.0],\n",
       "     [1244.0, 201.0],\n",
       "     [1243.0, 200.0],\n",
       "     [1242.0, 201.0],\n",
       "     [1227.0, 201.0],\n",
       "     [1226.0, 202.0],\n",
       "     [1225.0, 202.0],\n",
       "     [1224.0, 203.0],\n",
       "     [1223.0, 203.0],\n",
       "     [1220.0, 206.0],\n",
       "     [1219.0, 206.0],\n",
       "     [1217.0, 208.0],\n",
       "     [1216.0, 208.0],\n",
       "     [1213.0, 211.0],\n",
       "     [1212.0, 211.0],\n",
       "     [1209.0, 214.0],\n",
       "     [1208.0, 214.0],\n",
       "     [1206.0, 216.0],\n",
       "     [1205.0, 216.0],\n",
       "     [1201.0, 220.0],\n",
       "     [1200.0, 220.0],\n",
       "     [1195.0, 225.0],\n",
       "     [1194.0, 225.0],\n",
       "     [1187.0, 232.0],\n",
       "     [1186.0, 232.0],\n",
       "     [1186.0, 233.0],\n",
       "     [1185.0, 234.0],\n",
       "     [1184.0, 234.0],\n",
       "     [1175.0, 243.0],\n",
       "     [1175.0, 250.0],\n",
       "     [1176.0, 251.0],\n",
       "     [1176.0, 252.0],\n",
       "     [1175.0, 253.0],\n",
       "     [1176.0, 254.0],\n",
       "     [1176.0, 272.0],\n",
       "     [1177.0, 273.0],\n",
       "     [1176.0, 274.0],\n",
       "     [1176.0, 275.0],\n",
       "     [1177.0, 276.0],\n",
       "     [1177.0, 277.0],\n",
       "     [1176.0, 278.0],\n",
       "     [1176.0, 279.0],\n",
       "     [1177.0, 280.0],\n",
       "     [1177.0, 292.0],\n",
       "     [1178.0, 293.0],\n",
       "     [1178.0, 294.0],\n",
       "     [1177.0, 295.0],\n",
       "     [1177.0, 296.0],\n",
       "     [1179.0, 298.0],\n",
       "     [1180.0, 298.0],\n",
       "     [1182.0, 300.0],\n",
       "     [1184.0, 300.0],\n",
       "     [1186.0, 302.0],\n",
       "     [1187.0, 302.0],\n",
       "     [1188.0, 303.0],\n",
       "     [1189.0, 303.0],\n",
       "     [1190.0, 304.0],\n",
       "     [1191.0, 304.0],\n",
       "     [1193.0, 306.0],\n",
       "     [1194.0, 306.0],\n",
       "     [1195.0, 307.0],\n",
       "     [1196.0, 307.0],\n",
       "     [1197.0, 308.0],\n",
       "     [1198.0, 308.0],\n",
       "     [1199.0, 309.0],\n",
       "     [1200.0, 309.0],\n",
       "     [1201.0, 310.0],\n",
       "     [1202.0, 310.0],\n",
       "     [1204.0, 312.0],\n",
       "     [1205.0, 312.0],\n",
       "     [1206.0, 313.0],\n",
       "     [1207.0, 313.0],\n",
       "     [1208.0, 314.0],\n",
       "     [1209.0, 314.0],\n",
       "     [1210.0, 315.0],\n",
       "     [1211.0, 315.0],\n",
       "     [1212.0, 316.0],\n",
       "     [1213.0, 316.0],\n",
       "     [1215.0, 318.0],\n",
       "     [1216.0, 318.0],\n",
       "     [1217.0, 319.0],\n",
       "     [1218.0, 319.0],\n",
       "     [1219.0, 320.0],\n",
       "     [1220.0, 320.0],\n",
       "     [1222.0, 322.0],\n",
       "     [1223.0, 322.0],\n",
       "     [1224.0, 323.0],\n",
       "     [1225.0, 323.0],\n",
       "     [1226.0, 324.0],\n",
       "     [1228.0, 324.0],\n",
       "     [1229.0, 323.0],\n",
       "     [1230.0, 323.0],\n",
       "     [1231.0, 322.0],\n",
       "     [1233.0, 322.0],\n",
       "     [1234.0, 321.0],\n",
       "     [1235.0, 321.0],\n",
       "     [1236.0, 320.0],\n",
       "     [1237.0, 320.0],\n",
       "     [1238.0, 319.0],\n",
       "     [1240.0, 319.0],\n",
       "     [1241.0, 318.0],\n",
       "     [1242.0, 318.0],\n",
       "     [1243.0, 317.0],\n",
       "     [1244.0, 317.0],\n",
       "     [1245.0, 316.0],\n",
       "     [1247.0, 316.0],\n",
       "     [1248.0, 315.0],\n",
       "     [1249.0, 315.0],\n",
       "     [1250.0, 314.0],\n",
       "     [1251.0, 314.0],\n",
       "     [1252.0, 313.0],\n",
       "     [1253.0, 313.0],\n",
       "     [1254.0, 312.0],\n",
       "     [1255.0, 312.0],\n",
       "     [1256.0, 311.0],\n",
       "     [1258.0, 311.0],\n",
       "     [1259.0, 310.0],\n",
       "     [1260.0, 310.0],\n",
       "     [1261.0, 309.0],\n",
       "     [1262.0, 309.0],\n",
       "     [1263.0, 308.0],\n",
       "     [1264.0, 308.0],\n",
       "     [1265.0, 307.0],\n",
       "     [1266.0, 307.0],\n",
       "     [1267.0, 306.0],\n",
       "     [1269.0, 306.0],\n",
       "     [1271.0, 304.0],\n",
       "     [1272.0, 304.0],\n",
       "     [1273.0, 303.0],\n",
       "     [1275.0, 303.0],\n",
       "     [1276.0, 302.0],\n",
       "     [1277.0, 302.0],\n",
       "     [1278.0, 301.0],\n",
       "     [1279.0, 301.0],\n",
       "     [1280.0, 300.0],\n",
       "     [1281.0, 300.0],\n",
       "     [1281.0, 299.0],\n",
       "     [1282.0, 298.0],\n",
       "     [1282.0, 297.0],\n",
       "     [1283.0, 296.0],\n",
       "     [1283.0, 293.0],\n",
       "     [1284.0, 292.0],\n",
       "     [1284.0, 289.0],\n",
       "     [1285.0, 288.0],\n",
       "     [1285.0, 285.0],\n",
       "     [1286.0, 284.0],\n",
       "     [1286.0, 281.0],\n",
       "     [1287.0, 280.0],\n",
       "     [1287.0, 277.0],\n",
       "     [1288.0, 276.0],\n",
       "     [1288.0, 273.0],\n",
       "     [1289.0, 272.0],\n",
       "     [1289.0, 269.0],\n",
       "     [1290.0, 268.0],\n",
       "     [1290.0, 265.0],\n",
       "     [1291.0, 264.0],\n",
       "     [1291.0, 260.0],\n",
       "     [1292.0, 259.0],\n",
       "     [1292.0, 256.0],\n",
       "     [1293.0, 255.0],\n",
       "     [1293.0, 251.0],\n",
       "     [1294.0, 250.0],\n",
       "     [1294.0, 247.0],\n",
       "     [1295.0, 246.0],\n",
       "     [1295.0, 241.0],\n",
       "     [1294.0, 240.0],\n",
       "     [1294.0, 237.0],\n",
       "     [1293.0, 236.0],\n",
       "     [1293.0, 234.0],\n",
       "     [1292.0, 233.0],\n",
       "     [1292.0, 230.0],\n",
       "     [1291.0, 229.0],\n",
       "     [1291.0, 227.0],\n",
       "     [1290.0, 226.0],\n",
       "     [1290.0, 224.0],\n",
       "     [1289.0, 223.0],\n",
       "     [1289.0, 220.0],\n",
       "     [1288.0, 219.0],\n",
       "     [1288.0, 217.0],\n",
       "     [1287.0, 216.0],\n",
       "     [1287.0, 214.0],\n",
       "     [1286.0, 213.0],\n",
       "     [1286.0, 212.0],\n",
       "     [1285.0, 211.0],\n",
       "     [1285.0, 209.0],\n",
       "     [1284.0, 208.0],\n",
       "     [1284.0, 206.0],\n",
       "     [1283.0, 205.0],\n",
       "     [1283.0, 203.0],\n",
       "     [1282.0, 202.0],\n",
       "     [1282.0, 201.0],\n",
       "     [1281.0, 200.0],\n",
       "     [1281.0, 199.0],\n",
       "     [1273.0, 199.0],\n",
       "     [1272.0, 200.0],\n",
       "     [1270.0, 200.0],\n",
       "     [1269.0, 199.0]]}]}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push code to your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = bucket\n",
    "key = 'artifact/code'\n",
    "from boto3 import client\n",
    "s3 = client('s3')\n",
    "BUCKET_NAME = bucket\n",
    "DIR_NAME = 'code'\n",
    "# Iterate through the files in the directory\n",
    "for root, dirs, files in os.walk(DIR_NAME):\n",
    "    for file in files:\n",
    "        # Construct the full local path of the file\n",
    "        local_path = os.path.join(root, file)\n",
    "        # Construct the full S3 path of the file\n",
    "        s3_path = os.path.join(root.replace(DIR_NAME, key), file)\n",
    "        # Upload the file to S3\n",
    "        s3.upload_file(local_path, BUCKET_NAME, s3_path)\n",
    "        print(f'Uploaded {local_path} to s3://{BUCKET_NAME}/{s3_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push model to your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelbucket = estimator.output_path.split(\"/\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"model\")\n",
    "except:\n",
    "    pass\n",
    "BUCKET_NAME = modelbucket\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(BUCKET_NAME).download_file(sagemaker_job_name + \"/output/model.tar.gz\", \"model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = client('s3')\n",
    "BUCKET_NAME = bucket\n",
    "s3.upload_file(\"model/model.tar.gz\", BUCKET_NAME, \"model/model.tar.gz\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
