{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheXpert : A Large Chest X-Ray Dataset and Competition\n",
    "\n",
    "This competition launched by the Stanford ML group aims at finding a prediction model which could perform as well as radiologist to find different pathologies thanks to chest X-Ray. The Dataset available to train our model is composed of 223,414 chest radiographs of 65,240 patients.\n",
    "\n",
    "<img src=\"view1_frontal.jpg\" title=\"X-Ray image of the dataset\" width = 320/>\n",
    "\n",
    "The website of the competition:\n",
    "https://stanfordmlgroup.github.io/competitions/chexpert/\n",
    "\n",
    "[Publication](https://arxiv.org/pdf/1901.07031.pdf) : Irvin, Jeremy, et al. \"CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison.\" arXiv preprint arXiv:1901.07031 (2019).\n",
    "\n",
    "Our goal is first to reproduce main results obtained in the related paper, published in January 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (9.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "we used this open source https://www.kaggle.com/code/dnik007/pneumonia-detection-using-pytorch notebook.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d4300856-e57e-4672-9f23-33074100ef98'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "metadata = json.load(open(\"/opt/ml/metadata/resource-metadata.json\",\"r\"))\n",
    "bucket = metadata[\"UserProfileName\"]\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d4300856-e57e-4672-9f23-33074100ef98'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/032589a4-c0d1-4c0f-800a-c6fd1240dd3b.dcm.png\n",
      "labels/labels.csv\n",
      "labels/rois.json\n"
     ]
    }
   ],
   "source": [
    "from boto3 import client\n",
    "\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-58fe9c9fb49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mboto3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data'"
     ]
    }
   ],
   "source": [
    "# Downloading Data from S3\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from boto3 import client\n",
    "import os\n",
    "os.mkdir(\"data\")\n",
    "os.mkdir(\"labels\")\n",
    "\n",
    "BUCKET_NAME = bucket\n",
    "c = 0\n",
    "conn = client('s3') \n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])\n",
    "    KEY = key['Key']\n",
    "    s3 = boto3.resource('s3')\n",
    "    try:\n",
    "        s3.Bucket(BUCKET_NAME).download_file(KEY, f\"{key['Key']}\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise\n",
    "    c = c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dcm to Png\n",
    "!pip install pydicom\n",
    "import pydicom as dicom\n",
    "import pydicom\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    try:\n",
    "        print(\"Converting to PNG .........................\")\n",
    "        dicom = dcmread(path, force=True)\n",
    "        print(dicom.SOPInstanceUID, \">>>>>>\", dicom.StudyInstanceUID, \">>>>>\", dicom.SeriesInstanceUID)\n",
    "        #if voi_lut:\n",
    "        if voi_lut and len(dicom.get(\"VOILUTSequence\", [])):\n",
    "            data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "        else:\n",
    "            data = dicom.pixel_array\n",
    "        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.amax(data) - data\n",
    "        data = data - np.min(data)\n",
    "        data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data,dicom.PatientName\n",
    "    except Exception as e:\n",
    "        print(e, \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        return \"corrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert dicoms to png and store in training_data_png\n",
    "\n",
    "from glob import glob\n",
    "files_ = glob('data/*.dcm',recursive=True)\n",
    "try:\n",
    "    os.mkdir(\"training_data_png\")\n",
    "except:\n",
    "    pass\n",
    "print(files_)\n",
    "c = 0\n",
    "for i in files_:\n",
    "    try:\n",
    "        print(\"\\n>>> \",i)\n",
    "        img,patientname = read_xray(i)\n",
    "        with open(\"filename.pkl\", 'wb') as f:\n",
    "            pickle.dump(img, f)\n",
    "        ims = pickle.load(open(\"filename.pkl\", \"rb\"))\n",
    "        norm = (ims.astype(np.float) - ims.min()) * 255.0 / (ims.max() - ims.min())\n",
    "        filename = str(i).split(\"/\")[1].split(\"_\")[0]\n",
    "        print(\"\\n>> filename\",filename)\n",
    "        Image.fromarray(norm.astype(np.uint8)).save(f\"training_data_png/{filename}.png\")\n",
    "        c = c + 1\n",
    "        print(c, \"Done\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "labels = pd.read_csv(\"./labels/labels.csv\",header=1)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_ = glob('training_data_png/*.png',recursive=True)\n",
    "\n",
    "for file in files_:\n",
    "    sagemaker_session.upload_data(path=file  , bucket=bucket, key_prefix=\"data/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `classifier.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of gpus available in the current container.\n",
    "* `SM_CURRENT_HOST`: The name of the current container on the container network.\n",
    "* `SM_HOSTS`: JSON encoded list containing all the hosts .\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (``if __name__=='__main__':``) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcv2\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbackends\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcudnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mcudnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtransforms\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtransforms\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtfunc\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dataset\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdataset\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m random_split\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlr_scheduler\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ReduceLROnPlateau\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mfunc\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m roc_auc_score\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmetrics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mcopy\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m deepcopy\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m cuda\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtimeit\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m default_timer \u001b[34mas\u001b[39;49;00m timer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms, models\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader, sampler\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshlex\u001b[39;49;00m, \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchsummary\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m summary\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpydicom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "class_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mNo Finding\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEnlarged Cardiomediastinum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCardiomegaly\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Opacity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mLung Lesion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEdema\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mConsolidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumonia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAtelectasis\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumothorax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Effusion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Other\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mFracture\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSupport Devices\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "nnClassCount = \u001b[34m14\u001b[39;49;00m \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mfind_file_path\u001b[39;49;00m(filename):\u001b[37m\u001b[39;49;00m\n",
      "    file_path = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m path \u001b[35min\u001b[39;49;00m glob.glob(\u001b[33m'\u001b[39;49;00m\u001b[33m**/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + filename, recursive=\u001b[34mTrue\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m file_path \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            file_path = os.path.abspath(path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mbreak\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m file_path\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[33m''' INFERENCING'''\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_json\u001b[39;49;00m(coord,og_img_size):\u001b[37m\u001b[39;49;00m\n",
      "    final_coord = [[coord[x]*(og_img_size[\u001b[34m0\u001b[39;49;00m]/\u001b[34m224\u001b[39;49;00m),coord[y]*(og_img_size[\u001b[34m1\u001b[39;49;00m]/\u001b[34m224\u001b[39;49;00m)] \u001b[34mfor\u001b[39;49;00m x,y \u001b[35min\u001b[39;49;00m \u001b[36mzip\u001b[39;49;00m(\u001b[36mlist\u001b[39;49;00m(\u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m,\u001b[36mlen\u001b[39;49;00m(coord),\u001b[34m2\u001b[39;49;00m)),\u001b[36mlist\u001b[39;49;00m(\u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m,\u001b[36mlen\u001b[39;49;00m(coord),\u001b[34m2\u001b[39;49;00m)))]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#final_coord = np.array(final_coord)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m(final_coord)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_coord_dict\u001b[39;49;00m(cont_new):\u001b[37m\u001b[39;49;00m\n",
      "    final_pairs = get_pairs(cont_new)\u001b[37m\u001b[39;49;00m\n",
      "    line_list = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m,\u001b[36mlen\u001b[39;49;00m(final_pairs)):\u001b[37m\u001b[39;49;00m\n",
      "        coord_cur,coord_after = final_pairs[i][\u001b[34m0\u001b[39;49;00m],final_pairs[i][\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        z = {\u001b[33m'\u001b[39;49;00m\u001b[33mactive\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mhighlight\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mlines\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [{\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_after[\u001b[34m0\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_after[\u001b[34m1\u001b[39;49;00m]}],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_cur[\u001b[34m0\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: coord_cur[\u001b[34m1\u001b[39;49;00m]}\u001b[37m\u001b[39;49;00m\n",
      "        line_list.append(z)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m line_list\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_1D_coord\u001b[39;49;00m(contours):\u001b[37m\u001b[39;49;00m\n",
      "    global_list=[]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m contour_id \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(contours)):\u001b[37m\u001b[39;49;00m\n",
      "        local_list=[]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m point_idx \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(contours[contour_id].shape[\u001b[34m0\u001b[39;49;00m]):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m(point_idx==\u001b[34m0\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                X_0= contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                Y_0 = contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            X = contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            Y = contours[contour_id][point_idx][\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            local_list.append(X)\u001b[37m\u001b[39;49;00m\n",
      "            local_list.append(Y)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# If the last point is reached, then append the first point\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m(point_idx == contours[contour_id].shape[\u001b[34m0\u001b[39;49;00m]-\u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                local_list.append(X_0)\u001b[37m\u001b[39;49;00m\n",
      "                local_list.append(Y_0)\u001b[37m\u001b[39;49;00m\n",
      "        global_list.append(deepcopy(local_list))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m(global_list)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mthreshold\u001b[39;49;00m(minimum,maximum,image,binary=\u001b[34mTrue\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m(binary): \u001b[37m# If binary is True, then the image is converted to binary\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image<minimum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image>maximum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[(image>\u001b[34m0\u001b[39;49;00m)]=\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m: \u001b[37m# If binary is False, then the image is converted to grayscale\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image<minimum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image[image>maximum]=\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m image\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_pairs\u001b[39;49;00m(cont_new):\u001b[37m\u001b[39;49;00m\n",
      "    pairs=[]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m,cont_new.shape[\u001b[34m0\u001b[39;49;00m]):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m (i < (cont_new.shape[\u001b[34m0\u001b[39;49;00m]-\u001b[34m1\u001b[39;49;00m)):\u001b[37m\u001b[39;49;00m\n",
      "            pairs.append((cont_new[i],cont_new[i+\u001b[34m1\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            pairs.append((cont_new[i],cont_new[\u001b[34m0\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m(pairs)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    model = DenseNet121(nnClassCount)\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    f = \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m>>>>>>>>>>>>>>> model dir >>>>>>>>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(model_dir)\u001b[37m\u001b[39;49;00m\n",
      "    model_def_path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.isfile(model_def_path):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mfile not found in \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_def_path\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMissing the model definition file\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "    modelCheckpoint = torch.load(model_def_path)\u001b[37m\u001b[39;49;00m\n",
      "    model.load_state_dict(modelCheckpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    model.eval()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    torch.save(model, path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:    \u001b[37m\u001b[39;49;00m\n",
      "        input_data = json.loads(request_body)\u001b[37m\u001b[39;49;00m\n",
      "        url = input_data[\u001b[33m'\u001b[39;49;00m\u001b[33murl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mImage url: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00murl\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        image_data = Image.open(requests.get(url, stream=\u001b[34mTrue\u001b[39;49;00m).raw).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        image_transform = transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "            transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "            transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        ])\u001b[37m\u001b[39;49;00m\n",
      "        data = image_transform(image_data)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[36mstr\u001b[39;49;00m(data.shape))\u001b[37m\u001b[39;49;00m\n",
      "        data = torch.tensor(data, dtype=torch.float32, device=device).unsqueeze(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[36mstr\u001b[39;49;00m(data.shape))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m [data, image_data.size]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcontent_type\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_object, model):\u001b[37m\u001b[39;49;00m\n",
      "    input_object, og_img_size = input_object\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[36mstr\u001b[39;49;00m(input_object.shape))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# logger.info(model.classifier)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        output = model.module.densenet121.features(input_object)\u001b[37m\u001b[39;49;00m\n",
      "        l = model(input_object)\u001b[37m\u001b[39;49;00m\n",
      "        heatmap = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        weights = \u001b[36mlist\u001b[39;49;00m(model.module.densenet121.features.parameters())[-\u001b[34m2\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m (\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(weights)):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mmap\u001b[39;49;00m = output[\u001b[34m0\u001b[39;49;00m,i,:,:]\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m i == \u001b[34m0\u001b[39;49;00m: \u001b[37m\u001b[39;49;00m\n",
      "                heatmap = weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m: \u001b[37m\u001b[39;49;00m\n",
      "                heatmap += weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            npHeatmap = heatmap.cpu().data.numpy()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m [output,l,npHeatmap, og_img_size]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(predictions, content_type):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34massert\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    output,l,npHeatmap,og_img_size = predictions\u001b[37m\u001b[39;49;00m\n",
      "    cam = npHeatmap / np.max(npHeatmap)\u001b[37m\u001b[39;49;00m\n",
      "    cam = cv2.resize(cam, (\u001b[34m224\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    heatmap = cv2.applyColorMap(np.uint8(\u001b[34m255\u001b[39;49;00m*cam), cv2.COLORMAP_JET)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- Blend original and heatmap \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    temp = heatmap.copy()\u001b[37m\u001b[39;49;00m\n",
      "    img = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(img.min())\u001b[37m\u001b[39;49;00m\n",
      "    img = (img/\u001b[34m1\u001b[39;49;00m).astype(\u001b[33m'\u001b[39;49;00m\u001b[33muint8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    binary = threshold(\u001b[34m245\u001b[39;49;00m,\u001b[34m500\u001b[39;49;00m,img)\u001b[37m\u001b[39;49;00m\n",
      "    binary = binary.astype(np.int32)\u001b[37m\u001b[39;49;00m\n",
      "    contours, _ = cv2.findContours(binary,cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE) \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# multi_data = []\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# multidata_dict={}\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# path_roi = find_file_path(\"ROIFormat.txt\")\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# with open(path_roi) as json_file:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     data_orig = json.load(json_file)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    coords = get_1D_coord(contours)\u001b[37m\u001b[39;49;00m\n",
      "    data_final = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m coord \u001b[35min\u001b[39;49;00m coords:\u001b[37m\u001b[39;49;00m\n",
      "        data_final.append(get_json(coord,og_img_size))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mFINAL JSON\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    output = response_converter(l.tolist(),data_final)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(output)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mresponse_converter\u001b[39;49;00m(labels,coords):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(labels,coords)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    THIS IS A CUSTOM RESPONSE CCONVERTER\u001b[39;49;00m\n",
      "\u001b[33m    CARPL EXPECTS OUTPUT IN THIS FORMAT:\u001b[39;49;00m\n",
      "\u001b[33m    {\u001b[39;49;00m\n",
      "\u001b[33m        \"response\": {\u001b[39;49;00m\n",
      "\u001b[33m            \"findings\":[\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_A\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_A\u001b[39;49;00m\n",
      "\u001b[33m                },\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_B\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_B\u001b[39;49;00m\n",
      "\u001b[33m                }\u001b[39;49;00m\n",
      "\u001b[33m            ],\u001b[39;49;00m\n",
      "\u001b[33m            \"rois\":[\u001b[39;49;00m\n",
      "\u001b[33m                    {\u001b[39;49;00m\n",
      "\u001b[33m                        \"finding_name\":\"class1\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"type\":\"Rectangle\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"points\":[\u001b[39;49;00m\n",
      "\u001b[33m                            [50,300],\u001b[39;49;00m\n",
      "\u001b[33m                            [100,200]\u001b[39;49;00m\n",
      "\u001b[33m                        ]\u001b[39;49;00m\n",
      "\u001b[33m                    },\u001b[39;49;00m\n",
      "\u001b[33m                    {\u001b[39;49;00m\n",
      "\u001b[33m                        \"finding_name\":\"class2\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"type\":\"Freehand\",\u001b[39;49;00m\n",
      "\u001b[33m                        \"points\":[\u001b[39;49;00m\n",
      "\u001b[33m                            [500,300],\u001b[39;49;00m\n",
      "\u001b[33m                            [500,320],\u001b[39;49;00m\n",
      "\u001b[33m                            [500,420],\u001b[39;49;00m\n",
      "\u001b[33m                            [800,420],\u001b[39;49;00m\n",
      "\u001b[33m                            [800,370],\u001b[39;49;00m\n",
      "\u001b[33m                            [800,320]\u001b[39;49;00m\n",
      "\u001b[33m                        ]\u001b[39;49;00m\n",
      "\u001b[33m                    }\u001b[39;49;00m\n",
      "\u001b[33m                ]\u001b[39;49;00m\n",
      "\u001b[33m        }\u001b[39;49;00m\n",
      "\u001b[33m    }\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mresponse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m : {\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mfindings\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:[{\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[36mstr\u001b[39;49;00m(e),\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mprobability\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:l\u001b[37m\u001b[39;49;00m\n",
      "                } \u001b[34mfor\u001b[39;49;00m e,l \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(labels[\u001b[34m0\u001b[39;49;00m])],\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mrois\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:[\u001b[37m\u001b[39;49;00m\n",
      "                    {\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mfinding_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[36mstr\u001b[39;49;00m(e),\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mFreehand\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mpoints\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:coords[e],\u001b[37m\u001b[39;49;00m\n",
      "                    } \u001b[34mfor\u001b[39;49;00m e,l \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(coords)\u001b[37m\u001b[39;49;00m\n",
      "                ]\u001b[37m\u001b[39;49;00m\n",
      "            }\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(e)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mCheXpertDataSet\u001b[39;49;00m(Dataset):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, image_list_file, transform=\u001b[34mNone\u001b[39;49;00m, policy=\u001b[33m\"\u001b[39;49;00m\u001b[33mones\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        image_list_file: path to the file containing images with corresponding labels.\u001b[39;49;00m\n",
      "\u001b[33m        transform: optional transform to be applied on a sample.\u001b[39;49;00m\n",
      "\u001b[33m        Upolicy: name the policy with regard to the uncertain labels\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        image_names = glob.glob(image_list_file+\u001b[33m\"\u001b[39;49;00m\u001b[33m/*.png\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,recursive = \u001b[34mTrue\u001b[39;49;00m )\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m\u001b[39;49;00m\n",
      "        labels = np.ones((\u001b[36mlen\u001b[39;49;00m(image_names),nnClassCount))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.image_names = image_names\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.labels = labels\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.transform = transform\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, index):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"Take the index of item and returns the image and its labels\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        image_name = \u001b[36mself\u001b[39;49;00m.image_names[index]\u001b[37m\u001b[39;49;00m\n",
      "        image = Image.open(image_name).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        label = \u001b[36mself\u001b[39;49;00m.labels[index]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.transform \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            image = \u001b[36mself\u001b[39;49;00m.transform(image)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m image, torch.FloatTensor(label)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__len__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.image_names)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mCheXpertTrainer\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m (model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, launchTimestamp, checkpoint, save_path):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#SETTINGS: OPTIMIZER & SCHEDULER\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        optimizer = optim.Adam (model.parameters(), lr=\u001b[34m0.0001\u001b[39;49;00m, betas=(\u001b[34m0.9\u001b[39;49;00m, \u001b[34m0.999\u001b[39;49;00m), eps=\u001b[34m1e-08\u001b[39;49;00m, weight_decay=\u001b[34m1e-5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#SETTINGS: LOSS\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        loss = torch.nn.BCELoss(size_average = \u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#LOAD CHECKPOINT \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m checkpoint != \u001b[34mNone\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            modelCheckpoint = torch.load(checkpoint)\u001b[37m\u001b[39;49;00m\n",
      "            model.load_state_dict(modelCheckpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.load_state_dict(modelCheckpoint[\u001b[33m'\u001b[39;49;00m\u001b[33moptimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#TRAIN THE NETWORK\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        lossMIN = \u001b[34m100000\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m epochID \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m, trMaxEpoch):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            timestampTime = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampDate = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampSTART = timestampDate + \u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampTime\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            batchs, losst, losse = CheXpertTrainer.epochTrain(model, dataLoaderTrain, dataLoaderVal, optimizer, trMaxEpoch, nnClassCount, loss)\u001b[37m\u001b[39;49;00m\n",
      "            lossVal = CheXpertTrainer.epochVal(model, dataLoaderVal, optimizer, trMaxEpoch, nnClassCount, loss)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            timestampTime = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampDate = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            timestampEND = timestampDate + \u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampTime\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m lossVal < lossMIN:\u001b[37m\u001b[39;49;00m\n",
      "                lossMIN = lossVal    \u001b[37m\u001b[39;49;00m\n",
      "                torch.save({\u001b[33m'\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epochID + \u001b[34m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.state_dict(), \u001b[33m'\u001b[39;49;00m\u001b[33mbest_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: lossMIN, \u001b[33m'\u001b[39;49;00m\u001b[33moptimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m : optimizer.state_dict()}, save_path +  \u001b[33m\"\u001b[39;49;00m\u001b[33m/model.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m (\u001b[33m'\u001b[39;49;00m\u001b[33mEpoch [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(epochID + \u001b[34m1\u001b[39;49;00m) + \u001b[33m'\u001b[39;49;00m\u001b[33m] [save] [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampEND + \u001b[33m'\u001b[39;49;00m\u001b[33m] loss= \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(lossVal))\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# save_model(model, save_path)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m (\u001b[33m'\u001b[39;49;00m\u001b[33mEpoch [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(epochID + \u001b[34m1\u001b[39;49;00m) + \u001b[33m'\u001b[39;49;00m\u001b[33m] [----] [\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampEND + \u001b[33m'\u001b[39;49;00m\u001b[33m] loss= \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(lossVal))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m batchs, losst, losse        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#-------------------------------------------------------------------------------- \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "       \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mepochTrain\u001b[39;49;00m(model, dataLoaderTrain, dataLoaderVal, optimizer, trMaxEpoch, classCount, loss):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        batch = []\u001b[37m\u001b[39;49;00m\n",
      "        losstrain = []\u001b[37m\u001b[39;49;00m\n",
      "        losseval = []\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model.train()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batchID, (varInput, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataLoaderTrain):\u001b[37m\u001b[39;49;00m\n",
      "            use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                varTarget = target.cuda(non_blocking = \u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                varTarget = target\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m#varTarget = target.cuda()         \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            varOutput = model(varInput)\u001b[37m\u001b[39;49;00m\n",
      "            lossvalue = loss(varOutput, varTarget)\u001b[37m\u001b[39;49;00m\n",
      "                       \u001b[37m\u001b[39;49;00m\n",
      "            optimizer.zero_grad()\u001b[37m\u001b[39;49;00m\n",
      "            lossvalue.backward()\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.step()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            l = lossvalue.item()\u001b[37m\u001b[39;49;00m\n",
      "            losstrain.append(l)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m batchID%\u001b[34m35\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(batchID//\u001b[34m35\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m batches computed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m#Fill three arrays to see the evolution of the loss\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "                batch.append(batchID)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "                le = CheXpertTrainer.epochVal(model, dataLoaderVal, optimizer, trMaxEpoch, classCount, loss).item()\u001b[37m\u001b[39;49;00m\n",
      "                losseval.append(le)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(batchID)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(l)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(le)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m batch, losstrain, losseval\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#-------------------------------------------------------------------------------- \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mepochVal\u001b[39;49;00m(model, dataLoaderVal, optimizer, epochMax, classCount, loss):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        lossVal = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        lossValNorm = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i, (varInput, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataLoaderVal):\u001b[37m\u001b[39;49;00m\n",
      "                use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target.cuda(non_blocking = \u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m\u001b[39;49;00m\n",
      "                varOutput = model(varInput)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "                losstensor = loss(varOutput, target)\u001b[37m\u001b[39;49;00m\n",
      "                lossVal += losstensor\u001b[37m\u001b[39;49;00m\n",
      "                lossValNorm += \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "        outLoss = lossVal / lossValNorm\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m outLoss\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#--------------------------------------------------------------------------------     \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- Computes area under ROC curve \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- dataGT - ground truth data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- dataPRED - predicted data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#---- classCount - number of classes\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcomputeAUROC\u001b[39;49;00m (dataGT, dataPRED, classCount):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        outAUROC = []\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        datanpGT = dataGT.cpu().numpy()\u001b[37m\u001b[39;49;00m\n",
      "        datanpPRED = dataPRED.cpu().numpy()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(classCount):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mexcept\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mpass\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m outAUROC\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#-------------------------------------------------------------------------------- \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, dataLoaderTest, nnClassCount, checkpoint, class_names):   \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        cudnn.benchmark = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m checkpoint != \u001b[34mNone\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            modelCheckpoint = torch.load(checkpoint)\u001b[37m\u001b[39;49;00m\n",
      "            model.load_state_dict(modelCheckpoint[\u001b[33m'\u001b[39;49;00m\u001b[33mstate_dict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            outGT = torch.FloatTensor().cuda()\u001b[37m\u001b[39;49;00m\n",
      "            outPRED = torch.FloatTensor().cuda()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            outGT = torch.FloatTensor()\u001b[37m\u001b[39;49;00m\n",
      "            outPRED = torch.FloatTensor()\u001b[37m\u001b[39;49;00m\n",
      "       \u001b[37m\u001b[39;49;00m\n",
      "        model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i, (\u001b[36minput\u001b[39;49;00m, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataLoaderTest):\u001b[37m\u001b[39;49;00m\n",
      "                use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target.cuda()\u001b[37m\u001b[39;49;00m\n",
      "                    outGT = torch.cat((outGT, target), \u001b[34m0\u001b[39;49;00m).cuda()\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                    target = target\u001b[37m\u001b[39;49;00m\n",
      "                    outGT = torch.cat((outGT, target), \u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "                bs, c, h, w = \u001b[36minput\u001b[39;49;00m.size()\u001b[37m\u001b[39;49;00m\n",
      "                varInput = \u001b[36minput\u001b[39;49;00m.view(-\u001b[34m1\u001b[39;49;00m, c, h, w)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "                out = model(varInput)\u001b[37m\u001b[39;49;00m\n",
      "                outPRED = torch.cat((outPRED, out), \u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        aurocIndividual = CheXpertTrainer.computeAUROC(outGT, outPRED, nnClassCount)\u001b[37m\u001b[39;49;00m\n",
      "        aurocMean = np.array(aurocIndividual).mean()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m (\u001b[33m'\u001b[39;49;00m\u001b[33mAUROC mean \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, aurocMean)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m (\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(aurocIndividual)):\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m (class_names[i], \u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, aurocIndividual[i])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m outGT, outPRED\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mDenseNet121\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"Model modified.\u001b[39;49;00m\n",
      "\u001b[33m    The architecture of our model is the same as standard DenseNet121\u001b[39;49;00m\n",
      "\u001b[33m    except the classifier layer which has an additional sigmoid function.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, out_size):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(DenseNet121, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.densenet121 = torchvision.models.densenet121(pretrained=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        num_ftrs = \u001b[36mself\u001b[39;49;00m.densenet121.classifier.in_features\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.densenet121.classifier = nn.Sequential(\u001b[37m\u001b[39;49;00m\n",
      "            nn.Linear(num_ftrs, out_size),\u001b[37m\u001b[39;49;00m\n",
      "            nn.Sigmoid()\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.densenet121(x)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_dataloader\u001b[39;49;00m(traindir,testdir,validdir,batch_size=\u001b[34m128\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    image_transforms = {\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Train uses data augmentation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m), \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# transforms.RandomHorizontalFlip(),\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "                             [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])  \u001b[37m# Imagenet standards\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    ])\u001b[37m\u001b[39;49;00m\n",
      "        ,\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Validation does not use augmentation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    ]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Test does not use augmentation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    transforms.Compose([\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Resize(size=\u001b[34m256\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.CenterCrop(size=\u001b[34m224\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\n",
      "        transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    ]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    data = {\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    datasets.ImageFolder(root=traindir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    datasets.ImageFolder(root=validdir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    datasets.ImageFolder(root=testdir, transform=image_transforms[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Dataloader iterators\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    dataloaders = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: DataLoader(data[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m data,dataloaders\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpreops\u001b[39;49;00m(traindir,testdir,validdir):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m********* inside preops *************\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtraindir\u001b[33m}\u001b[39;49;00m\u001b[33m , \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtestdir\u001b[33m}\u001b[39;49;00m\u001b[33m , \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvaliddir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Empty lists\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    categories = []\u001b[37m\u001b[39;49;00m\n",
      "    img_categories = []\u001b[37m\u001b[39;49;00m\n",
      "    n_train = []\u001b[37m\u001b[39;49;00m\n",
      "    n_valid = []\u001b[37m\u001b[39;49;00m\n",
      "    n_test = []\u001b[37m\u001b[39;49;00m\n",
      "    hs = []\u001b[37m\u001b[39;49;00m\n",
      "    ws = []\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Iterate through each category\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m d \u001b[35min\u001b[39;49;00m os.listdir(traindir):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m d.startswith(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            categories.append(d)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# Number of each image\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            train_imgs = os.listdir(traindir + d)\u001b[37m\u001b[39;49;00m\n",
      "            valid_imgs = os.listdir(validdir + d)\u001b[37m\u001b[39;49;00m\n",
      "            test_imgs = os.listdir(testdir + d)\u001b[37m\u001b[39;49;00m\n",
      "            n_train.append(\u001b[36mlen\u001b[39;49;00m(train_imgs))\u001b[37m\u001b[39;49;00m\n",
      "            n_valid.append(\u001b[36mlen\u001b[39;49;00m(valid_imgs))\u001b[37m\u001b[39;49;00m\n",
      "            n_test.append(\u001b[36mlen\u001b[39;49;00m(test_imgs))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# Find stats for train images\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m train_imgs:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m i.startswith(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                    img_categories.append(d)\u001b[37m\u001b[39;49;00m\n",
      "                    img = Image.open(traindir + d + \u001b[33m'\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + i).convert(\u001b[33m\"\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "                    img_array = np.array(img)\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[37m# Shape\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                    hs.append(img_array.shape[\u001b[34m0\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "                    ws.append(img_array.shape[\u001b[34m1\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Dataframe of categories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    cat_df = pd.DataFrame({\u001b[33m'\u001b[39;49;00m\u001b[33mcategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: categories,\u001b[37m\u001b[39;49;00m\n",
      "                           \u001b[33m'\u001b[39;49;00m\u001b[33mn_train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: n_train,\u001b[37m\u001b[39;49;00m\n",
      "                           \u001b[33m'\u001b[39;49;00m\u001b[33mn_valid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: n_valid, \u001b[33m'\u001b[39;49;00m\u001b[33mn_test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: n_test}).\\\n",
      "        sort_values(\u001b[33m'\u001b[39;49;00m\u001b[33mcategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Dataframe of training images\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    image_df = pd.DataFrame({\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mcategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: img_categories,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mheight\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: hs,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mwidth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: ws\u001b[37m\u001b[39;49;00m\n",
      "    })\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m cat_df\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mHeatmapGenerator\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m, pathModel=\u001b[34mNone\u001b[39;49;00m, nnClassCount=\u001b[34m14\u001b[39;49;00m, transCrop=\u001b[34m224\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model = DenseNet121(nnClassCount)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        use_gpu = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "            model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model = torch.load(pathModel)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model.load_state_dict(modelCheckpoint['state_dict'])\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model = model\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Initialize the weights\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.weights = \u001b[36mlist\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.model.module.densenet121.features.parameters())[-\u001b[34m2\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Initialize the image transform\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        normalize = transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        transformList = []\u001b[37m\u001b[39;49;00m\n",
      "        transformList.append(transforms.Resize((transCrop, transCrop)))\u001b[37m\u001b[39;49;00m\n",
      "        transformList.append(transforms.ToTensor())\u001b[37m\u001b[39;49;00m\n",
      "        transformList.append(normalize)  \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.transformSequence = transforms.Compose(transformList)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#--------------------------------------------------------------------------------\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "     \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mgenerate\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m, pathImageFile, pathOutputFile, transCrop):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Load image, transform, convert \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            use_gpu = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      " \u001b[37m\u001b[39;49;00m\n",
      "            imageData = Image.open(pathImageFile).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            imageData = \u001b[36mself\u001b[39;49;00m.transformSequence(imageData)\u001b[37m\u001b[39;49;00m\n",
      "            imageData = imageData.unsqueeze_(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "                imageData = imageData\u001b[37m\u001b[39;49;00m\n",
      "            l = \u001b[36mself\u001b[39;49;00m.model(imageData)\u001b[37m\u001b[39;49;00m\n",
      "            output = \u001b[36mself\u001b[39;49;00m.model.module.densenet121.features(imageData)\u001b[37m\u001b[39;49;00m\n",
      "            label = class_names[torch.max(l,\u001b[34m1\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]]\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m#---- Generate heatmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            heatmap = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m (\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.weights)):\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mmap\u001b[39;49;00m = output[\u001b[34m0\u001b[39;49;00m,i,:,:]\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m i == \u001b[34m0\u001b[39;49;00m: heatmap = \u001b[36mself\u001b[39;49;00m.weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34melse\u001b[39;49;00m: heatmap += \u001b[36mself\u001b[39;49;00m.weights[i] * \u001b[36mmap\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                npHeatmap = heatmap.cpu().data.numpy()\u001b[37m\u001b[39;49;00m\n",
      "        cam = npHeatmap / np.max(npHeatmap)\u001b[37m\u001b[39;49;00m\n",
      "        cam = cv2.resize(cam, (transCrop, transCrop))\u001b[37m\u001b[39;49;00m\n",
      "        heatmap = cv2.applyColorMap(np.uint8(\u001b[34m255\u001b[39;49;00m*cam), cv2.COLORMAP_JET)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---- Blend original and heatmap \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        temp = heatmap.copy()\u001b[37m\u001b[39;49;00m\n",
      "        img = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(img.min())\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# print(img.shape)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        img = (img/\u001b[34m1\u001b[39;49;00m).astype(\u001b[33m'\u001b[39;49;00m\u001b[33muint8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        binary = threshold(\u001b[34m200\u001b[39;49;00m,\u001b[34m255\u001b[39;49;00m,img)\u001b[37m\u001b[39;49;00m\n",
      "        binary = binary.astype(np.int32)\u001b[37m\u001b[39;49;00m\n",
      "        contours, _ = cv2.findContours(binary,cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE) \u001b[37m\u001b[39;49;00m\n",
      "        multi_data = []\u001b[37m\u001b[39;49;00m\n",
      "        multidata_dict={}\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mROIFormat.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m json_file:\u001b[37m\u001b[39;49;00m\n",
      "            data_orig = json.load(json_file)\u001b[37m\u001b[39;49;00m\n",
      "        coords = get_1D_coord(contours)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m coord \u001b[35min\u001b[39;49;00m coords:\u001b[37m\u001b[39;49;00m\n",
      "            data_final = get_json(data = data_orig, coord=coord)\u001b[37m\u001b[39;49;00m\n",
      "            multi_data.append(deepcopy(data_final[\u001b[33m'\u001b[39;49;00m\u001b[33mallTools\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "        multidata_dict[\u001b[33m'\u001b[39;49;00m\u001b[33mallTools\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = multi_data\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mFINAL JSON\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(multidata_dict)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         imgOriginal = cv2.imread(pathImageFile, 1)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         imgOriginal = cv2.resize(imgOriginal, (transCrop, transCrop))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         img = cv2.addWeighted(imgOriginal,1,heatmap,0.35,0)            \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.title(label)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.imshow(img)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.plot()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.axis('off')\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.savefig(pathOutputFile)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#         plt.show()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mrun\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    batch_size = \u001b[34m128\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    traindir = args.data_dir_train + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#datadir + '/train/'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    validdir = args.data_dir_val + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#datadir + '/val/'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    testdir = args.data_dir_test + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#datadir + '/test/'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "    pathFileTrain = args.data_dir_train\u001b[37m\u001b[39;49;00m\n",
      "    pathFileValid = args.data_dir_val\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Neural network parameters:\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    nnIsTrained = \u001b[34mFalse\u001b[39;49;00m                 \u001b[37m#pre-trained using ImageNet\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    nnClassCount = \u001b[34m14\u001b[39;49;00m                   \u001b[37m#dimension of the output\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Training settings: batch size, maximum number of epochs\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trBatchSize = \u001b[34m64\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trMaxEpoch = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Parameters related to image transforms: size of the down-scaled image, cropped image\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    imgtransResize = (\u001b[34m320\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    imgtransCrop = \u001b[34m224\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Class names\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    class_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mNo Finding\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEnlarged Cardiomediastinum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCardiomegaly\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mLung Opacity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mLung Lesion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mEdema\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mConsolidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumonia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAtelectasis\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPneumothorax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Effusion\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mPleural Other\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mFracture\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSupport Devices\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#TRANSFORM DATA\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    normalize = transforms.Normalize([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m], [\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    transformList = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#transformList.append(transforms.Resize(imgtransCrop))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(transforms.RandomResizedCrop(imgtransCrop))\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(transforms.RandomHorizontalFlip())\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(transforms.ToTensor())\u001b[37m\u001b[39;49;00m\n",
      "    transformList.append(normalize)      \u001b[37m\u001b[39;49;00m\n",
      "    transformSequence=transforms.Compose(transformList)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#LOAD DATASET\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# cat_df = preops(traindir,testdir,validdir)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    nnClassCount = \u001b[36mlen\u001b[39;49;00m(class_names)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    data,dataloaders = create_dataloader(traindir,testdir,validdir,batch_size)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    dataset = CheXpertDataSet(pathFileTrain ,transformSequence, policy=\u001b[33m\"\u001b[39;49;00m\u001b[33mones\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    datasetTest, datasetTrain = random_split(dataset, [\u001b[34m1\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(dataset) - \u001b[34m1\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    datasetValid = CheXpertDataSet(pathFileValid, transformSequence)            \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# dataLoaderTrain = dataloaders[\"train\"]#DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=24, pin_memory=True)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# dataLoaderVal = dataloaders[\"val\"]#DataLoader(dataset=datasetValid, batch_size=trBatchSize, shuffle=False, num_workers=24, pin_memory=True)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# dataLoaderTest = dataloaders[\"test\"]#DataLoader(dataset=datasetTest, num_workers=24, pin_memory=True)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=\u001b[34mTrue\u001b[39;49;00m,  num_workers=\u001b[34m24\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dataLoaderVal = DataLoader(dataset=datasetValid, batch_size=trBatchSize, shuffle=\u001b[34mFalse\u001b[39;49;00m, num_workers=\u001b[34m24\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dataLoaderTest = DataLoader(dataset=datasetTest, num_workers=\u001b[34m24\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# initialize and load the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    use_gpu = torch.cuda.is_available()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m use_gpu:\u001b[37m\u001b[39;49;00m\n",
      "        model = DenseNet121(nnClassCount).cuda()\u001b[37m\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model).cuda()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        model = DenseNet121(nnClassCount)\u001b[37m\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    timestampTime = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    timestampDate = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    timestampLaunch = timestampDate + \u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + timestampTime\u001b[37m\u001b[39;49;00m\n",
      "    save_path = args.model_dir\u001b[37m\u001b[39;49;00m\n",
      "    batch, losst, losse = CheXpertTrainer.train(model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, timestampLaunch, \u001b[34mNone\u001b[39;49;00m, save_path)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel trained\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    losstn = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(losst), \u001b[34m35\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        losstn.append(np.mean(losst[i:i+\u001b[34m35\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(losstn)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(losse)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m64\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m1000\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "   \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m100\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir-train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir-test\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TESTING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir-val\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    args = parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    run(args)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters. In this case we are going to run our training job on 2 ```ml.c4.xlarge``` instances. But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)). The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the `classifier.py` script above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==2.152.0\n",
      "  Downloading sagemaker-2.152.0.tar.gz (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.1/751.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (22.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.26.111)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.21.6)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (3.20.3)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.0.1)\n",
      "Collecting importlib-metadata<5.0,>=1.4.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (1.3.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (0.7.5)\n",
      "Collecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.152.0) (3.2.0)\n",
      "Collecting tblib==1.7.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.111 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.152.0) (1.29.111)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.152.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.152.0) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.152.0) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.152.0) (4.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.152.0) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.152.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker==2.152.0) (59.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker==2.152.0) (0.15.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.152.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.152.0) (2019.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (0.3.2)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.152.0) (1.7.6.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker==2.152.0) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.111->boto3<2.0,>=1.26.28->sagemaker==2.152.0) (1.26.15)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.152.0-py2.py3-none-any.whl size=1007509 sha256=1c4428c07b5db3a84ab007499d1bc299f2d67a9c7bfe46f63b3e9c5616d587b0\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/5b/a4/ad61c362425ff3ffeb666f9dc85274cb0d6271f7d897c976df\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: tblib, PyYAML, importlib-metadata, sagemaker\n",
      "  Attempting uninstall: tblib\n",
      "    Found existing installation: tblib 1.6.0\n",
      "    Uninstalling tblib-1.6.0:\n",
      "      Successfully uninstalled tblib-1.6.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.3.0\n",
      "    Uninstalling importlib-metadata-6.3.0:\n",
      "      Successfully uninstalled importlib-metadata-6.3.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.145.0\n",
      "    Uninstalling sagemaker-2.145.0:\n",
      "      Successfully uninstalled sagemaker-2.145.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "awscli 1.27.111 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-5.4.1 importlib-metadata-4.13.0 sagemaker-2.152.0 tblib-1.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker==2.152.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.152.0\n"
     ]
    }
   ],
   "source": [
    "!pip show sagemaker | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"classifier.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.12.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    # instance_type=\"ml.g4dn.xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},\n",
    "    dependencies=['code/requirements.txt'],\n",
    "    source_dir = \"code\",\n",
    "    max_run=20,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-06-20-11-49-10-213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-20 11:49:21 Starting - Starting the training job...\n",
      "2023-06-20 11:49:34 Starting - Preparing the instances for training...\n",
      "2023-06-20 11:50:22 Downloading - Downloading input data......\n",
      "2023-06-20 11:50:57 Training - Downloading the training image...\n",
      "2023-06-20 11:51:48 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:51,515 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:51,523 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:51,531 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:51,533 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:52,191 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[34mCollecting pydicom\u001b[0m\n",
      "\u001b[34mDownloading pydicom-2.4.1-py3-none-any.whl (1.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 53.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.22.2)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary\u001b[0m\n",
      "\u001b[34mDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.4.3)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless\u001b[0m\n",
      "\u001b[34mDownloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.2/49.2 MB 40.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (3.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 7)) (2022.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 7)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchsummary, pydicom, opencv-python-headless\u001b[0m\n",
      "\u001b[34mSuccessfully installed opencv-python-headless-4.7.0.72 pydicom-2.4.1 torchsummary-1.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.1.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:56,283 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:56,284 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:56,287 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:56,299 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:56,310 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-06-20 11:51:56,318 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validating\": \"/opt/ml/input/data/validating\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validating\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2023-06-20-11-49-10-213\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-20-11-49-10-213/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"classifier\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"classifier.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=classifier.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validating\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\",\"validating\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=classifier\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-20-11-49-10-213/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\",\"validating\":\"/opt/ml/input/data/validating\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validating\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2023-06-20-11-49-10-213\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-20-11-49-10-213/source/sourcedir.tar.gz\",\"module_name\":\"classifier\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"classifier.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATING=/opt/ml/input/data/validating\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 classifier.py --backend gloo --epochs 1\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:559: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m>>>>>>>>>>>>>>>>>>> MODEL LOADED SUCCESSFULLY >>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[2023-06-20 11:51:59.250 algo-1:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-06-20 11:51:59.422 algo-1:39 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-06-20 11:51:59.424 algo-1:39 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-06-20 11:51:59.424 algo-1:39 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-06-20 11:51:59.425 algo-1:39 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-06-20 11:51:59.425 algo-1:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m0 % batches computed\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:559: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[34m0\u001b[0m\n",
      "\u001b[34m40.21757888793945\u001b[0m\n",
      "\u001b[34m51.81035232543945\u001b[0m\n",
      "\u001b[34mEpoch [1] [----] [20062023-115202] loss= tensor(50.2272)\u001b[0m\n",
      "\u001b[34mModel trained\u001b[0m\n",
      "\u001b[34m[40.21757888793945]\u001b[0m\n",
      "\u001b[34m[51.81035232543945]\u001b[0m\n",
      "\u001b[34m2023-06-20 11:52:02,758 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-20 11:52:02,758 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-20 11:52:02,759 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-06-20 11:52:24 Uploading - Uploading generated training model\n",
      "2023-06-20 11:52:24 Completed - Training job completed\n",
      "Training seconds: 122\n",
      "Billable seconds: 122\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    {\n",
    "        \"training\":\"s3://\"+bucket+\"/data/train\" ,\n",
    "        \"testing\":\"s3://\"+bucket+\"/data/train\",\n",
    "        \"validating\":\"s3://\"+bucket+\"/data/train\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Host your model in Sagemaker\n",
    "### Create endpoint\n",
    "After training, we use the `PyTorch` estimator object to build and deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `classifier.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `classifier.py`. Here we will deploy the model to a single ```ml.m4.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'framework_version': '1.12.0',\n",
       " 'py_version': 'py38',\n",
       " 'instance_count': 1,\n",
       " 'instance_type': 'ml.m5.large',\n",
       " 'keep_alive_period_in_seconds': None,\n",
       " 'instance_groups': None,\n",
       " 'volume_size': 30,\n",
       " 'max_run': 20,\n",
       " 'input_mode': 'File',\n",
       " 'metric_definitions': None,\n",
       " 'model_uri': None,\n",
       " 'model_channel_name': 'model',\n",
       " 'code_uri': None,\n",
       " 'code_channel_name': 'code',\n",
       " 'source_dir': 'code',\n",
       " 'git_config': None,\n",
       " 'container_log_level': 20,\n",
       " '_hyperparameters': {'epochs': 1,\n",
       "  'backend': 'gloo',\n",
       "  'sagemaker_submit_directory': 's3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-20-11-49-10-213/source/sourcedir.tar.gz',\n",
       "  'sagemaker_program': 'classifier.py',\n",
       "  'sagemaker_container_log_level': 20,\n",
       "  'sagemaker_job_name': 'pytorch-training-2023-06-20-11-49-10-213',\n",
       "  'sagemaker_region': 'ap-south-1'},\n",
       " 'code_location': None,\n",
       " 'entry_point': 'classifier.py',\n",
       " 'dependencies': ['code/requirements.txt'],\n",
       " 'uploaded_code': UserCode(s3_prefix='s3://sagemaker-ap-south-1-023180687239/pytorch-training-2023-06-20-11-49-10-213/source/sourcedir.tar.gz', script_name='classifier.py'),\n",
       " 'tags': None,\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7f8c5ed1d690>,\n",
       " 'base_job_name': 'pytorch-training',\n",
       " '_current_job_name': 'pytorch-training-2023-06-20-11-49-10-213',\n",
       " 'output_path': 's3://sagemaker-ap-south-1-023180687239/',\n",
       " 'latest_training_job': <sagemaker.estimator._TrainingJob at 0x7f8c5d2dcc90>,\n",
       " 'jobs': [<sagemaker.estimator._TrainingJob at 0x7f8c5d2dcc90>],\n",
       " 'deploy_instance_type': None,\n",
       " '_compiled_models': {},\n",
       " 'role': 'arn:aws:iam::023180687239:role/service-role/AmazonSageMaker-ExecutionRole-20220906T142944',\n",
       " 'output_kms_key': None,\n",
       " 'volume_kms_key': None,\n",
       " 'subnets': None,\n",
       " 'security_group_ids': None,\n",
       " 'training_repository_access_mode': None,\n",
       " 'training_repository_credentials_provider_arn': None,\n",
       " 'encrypt_inter_container_traffic': False,\n",
       " 'use_spot_instances': False,\n",
       " 'max_wait': None,\n",
       " 'checkpoint_s3_uri': None,\n",
       " 'checkpoint_local_path': None,\n",
       " 'rules': None,\n",
       " 'debugger_hook_config': <sagemaker.debugger.debugger.DebuggerHookConfig at 0x7f8c5f64f250>,\n",
       " 'tensorboard_output_config': None,\n",
       " 'debugger_rule_configs': [],\n",
       " 'collection_configs': set(),\n",
       " 'enable_sagemaker_metrics': True,\n",
       " '_enable_network_isolation': False,\n",
       " 'profiler_config': <sagemaker.debugger.profiler_config.ProfilerConfig at 0x7f8c5f64f450>,\n",
       " 'disable_profiler': False,\n",
       " 'environment': None,\n",
       " 'max_retry_attempts': None,\n",
       " 'profiler_rule_configs': [],\n",
       " 'profiler_rules': [],\n",
       " 'debugger_rules': [],\n",
       " 'image_uri': None,\n",
       " 'distribution': {},\n",
       " 'compiler_config': None}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_job_name = estimator._hyperparameters[\"sagemaker_job_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: pytorch-training-2023-06-20-11-52-34-872\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-2023-06-20-11-52-34-872\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2023-06-20-11-52-34-872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.2xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "You can use the test images to evalute the endpoint. The accuracy of the model depends on how many it is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endpoint_name': 'pytorch-training-2023-06-20-11-52-34-872',\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7f8c5ed1d690>,\n",
       " 'serializer': <sagemaker.serializers.NumpySerializer at 0x7f8c5e834a50>,\n",
       " 'deserializer': <sagemaker.deserializers.NumpyDeserializer at 0x7f8c5e8348d0>,\n",
       " '_endpoint_config_name': None,\n",
       " '_model_names': None,\n",
       " '_context': None}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-training-2023-06-20-11-52-34-872'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Invoke endpoint and test your model in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '7ee1c519-bf5d-450a-8efc-e6321bd6b32f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7ee1c519-bf5d-450a-8efc-e6321bd6b32f', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Tue, 20 Jun 2023 11:55:12 GMT', 'content-type': 'application/json', 'content-length': '16249', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7f8c5cebbb90>}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "custom_attributes = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.\n",
    "endpoint_name = \"test\"#predictor.endpoint_name                                        # Your endpoint name.\n",
    "content_type = \"application/json\"                                        # The MIME type of the input data in the request body.\n",
    "accept = \"application/json\"                                              # The desired MIME type of the inference in the response.\n",
    "payload = json.dumps({\"url\":\"https://storage.googleapis.com/kaggle-datasets-images/17810/23340/c8372ebbe20b0f671c2f3c501ba51412/dataset-cover.jpeg?t=2018-03-24-19-05-18\"})                                           # Payload for inference.\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    CustomAttributes=custom_attributes, \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=payload\n",
    "    )\n",
    "\n",
    "print(response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Body': <botocore.response.StreamingBody object at 0x7f8c5cebbb90>,\n",
      " 'ContentType': 'application/json',\n",
      " 'InvokedProductionVariant': 'AllTraffic',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
      "                                      'content-length': '16249',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'date': 'Tue, 20 Jun 2023 11:55:12 GMT',\n",
      "                                      'x-amzn-invoked-production-variant': 'AllTraffic',\n",
      "                                      'x-amzn-requestid': '7ee1c519-bf5d-450a-8efc-e6321bd6b32f'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '7ee1c519-bf5d-450a-8efc-e6321bd6b32f',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = json.load(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': {'findings': [{'name': 'No Finding',\n",
       "    'probability': 0.15899339318275452},\n",
       "   {'name': 'Enlarged Cardiomediastinum', 'probability': 0.05995656177401543},\n",
       "   {'name': 'Cardiomegaly', 'probability': 0.29158324003219604},\n",
       "   {'name': 'Lung Opacity', 'probability': 0.4886914789676666},\n",
       "   {'name': 'Lung Lesion', 'probability': 0.08378386497497559},\n",
       "   {'name': 'Edema', 'probability': 0.21401825547218323},\n",
       "   {'name': 'Consolidation', 'probability': 0.13959090411663055},\n",
       "   {'name': 'Pneumonia', 'probability': 0.47525912523269653},\n",
       "   {'name': 'Atelectasis', 'probability': 0.21938934922218323},\n",
       "   {'name': 'Pneumothorax', 'probability': 0.3522780239582062},\n",
       "   {'name': 'Pleural Effusion', 'probability': 0.2807219922542572},\n",
       "   {'name': 'Pleural Other', 'probability': 0.03510424494743347},\n",
       "   {'name': 'Fracture', 'probability': 0.08782097697257996},\n",
       "   {'name': 'Support Devices', 'probability': 0.034316133707761765}],\n",
       "  'rois': [{'finding_name': '0',\n",
       "    'type': 'Freehand',\n",
       "    'points': [[630.0, 178.0],\n",
       "     [632.0, 178.0],\n",
       "     [633.0, 179.0],\n",
       "     [635.0, 179.0],\n",
       "     [636.0, 180.0],\n",
       "     [638.0, 180.0],\n",
       "     [639.0, 181.0],\n",
       "     [640.0, 181.0],\n",
       "     [641.0, 182.0],\n",
       "     [643.0, 182.0],\n",
       "     [644.0, 183.0],\n",
       "     [646.0, 183.0],\n",
       "     [647.0, 184.0],\n",
       "     [649.0, 184.0],\n",
       "     [650.0, 185.0],\n",
       "     [651.0, 185.0],\n",
       "     [652.0, 186.0],\n",
       "     [654.0, 186.0],\n",
       "     [655.0, 187.0],\n",
       "     [657.0, 187.0],\n",
       "     [658.0, 188.0],\n",
       "     [660.0, 188.0],\n",
       "     [661.0, 189.0],\n",
       "     [661.0, 197.0],\n",
       "     [662.0, 198.0],\n",
       "     [662.0, 199.0],\n",
       "     [661.0, 200.0],\n",
       "     [661.0, 205.0],\n",
       "     [662.0, 206.0],\n",
       "     [662.0, 213.0],\n",
       "     [663.0, 214.0],\n",
       "     [662.0, 215.0],\n",
       "     [663.0, 216.0],\n",
       "     [663.0, 217.0],\n",
       "     [664.0, 218.0],\n",
       "     [664.0, 226.0],\n",
       "     [665.0, 227.0],\n",
       "     [665.0, 232.0],\n",
       "     [666.0, 233.0],\n",
       "     [666.0, 237.0],\n",
       "     [667.0, 237.0],\n",
       "     [668.0, 238.0],\n",
       "     [668.0, 239.0],\n",
       "     [669.0, 240.0],\n",
       "     [669.0, 244.0],\n",
       "     [670.0, 244.0],\n",
       "     [671.0, 245.0],\n",
       "     [671.0, 246.0],\n",
       "     [672.0, 246.0],\n",
       "     [673.0, 247.0],\n",
       "     [673.0, 248.0],\n",
       "     [674.0, 248.0],\n",
       "     [675.0, 249.0],\n",
       "     [675.0, 250.0],\n",
       "     [677.0, 250.0],\n",
       "     [678.0, 251.0],\n",
       "     [677.0, 252.0],\n",
       "     [679.0, 252.0],\n",
       "     [680.0, 253.0],\n",
       "     [681.0, 253.0],\n",
       "     [682.0, 254.0],\n",
       "     [682.0, 257.0],\n",
       "     [683.0, 258.0],\n",
       "     [683.0, 263.0],\n",
       "     [684.0, 264.0],\n",
       "     [684.0, 269.0],\n",
       "     [685.0, 270.0],\n",
       "     [685.0, 276.0],\n",
       "     [686.0, 277.0],\n",
       "     [686.0, 283.0],\n",
       "     [687.0, 284.0],\n",
       "     [687.0, 291.0],\n",
       "     [688.0, 292.0],\n",
       "     [688.0, 298.0],\n",
       "     [687.0, 299.0],\n",
       "     [687.0, 300.0],\n",
       "     [686.0, 301.0],\n",
       "     [686.0, 302.0],\n",
       "     [685.0, 303.0],\n",
       "     [685.0, 304.0],\n",
       "     [683.0, 306.0],\n",
       "     [683.0, 307.0],\n",
       "     [681.0, 309.0],\n",
       "     [667.0, 309.0],\n",
       "     [666.0, 308.0],\n",
       "     [665.0, 309.0],\n",
       "     [662.0, 309.0],\n",
       "     [661.0, 308.0],\n",
       "     [642.0, 308.0],\n",
       "     [641.0, 307.0],\n",
       "     [631.0, 307.0],\n",
       "     [630.0, 306.0],\n",
       "     [628.0, 306.0],\n",
       "     [627.0, 307.0],\n",
       "     [625.0, 305.0],\n",
       "     [625.0, 304.0],\n",
       "     [624.0, 303.0],\n",
       "     [624.0, 302.0],\n",
       "     [622.0, 300.0],\n",
       "     [622.0, 299.0],\n",
       "     [621.0, 298.0],\n",
       "     [621.0, 295.0],\n",
       "     [620.0, 294.0],\n",
       "     [620.0, 289.0],\n",
       "     [619.0, 288.0],\n",
       "     [619.0, 283.0],\n",
       "     [618.0, 282.0],\n",
       "     [618.0, 278.0],\n",
       "     [617.0, 277.0],\n",
       "     [617.0, 273.0],\n",
       "     [616.0, 272.0],\n",
       "     [616.0, 269.0],\n",
       "     [615.0, 268.0],\n",
       "     [615.0, 267.0],\n",
       "     [614.0, 266.0],\n",
       "     [614.0, 262.0],\n",
       "     [613.0, 261.0],\n",
       "     [613.0, 260.0],\n",
       "     [612.0, 259.0],\n",
       "     [612.0, 258.0],\n",
       "     [611.0, 257.0],\n",
       "     [611.0, 256.0],\n",
       "     [610.0, 255.0],\n",
       "     [610.0, 253.0],\n",
       "     [607.0, 250.0],\n",
       "     [607.0, 249.0],\n",
       "     [606.0, 248.0],\n",
       "     [606.0, 247.0],\n",
       "     [605.0, 247.0],\n",
       "     [604.0, 246.0],\n",
       "     [604.0, 245.0],\n",
       "     [602.0, 243.0],\n",
       "     [602.0, 241.0],\n",
       "     [601.0, 240.0],\n",
       "     [601.0, 235.0],\n",
       "     [600.0, 234.0],\n",
       "     [600.0, 225.0],\n",
       "     [599.0, 224.0],\n",
       "     [599.0, 220.0],\n",
       "     [598.0, 219.0],\n",
       "     [599.0, 218.0],\n",
       "     [599.0, 215.0],\n",
       "     [598.0, 214.0],\n",
       "     [598.0, 213.0],\n",
       "     [599.0, 212.0],\n",
       "     [598.0, 211.0],\n",
       "     [598.0, 201.0],\n",
       "     [597.0, 200.0],\n",
       "     [597.0, 192.0],\n",
       "     [596.0, 191.0],\n",
       "     [596.0, 189.0],\n",
       "     [597.0, 188.0],\n",
       "     [598.0, 188.0],\n",
       "     [599.0, 187.0],\n",
       "     [601.0, 187.0],\n",
       "     [602.0, 186.0],\n",
       "     [603.0, 186.0],\n",
       "     [604.0, 185.0],\n",
       "     [606.0, 185.0],\n",
       "     [607.0, 184.0],\n",
       "     [608.0, 184.0],\n",
       "     [609.0, 183.0],\n",
       "     [611.0, 183.0],\n",
       "     [612.0, 182.0],\n",
       "     [613.0, 182.0],\n",
       "     [614.0, 181.0],\n",
       "     [616.0, 181.0],\n",
       "     [617.0, 180.0],\n",
       "     [618.0, 180.0],\n",
       "     [619.0, 179.0],\n",
       "     [621.0, 179.0],\n",
       "     [622.0, 178.0],\n",
       "     [624.0, 178.0],\n",
       "     [625.0, 177.0],\n",
       "     [629.0, 177.0],\n",
       "     [630.0, 178.0]]},\n",
       "   {'finding_name': '1',\n",
       "    'type': 'Freehand',\n",
       "    'points': [[625.0, 178.0],\n",
       "     [624.0, 179.0],\n",
       "     [622.0, 179.0],\n",
       "     [621.0, 180.0],\n",
       "     [619.0, 180.0],\n",
       "     [618.0, 181.0],\n",
       "     [617.0, 181.0],\n",
       "     [616.0, 182.0],\n",
       "     [614.0, 182.0],\n",
       "     [613.0, 183.0],\n",
       "     [612.0, 183.0],\n",
       "     [611.0, 184.0],\n",
       "     [609.0, 184.0],\n",
       "     [608.0, 185.0],\n",
       "     [607.0, 185.0],\n",
       "     [606.0, 186.0],\n",
       "     [604.0, 186.0],\n",
       "     [603.0, 187.0],\n",
       "     [602.0, 187.0],\n",
       "     [601.0, 188.0],\n",
       "     [599.0, 188.0],\n",
       "     [598.0, 189.0],\n",
       "     [597.0, 189.0],\n",
       "     [597.0, 191.0],\n",
       "     [598.0, 192.0],\n",
       "     [598.0, 200.0],\n",
       "     [599.0, 201.0],\n",
       "     [599.0, 211.0],\n",
       "     [600.0, 212.0],\n",
       "     [599.0, 213.0],\n",
       "     [599.0, 214.0],\n",
       "     [600.0, 215.0],\n",
       "     [600.0, 218.0],\n",
       "     [599.0, 219.0],\n",
       "     [600.0, 220.0],\n",
       "     [600.0, 224.0],\n",
       "     [601.0, 225.0],\n",
       "     [601.0, 234.0],\n",
       "     [602.0, 235.0],\n",
       "     [602.0, 240.0],\n",
       "     [603.0, 241.0],\n",
       "     [603.0, 243.0],\n",
       "     [605.0, 245.0],\n",
       "     [605.0, 246.0],\n",
       "     [606.0, 246.0],\n",
       "     [607.0, 247.0],\n",
       "     [607.0, 248.0],\n",
       "     [608.0, 249.0],\n",
       "     [608.0, 250.0],\n",
       "     [611.0, 253.0],\n",
       "     [611.0, 255.0],\n",
       "     [612.0, 256.0],\n",
       "     [612.0, 257.0],\n",
       "     [613.0, 258.0],\n",
       "     [613.0, 259.0],\n",
       "     [614.0, 260.0],\n",
       "     [614.0, 261.0],\n",
       "     [615.0, 262.0],\n",
       "     [615.0, 266.0],\n",
       "     [616.0, 267.0],\n",
       "     [616.0, 268.0],\n",
       "     [617.0, 269.0],\n",
       "     [617.0, 272.0],\n",
       "     [618.0, 273.0],\n",
       "     [618.0, 277.0],\n",
       "     [619.0, 278.0],\n",
       "     [619.0, 282.0],\n",
       "     [620.0, 283.0],\n",
       "     [620.0, 288.0],\n",
       "     [621.0, 289.0],\n",
       "     [621.0, 294.0],\n",
       "     [622.0, 295.0],\n",
       "     [622.0, 298.0],\n",
       "     [623.0, 299.0],\n",
       "     [623.0, 300.0],\n",
       "     [625.0, 302.0],\n",
       "     [625.0, 303.0],\n",
       "     [626.0, 304.0],\n",
       "     [626.0, 305.0],\n",
       "     [627.0, 306.0],\n",
       "     [628.0, 305.0],\n",
       "     [630.0, 305.0],\n",
       "     [631.0, 306.0],\n",
       "     [641.0, 306.0],\n",
       "     [642.0, 307.0],\n",
       "     [661.0, 307.0],\n",
       "     [662.0, 308.0],\n",
       "     [665.0, 308.0],\n",
       "     [666.0, 307.0],\n",
       "     [667.0, 308.0],\n",
       "     [681.0, 308.0],\n",
       "     [682.0, 307.0],\n",
       "     [682.0, 306.0],\n",
       "     [684.0, 304.0],\n",
       "     [684.0, 303.0],\n",
       "     [685.0, 302.0],\n",
       "     [685.0, 301.0],\n",
       "     [686.0, 300.0],\n",
       "     [686.0, 299.0],\n",
       "     [687.0, 298.0],\n",
       "     [687.0, 292.0],\n",
       "     [686.0, 291.0],\n",
       "     [686.0, 284.0],\n",
       "     [685.0, 283.0],\n",
       "     [685.0, 277.0],\n",
       "     [684.0, 276.0],\n",
       "     [684.0, 270.0],\n",
       "     [683.0, 269.0],\n",
       "     [683.0, 264.0],\n",
       "     [682.0, 263.0],\n",
       "     [682.0, 258.0],\n",
       "     [681.0, 257.0],\n",
       "     [681.0, 254.0],\n",
       "     [680.0, 254.0],\n",
       "     [679.0, 253.0],\n",
       "     [677.0, 253.0],\n",
       "     [676.0, 252.0],\n",
       "     [677.0, 251.0],\n",
       "     [675.0, 251.0],\n",
       "     [674.0, 250.0],\n",
       "     [674.0, 249.0],\n",
       "     [673.0, 249.0],\n",
       "     [672.0, 248.0],\n",
       "     [672.0, 247.0],\n",
       "     [671.0, 247.0],\n",
       "     [670.0, 246.0],\n",
       "     [670.0, 245.0],\n",
       "     [669.0, 245.0],\n",
       "     [668.0, 244.0],\n",
       "     [668.0, 240.0],\n",
       "     [667.0, 239.0],\n",
       "     [667.0, 238.0],\n",
       "     [666.0, 238.0],\n",
       "     [665.0, 237.0],\n",
       "     [665.0, 233.0],\n",
       "     [664.0, 232.0],\n",
       "     [664.0, 227.0],\n",
       "     [663.0, 226.0],\n",
       "     [663.0, 218.0],\n",
       "     [662.0, 217.0],\n",
       "     [662.0, 216.0],\n",
       "     [661.0, 215.0],\n",
       "     [662.0, 214.0],\n",
       "     [661.0, 213.0],\n",
       "     [661.0, 206.0],\n",
       "     [660.0, 205.0],\n",
       "     [660.0, 200.0],\n",
       "     [661.0, 199.0],\n",
       "     [661.0, 198.0],\n",
       "     [660.0, 197.0],\n",
       "     [660.0, 189.0],\n",
       "     [658.0, 189.0],\n",
       "     [657.0, 188.0],\n",
       "     [655.0, 188.0],\n",
       "     [654.0, 187.0],\n",
       "     [652.0, 187.0],\n",
       "     [651.0, 186.0],\n",
       "     [650.0, 186.0],\n",
       "     [649.0, 185.0],\n",
       "     [647.0, 185.0],\n",
       "     [646.0, 184.0],\n",
       "     [644.0, 184.0],\n",
       "     [643.0, 183.0],\n",
       "     [641.0, 183.0],\n",
       "     [640.0, 182.0],\n",
       "     [639.0, 182.0],\n",
       "     [638.0, 181.0],\n",
       "     [636.0, 181.0],\n",
       "     [635.0, 180.0],\n",
       "     [633.0, 180.0],\n",
       "     [632.0, 179.0],\n",
       "     [630.0, 179.0],\n",
       "     [629.0, 178.0],\n",
       "     [625.0, 178.0]]},\n",
       "   {'finding_name': '2',\n",
       "    'type': 'Freehand',\n",
       "    'points': [[1284.0, 123.0],\n",
       "     [1285.0, 123.0],\n",
       "     [1287.0, 125.0],\n",
       "     [1288.0, 125.0],\n",
       "     [1291.0, 128.0],\n",
       "     [1292.0, 128.0],\n",
       "     [1295.0, 131.0],\n",
       "     [1296.0, 131.0],\n",
       "     [1301.0, 136.0],\n",
       "     [1301.0, 137.0],\n",
       "     [1302.0, 138.0],\n",
       "     [1302.0, 139.0],\n",
       "     [1304.0, 141.0],\n",
       "     [1304.0, 142.0],\n",
       "     [1305.0, 143.0],\n",
       "     [1305.0, 144.0],\n",
       "     [1306.0, 145.0],\n",
       "     [1306.0, 146.0],\n",
       "     [1307.0, 147.0],\n",
       "     [1307.0, 148.0],\n",
       "     [1309.0, 150.0],\n",
       "     [1309.0, 151.0],\n",
       "     [1310.0, 152.0],\n",
       "     [1310.0, 153.0],\n",
       "     [1311.0, 154.0],\n",
       "     [1311.0, 155.0],\n",
       "     [1312.0, 156.0],\n",
       "     [1312.0, 157.0],\n",
       "     [1313.0, 158.0],\n",
       "     [1313.0, 159.0],\n",
       "     [1314.0, 160.0],\n",
       "     [1314.0, 161.0],\n",
       "     [1315.0, 162.0],\n",
       "     [1315.0, 163.0],\n",
       "     [1316.0, 164.0],\n",
       "     [1316.0, 165.0],\n",
       "     [1317.0, 166.0],\n",
       "     [1317.0, 167.0],\n",
       "     [1318.0, 168.0],\n",
       "     [1318.0, 169.0],\n",
       "     [1319.0, 170.0],\n",
       "     [1319.0, 171.0],\n",
       "     [1320.0, 172.0],\n",
       "     [1320.0, 173.0],\n",
       "     [1321.0, 174.0],\n",
       "     [1321.0, 175.0],\n",
       "     [1322.0, 176.0],\n",
       "     [1322.0, 177.0],\n",
       "     [1323.0, 178.0],\n",
       "     [1323.0, 180.0],\n",
       "     [1324.0, 181.0],\n",
       "     [1324.0, 182.0],\n",
       "     [1325.0, 183.0],\n",
       "     [1325.0, 184.0],\n",
       "     [1326.0, 185.0],\n",
       "     [1326.0, 186.0],\n",
       "     [1327.0, 187.0],\n",
       "     [1327.0, 188.0],\n",
       "     [1328.0, 189.0],\n",
       "     [1328.0, 195.0],\n",
       "     [1329.0, 196.0],\n",
       "     [1329.0, 202.0],\n",
       "     [1330.0, 203.0],\n",
       "     [1330.0, 209.0],\n",
       "     [1331.0, 210.0],\n",
       "     [1331.0, 217.0],\n",
       "     [1332.0, 218.0],\n",
       "     [1332.0, 225.0],\n",
       "     [1333.0, 226.0],\n",
       "     [1333.0, 234.0],\n",
       "     [1334.0, 235.0],\n",
       "     [1334.0, 249.0],\n",
       "     [1333.0, 250.0],\n",
       "     [1333.0, 256.0],\n",
       "     [1332.0, 257.0],\n",
       "     [1332.0, 262.0],\n",
       "     [1331.0, 263.0],\n",
       "     [1331.0, 268.0],\n",
       "     [1330.0, 269.0],\n",
       "     [1330.0, 275.0],\n",
       "     [1329.0, 276.0],\n",
       "     [1329.0, 280.0],\n",
       "     [1328.0, 281.0],\n",
       "     [1328.0, 287.0],\n",
       "     [1327.0, 288.0],\n",
       "     [1327.0, 292.0],\n",
       "     [1326.0, 293.0],\n",
       "     [1326.0, 297.0],\n",
       "     [1325.0, 298.0],\n",
       "     [1325.0, 300.0],\n",
       "     [1324.0, 301.0],\n",
       "     [1324.0, 303.0],\n",
       "     [1323.0, 304.0],\n",
       "     [1323.0, 306.0],\n",
       "     [1322.0, 307.0],\n",
       "     [1322.0, 309.0],\n",
       "     [1321.0, 310.0],\n",
       "     [1321.0, 312.0],\n",
       "     [1320.0, 313.0],\n",
       "     [1320.0, 315.0],\n",
       "     [1319.0, 316.0],\n",
       "     [1319.0, 317.0],\n",
       "     [1318.0, 318.0],\n",
       "     [1318.0, 319.0],\n",
       "     [1317.0, 320.0],\n",
       "     [1317.0, 322.0],\n",
       "     [1316.0, 323.0],\n",
       "     [1316.0, 324.0],\n",
       "     [1315.0, 325.0],\n",
       "     [1315.0, 327.0],\n",
       "     [1314.0, 328.0],\n",
       "     [1314.0, 329.0],\n",
       "     [1313.0, 330.0],\n",
       "     [1313.0, 331.0],\n",
       "     [1312.0, 332.0],\n",
       "     [1312.0, 333.0],\n",
       "     [1311.0, 334.0],\n",
       "     [1311.0, 335.0],\n",
       "     [1310.0, 336.0],\n",
       "     [1310.0, 337.0],\n",
       "     [1309.0, 338.0],\n",
       "     [1309.0, 339.0],\n",
       "     [1308.0, 340.0],\n",
       "     [1308.0, 341.0],\n",
       "     [1307.0, 342.0],\n",
       "     [1307.0, 343.0],\n",
       "     [1306.0, 344.0],\n",
       "     [1306.0, 345.0],\n",
       "     [1305.0, 346.0],\n",
       "     [1305.0, 347.0],\n",
       "     [1303.0, 349.0],\n",
       "     [1303.0, 350.0],\n",
       "     [1302.0, 351.0],\n",
       "     [1302.0, 378.0],\n",
       "     [1301.0, 379.0],\n",
       "     [1162.0, 379.0],\n",
       "     [1161.0, 378.0],\n",
       "     [1161.0, 351.0],\n",
       "     [1159.0, 349.0],\n",
       "     [1159.0, 348.0],\n",
       "     [1158.0, 347.0],\n",
       "     [1158.0, 346.0],\n",
       "     [1156.0, 344.0],\n",
       "     [1156.0, 343.0],\n",
       "     [1154.0, 341.0],\n",
       "     [1154.0, 340.0],\n",
       "     [1153.0, 339.0],\n",
       "     [1153.0, 338.0],\n",
       "     [1152.0, 337.0],\n",
       "     [1152.0, 336.0],\n",
       "     [1150.0, 334.0],\n",
       "     [1150.0, 333.0],\n",
       "     [1149.0, 332.0],\n",
       "     [1149.0, 331.0],\n",
       "     [1148.0, 330.0],\n",
       "     [1148.0, 329.0],\n",
       "     [1147.0, 328.0],\n",
       "     [1147.0, 327.0],\n",
       "     [1146.0, 326.0],\n",
       "     [1146.0, 325.0],\n",
       "     [1144.0, 323.0],\n",
       "     [1144.0, 322.0],\n",
       "     [1143.0, 321.0],\n",
       "     [1143.0, 320.0],\n",
       "     [1142.0, 319.0],\n",
       "     [1142.0, 318.0],\n",
       "     [1141.0, 317.0],\n",
       "     [1141.0, 316.0],\n",
       "     [1140.0, 315.0],\n",
       "     [1140.0, 313.0],\n",
       "     [1139.0, 312.0],\n",
       "     [1139.0, 311.0],\n",
       "     [1138.0, 310.0],\n",
       "     [1138.0, 309.0],\n",
       "     [1137.0, 308.0],\n",
       "     [1137.0, 307.0],\n",
       "     [1136.0, 306.0],\n",
       "     [1136.0, 304.0],\n",
       "     [1135.0, 303.0],\n",
       "     [1135.0, 302.0],\n",
       "     [1134.0, 301.0],\n",
       "     [1134.0, 300.0],\n",
       "     [1133.0, 299.0],\n",
       "     [1133.0, 297.0],\n",
       "     [1132.0, 296.0],\n",
       "     [1132.0, 289.0],\n",
       "     [1131.0, 288.0],\n",
       "     [1131.0, 282.0],\n",
       "     [1130.0, 281.0],\n",
       "     [1130.0, 274.0],\n",
       "     [1129.0, 273.0],\n",
       "     [1129.0, 268.0],\n",
       "     [1128.0, 267.0],\n",
       "     [1128.0, 261.0],\n",
       "     [1127.0, 260.0],\n",
       "     [1127.0, 255.0],\n",
       "     [1126.0, 254.0],\n",
       "     [1126.0, 249.0],\n",
       "     [1125.0, 248.0],\n",
       "     [1125.0, 238.0],\n",
       "     [1126.0, 237.0],\n",
       "     [1126.0, 232.0],\n",
       "     [1127.0, 231.0],\n",
       "     [1127.0, 227.0],\n",
       "     [1128.0, 226.0],\n",
       "     [1128.0, 222.0],\n",
       "     [1129.0, 221.0],\n",
       "     [1129.0, 217.0],\n",
       "     [1130.0, 216.0],\n",
       "     [1130.0, 213.0],\n",
       "     [1131.0, 212.0],\n",
       "     [1131.0, 209.0],\n",
       "     [1132.0, 208.0],\n",
       "     [1132.0, 205.0],\n",
       "     [1133.0, 204.0],\n",
       "     [1133.0, 201.0],\n",
       "     [1134.0, 200.0],\n",
       "     [1134.0, 199.0],\n",
       "     [1135.0, 198.0],\n",
       "     [1135.0, 195.0],\n",
       "     [1136.0, 194.0],\n",
       "     [1136.0, 192.0],\n",
       "     [1137.0, 191.0],\n",
       "     [1137.0, 189.0],\n",
       "     [1140.0, 186.0],\n",
       "     [1140.0, 185.0],\n",
       "     [1143.0, 182.0],\n",
       "     [1143.0, 181.0],\n",
       "     [1145.0, 179.0],\n",
       "     [1145.0, 178.0],\n",
       "     [1150.0, 173.0],\n",
       "     [1150.0, 172.0],\n",
       "     [1153.0, 169.0],\n",
       "     [1153.0, 168.0],\n",
       "     [1156.0, 165.0],\n",
       "     [1156.0, 164.0],\n",
       "     [1162.0, 158.0],\n",
       "     [1162.0, 157.0],\n",
       "     [1166.0, 153.0],\n",
       "     [1166.0, 152.0],\n",
       "     [1174.0, 144.0],\n",
       "     [1175.0, 144.0],\n",
       "     [1177.0, 142.0],\n",
       "     [1178.0, 142.0],\n",
       "     [1179.0, 141.0],\n",
       "     [1180.0, 141.0],\n",
       "     [1182.0, 139.0],\n",
       "     [1183.0, 139.0],\n",
       "     [1185.0, 137.0],\n",
       "     [1186.0, 137.0],\n",
       "     [1188.0, 135.0],\n",
       "     [1189.0, 135.0],\n",
       "     [1190.0, 134.0],\n",
       "     [1192.0, 134.0],\n",
       "     [1193.0, 133.0],\n",
       "     [1194.0, 133.0],\n",
       "     [1195.0, 132.0],\n",
       "     [1197.0, 132.0],\n",
       "     [1198.0, 131.0],\n",
       "     [1200.0, 131.0],\n",
       "     [1201.0, 130.0],\n",
       "     [1203.0, 130.0],\n",
       "     [1204.0, 129.0],\n",
       "     [1206.0, 129.0],\n",
       "     [1207.0, 128.0],\n",
       "     [1208.0, 128.0],\n",
       "     [1209.0, 127.0],\n",
       "     [1212.0, 127.0],\n",
       "     [1213.0, 126.0],\n",
       "     [1215.0, 126.0],\n",
       "     [1216.0, 125.0],\n",
       "     [1218.0, 125.0],\n",
       "     [1219.0, 124.0],\n",
       "     [1222.0, 124.0],\n",
       "     [1223.0, 123.0],\n",
       "     [1225.0, 123.0],\n",
       "     [1226.0, 122.0],\n",
       "     [1251.0, 122.0],\n",
       "     [1252.0, 121.0],\n",
       "     [1282.0, 121.0],\n",
       "     [1284.0, 123.0]]},\n",
       "   {'finding_name': '3',\n",
       "    'type': 'Freehand',\n",
       "    'points': [[1252.0, 122.0],\n",
       "     [1251.0, 123.0],\n",
       "     [1226.0, 123.0],\n",
       "     [1225.0, 124.0],\n",
       "     [1223.0, 124.0],\n",
       "     [1222.0, 125.0],\n",
       "     [1219.0, 125.0],\n",
       "     [1218.0, 126.0],\n",
       "     [1216.0, 126.0],\n",
       "     [1215.0, 127.0],\n",
       "     [1213.0, 127.0],\n",
       "     [1212.0, 128.0],\n",
       "     [1209.0, 128.0],\n",
       "     [1208.0, 129.0],\n",
       "     [1207.0, 129.0],\n",
       "     [1206.0, 130.0],\n",
       "     [1204.0, 130.0],\n",
       "     [1203.0, 131.0],\n",
       "     [1201.0, 131.0],\n",
       "     [1200.0, 132.0],\n",
       "     [1198.0, 132.0],\n",
       "     [1197.0, 133.0],\n",
       "     [1195.0, 133.0],\n",
       "     [1194.0, 134.0],\n",
       "     [1193.0, 134.0],\n",
       "     [1192.0, 135.0],\n",
       "     [1190.0, 135.0],\n",
       "     [1189.0, 136.0],\n",
       "     [1188.0, 136.0],\n",
       "     [1186.0, 138.0],\n",
       "     [1185.0, 138.0],\n",
       "     [1183.0, 140.0],\n",
       "     [1182.0, 140.0],\n",
       "     [1180.0, 142.0],\n",
       "     [1179.0, 142.0],\n",
       "     [1178.0, 143.0],\n",
       "     [1177.0, 143.0],\n",
       "     [1175.0, 145.0],\n",
       "     [1174.0, 145.0],\n",
       "     [1167.0, 152.0],\n",
       "     [1167.0, 153.0],\n",
       "     [1163.0, 157.0],\n",
       "     [1163.0, 158.0],\n",
       "     [1157.0, 164.0],\n",
       "     [1157.0, 165.0],\n",
       "     [1154.0, 168.0],\n",
       "     [1154.0, 169.0],\n",
       "     [1151.0, 172.0],\n",
       "     [1151.0, 173.0],\n",
       "     [1146.0, 178.0],\n",
       "     [1146.0, 179.0],\n",
       "     [1144.0, 181.0],\n",
       "     [1144.0, 182.0],\n",
       "     [1141.0, 185.0],\n",
       "     [1141.0, 186.0],\n",
       "     [1138.0, 189.0],\n",
       "     [1138.0, 191.0],\n",
       "     [1137.0, 192.0],\n",
       "     [1137.0, 194.0],\n",
       "     [1136.0, 195.0],\n",
       "     [1136.0, 198.0],\n",
       "     [1135.0, 199.0],\n",
       "     [1135.0, 200.0],\n",
       "     [1134.0, 201.0],\n",
       "     [1134.0, 204.0],\n",
       "     [1133.0, 205.0],\n",
       "     [1133.0, 208.0],\n",
       "     [1132.0, 209.0],\n",
       "     [1132.0, 212.0],\n",
       "     [1131.0, 213.0],\n",
       "     [1131.0, 216.0],\n",
       "     [1130.0, 217.0],\n",
       "     [1130.0, 221.0],\n",
       "     [1129.0, 222.0],\n",
       "     [1129.0, 226.0],\n",
       "     [1128.0, 227.0],\n",
       "     [1128.0, 231.0],\n",
       "     [1127.0, 232.0],\n",
       "     [1127.0, 237.0],\n",
       "     [1126.0, 238.0],\n",
       "     [1126.0, 248.0],\n",
       "     [1127.0, 249.0],\n",
       "     [1127.0, 254.0],\n",
       "     [1128.0, 255.0],\n",
       "     [1128.0, 260.0],\n",
       "     [1129.0, 261.0],\n",
       "     [1129.0, 267.0],\n",
       "     [1130.0, 268.0],\n",
       "     [1130.0, 273.0],\n",
       "     [1131.0, 274.0],\n",
       "     [1131.0, 281.0],\n",
       "     [1132.0, 282.0],\n",
       "     [1132.0, 288.0],\n",
       "     [1133.0, 289.0],\n",
       "     [1133.0, 296.0],\n",
       "     [1134.0, 297.0],\n",
       "     [1134.0, 299.0],\n",
       "     [1135.0, 300.0],\n",
       "     [1135.0, 301.0],\n",
       "     [1136.0, 302.0],\n",
       "     [1136.0, 303.0],\n",
       "     [1137.0, 304.0],\n",
       "     [1137.0, 306.0],\n",
       "     [1138.0, 307.0],\n",
       "     [1138.0, 308.0],\n",
       "     [1139.0, 309.0],\n",
       "     [1139.0, 310.0],\n",
       "     [1140.0, 311.0],\n",
       "     [1140.0, 312.0],\n",
       "     [1141.0, 313.0],\n",
       "     [1141.0, 315.0],\n",
       "     [1142.0, 316.0],\n",
       "     [1142.0, 317.0],\n",
       "     [1143.0, 318.0],\n",
       "     [1143.0, 319.0],\n",
       "     [1144.0, 320.0],\n",
       "     [1144.0, 321.0],\n",
       "     [1145.0, 322.0],\n",
       "     [1145.0, 323.0],\n",
       "     [1147.0, 325.0],\n",
       "     [1147.0, 326.0],\n",
       "     [1148.0, 327.0],\n",
       "     [1148.0, 328.0],\n",
       "     [1149.0, 329.0],\n",
       "     [1149.0, 330.0],\n",
       "     [1150.0, 331.0],\n",
       "     [1150.0, 332.0],\n",
       "     [1151.0, 333.0],\n",
       "     [1151.0, 334.0],\n",
       "     [1153.0, 336.0],\n",
       "     [1153.0, 337.0],\n",
       "     [1154.0, 338.0],\n",
       "     [1154.0, 339.0],\n",
       "     [1155.0, 340.0],\n",
       "     [1155.0, 341.0],\n",
       "     [1157.0, 343.0],\n",
       "     [1157.0, 344.0],\n",
       "     [1159.0, 346.0],\n",
       "     [1159.0, 347.0],\n",
       "     [1160.0, 348.0],\n",
       "     [1160.0, 349.0],\n",
       "     [1162.0, 351.0],\n",
       "     [1162.0, 378.0],\n",
       "     [1301.0, 378.0],\n",
       "     [1301.0, 351.0],\n",
       "     [1302.0, 350.0],\n",
       "     [1302.0, 349.0],\n",
       "     [1304.0, 347.0],\n",
       "     [1304.0, 346.0],\n",
       "     [1305.0, 345.0],\n",
       "     [1305.0, 344.0],\n",
       "     [1306.0, 343.0],\n",
       "     [1306.0, 342.0],\n",
       "     [1307.0, 341.0],\n",
       "     [1307.0, 340.0],\n",
       "     [1308.0, 339.0],\n",
       "     [1308.0, 338.0],\n",
       "     [1309.0, 337.0],\n",
       "     [1309.0, 336.0],\n",
       "     [1310.0, 335.0],\n",
       "     [1310.0, 334.0],\n",
       "     [1311.0, 333.0],\n",
       "     [1311.0, 332.0],\n",
       "     [1312.0, 331.0],\n",
       "     [1312.0, 330.0],\n",
       "     [1313.0, 329.0],\n",
       "     [1313.0, 328.0],\n",
       "     [1314.0, 327.0],\n",
       "     [1314.0, 325.0],\n",
       "     [1315.0, 324.0],\n",
       "     [1315.0, 323.0],\n",
       "     [1316.0, 322.0],\n",
       "     [1316.0, 320.0],\n",
       "     [1317.0, 319.0],\n",
       "     [1317.0, 318.0],\n",
       "     [1318.0, 317.0],\n",
       "     [1318.0, 316.0],\n",
       "     [1319.0, 315.0],\n",
       "     [1319.0, 313.0],\n",
       "     [1320.0, 312.0],\n",
       "     [1320.0, 310.0],\n",
       "     [1321.0, 309.0],\n",
       "     [1321.0, 307.0],\n",
       "     [1322.0, 306.0],\n",
       "     [1322.0, 304.0],\n",
       "     [1323.0, 303.0],\n",
       "     [1323.0, 301.0],\n",
       "     [1324.0, 300.0],\n",
       "     [1324.0, 298.0],\n",
       "     [1325.0, 297.0],\n",
       "     [1325.0, 293.0],\n",
       "     [1326.0, 292.0],\n",
       "     [1326.0, 288.0],\n",
       "     [1327.0, 287.0],\n",
       "     [1327.0, 281.0],\n",
       "     [1328.0, 280.0],\n",
       "     [1328.0, 276.0],\n",
       "     [1329.0, 275.0],\n",
       "     [1329.0, 269.0],\n",
       "     [1330.0, 268.0],\n",
       "     [1330.0, 263.0],\n",
       "     [1331.0, 262.0],\n",
       "     [1331.0, 257.0],\n",
       "     [1332.0, 256.0],\n",
       "     [1332.0, 250.0],\n",
       "     [1333.0, 249.0],\n",
       "     [1333.0, 235.0],\n",
       "     [1332.0, 234.0],\n",
       "     [1332.0, 226.0],\n",
       "     [1331.0, 225.0],\n",
       "     [1331.0, 218.0],\n",
       "     [1330.0, 217.0],\n",
       "     [1330.0, 210.0],\n",
       "     [1329.0, 209.0],\n",
       "     [1329.0, 203.0],\n",
       "     [1328.0, 202.0],\n",
       "     [1328.0, 196.0],\n",
       "     [1327.0, 195.0],\n",
       "     [1327.0, 189.0],\n",
       "     [1326.0, 188.0],\n",
       "     [1326.0, 187.0],\n",
       "     [1325.0, 186.0],\n",
       "     [1325.0, 185.0],\n",
       "     [1324.0, 184.0],\n",
       "     [1324.0, 183.0],\n",
       "     [1323.0, 182.0],\n",
       "     [1323.0, 181.0],\n",
       "     [1322.0, 180.0],\n",
       "     [1322.0, 178.0],\n",
       "     [1321.0, 177.0],\n",
       "     [1321.0, 176.0],\n",
       "     [1320.0, 175.0],\n",
       "     [1320.0, 174.0],\n",
       "     [1319.0, 173.0],\n",
       "     [1319.0, 172.0],\n",
       "     [1318.0, 171.0],\n",
       "     [1318.0, 170.0],\n",
       "     [1317.0, 169.0],\n",
       "     [1317.0, 168.0],\n",
       "     [1316.0, 167.0],\n",
       "     [1316.0, 166.0],\n",
       "     [1315.0, 165.0],\n",
       "     [1315.0, 164.0],\n",
       "     [1314.0, 163.0],\n",
       "     [1314.0, 162.0],\n",
       "     [1313.0, 161.0],\n",
       "     [1313.0, 160.0],\n",
       "     [1312.0, 159.0],\n",
       "     [1312.0, 158.0],\n",
       "     [1311.0, 157.0],\n",
       "     [1311.0, 156.0],\n",
       "     [1310.0, 155.0],\n",
       "     [1310.0, 154.0],\n",
       "     [1309.0, 153.0],\n",
       "     [1309.0, 152.0],\n",
       "     [1308.0, 151.0],\n",
       "     [1308.0, 150.0],\n",
       "     [1306.0, 148.0],\n",
       "     [1306.0, 147.0],\n",
       "     [1305.0, 146.0],\n",
       "     [1305.0, 145.0],\n",
       "     [1304.0, 144.0],\n",
       "     [1304.0, 143.0],\n",
       "     [1303.0, 142.0],\n",
       "     [1303.0, 141.0],\n",
       "     [1301.0, 139.0],\n",
       "     [1301.0, 138.0],\n",
       "     [1300.0, 137.0],\n",
       "     [1300.0, 136.0],\n",
       "     [1296.0, 132.0],\n",
       "     [1295.0, 132.0],\n",
       "     [1292.0, 129.0],\n",
       "     [1291.0, 129.0],\n",
       "     [1288.0, 126.0],\n",
       "     [1287.0, 126.0],\n",
       "     [1285.0, 124.0],\n",
       "     [1284.0, 124.0],\n",
       "     [1282.0, 122.0],\n",
       "     [1252.0, 122.0]]}]}}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push code to your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = bucket\n",
    "key = 'artifact/code'\n",
    "from boto3 import client\n",
    "s3 = client('s3')\n",
    "BUCKET_NAME = bucket\n",
    "DIR_NAME = 'code'\n",
    "# Iterate through the files in the directory\n",
    "for root, dirs, files in os.walk(DIR_NAME):\n",
    "    for file in files:\n",
    "        # Construct the full local path of the file\n",
    "        local_path = os.path.join(root, file)\n",
    "        # Construct the full S3 path of the file\n",
    "        s3_path = os.path.join(root.replace(DIR_NAME, key), file)\n",
    "        # Upload the file to S3\n",
    "        s3.upload_file(local_path, BUCKET_NAME, s3_path)\n",
    "        print(f'Uploaded {local_path} to s3://{BUCKET_NAME}/{s3_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push model to your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelbucket = estimator.output_path.split(\"/\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"model\")\n",
    "except:\n",
    "    pass\n",
    "BUCKET_NAME = modelbucket\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(BUCKET_NAME).download_file(sagemaker_job_name + \"/output/model.tar.gz\", \"model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = client('s3')\n",
    "BUCKET_NAME = bucket\n",
    "s3.upload_file(\"model/model.tar.gz\", BUCKET_NAME, \"model/model.tar.gz\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
