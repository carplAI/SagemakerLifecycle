{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torchvison as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0myes: standard output: Broken pipe\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall torchvison\n",
    "!pip install -qU torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (9.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MNIST Training using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using PyTorch.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-mnist\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28743102-e626-46b1-b5f1-d312c82e1bcb'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "metadata = json.load(open(\"/opt/ml/metadata/resource-metadata.json\",\"r\"))\n",
    "bucket = metadata[\"UserProfileName\"]\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28743102-e626-46b1-b5f1-d312c82e1bcb'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/1.11.344.6148.65065.152707.6306186.96124460631032360342854182473_5.50.165.1847.21251.931697.4943068.66587612922852477819742239754_9.59.156.4421.74552.215908.6904659.49034716993854402263648069793.dcm\n",
      "data/1.12.746.8025.62058.949442.1929181.53704693946484206476797649267_1.43.318.8932.46424.646527.5125264.34607190288155359632618069574_1.10.438.7074.32125.900008.4092280.70162125893606125565043933402.dcm\n",
      "data/1.12.967.5116.19356.946072.2432445.47831750788890784530891947041_7.73.122.6517.38425.389142.3671342.37329354064982022344298925837_1.94.287.6068.64042.801707.8730888.96213932843756638999515284232.dcm\n",
      "data/1.13.120.6964.99330.189205.6937115.13568674261194149132466639708_8.41.552.3169.48654.890784.1114012.14201826718081841047037652106_1.12.716.5329.19210.710458.9194349.92481456069811815581169388576.dcm\n",
      "data/1.13.142.7833.71939.935224.5464397.45905719824188091537499465124_4.25.566.4222.23306.762121.7943945.56687295583391761904186824676_1.16.435.9740.47447.416936.9741465.54444623486982581631972438676.dcm\n",
      "data/1.13.730.2419.85151.270968.4545256.25655911813086142567489641138_9.67.784.1519.63975.412791.1359465.57892300036664370288960805405_4.91.998.5134.92640.360898.4356616.12956076032076596955093898554.dcm\n",
      "data/1.14.353.2545.64494.651716.5371244.77837942775428522953806803267_3.38.156.9697.93995.870567.8100718.89961970534134074904953855418_3.77.462.7705.63194.974911.7766471.68085427517446792980950163519.dcm\n",
      "data/1.14.734.5383.13866.180108.7737045.24634452567539222745306846777_3.47.512.4308.88844.978974.8333351.93114562641818086253127085393_5.78.165.8753.87981.158522.9691017.31219635449818643820871103152.dcm\n",
      "data/1.14.874.5100.26957.464350.8344901.93156563516173311603948916689_9.99.136.1548.43905.344612.6492351.54543418923596905421189792785_9.39.224.9074.45936.831843.8831969.81109334288071326555323115630.dcm\n",
      "data/1.15.265.1299.61548.644955.7522286.52765376899817147761300983841_6.27.836.4337.11323.102088.2032355.48998052066371699819544384429_5.84.813.7442.26906.249641.7882071.42722539157927238158755261919.dcm\n",
      "data/1.16.117.5476.18310.454186.7761787.17947069217026626425096639748_2.49.462.1933.95988.534814.2381078.36302764730346005779500669285_2.67.931.4897.33379.559142.2328999.81218523322021525217065183734.dcm\n",
      "data/1.17.100.4863.92087.103614.7923897.40055186019181082792752862294_7.47.348.3890.49607.624780.9546773.95295363476040061679063308759_1.77.168.8708.16432.574999.4147770.11188502437450089848062001791.dcm\n",
      "data/1.17.463.8466.80670.918101.7064650.24586464634054378847708061374_5.49.296.6036.73255.310104.1807651.81463627707862460523697566921_3.70.791.8327.21758.119627.7163844.28050427410947465046798606603.dcm\n",
      "data/1.18.159.1371.61297.200412.4276488.74308152215431411286670342663_4.70.305.9394.93977.488751.3302541.10240460210961895757760595553_8.72.954.3902.64376.849756.5215898.74464889701846710141264766217.dcm\n",
      "data/1.18.907.3314.99823.414751.1585319.21852280100687743961466149501_1.13.213.4013.67084.240721.9694884.46746232454156551632077318369_1.10.473.1436.77765.111776.3389285.86021203145131218647273600165.dcm\n",
      "data/1.23.391.1731.38836.304784.2189747.72997408754147828291359224489_4.48.312.5847.67211.378696.6193045.59155958045226193523753599374_2.28.395.9177.16663.530731.1560364.73632503968610976745594051876.dcm\n",
      "data/1.60.189.2485.28370.744066.3192887.99536658409698265281922587092_4.62.143.1766.49452.390831.3652060.16908970487932721084260947354_5.13.739.6323.95176.911483.1047870.19058515666082043809459233223.dcm\n",
      "data/1.61.409.3848.15061.953607.2576674.82226917260491564586240519360_9.14.560.8353.45545.642219.7752569.12226218888015320681782118185_2.66.406.7563.78029.542325.2137084.17926805987453147793329018713.dcm\n",
      "data/1.65.474.4256.35307.106331.7368614.47092078273566977953428273050_2.51.812.5127.64842.534421.1963231.16270780506902189158429347396_4.38.164.1704.36318.682740.3889586.10136393472786550904565913473.dcm\n",
      "data/1.81.663.7193.17035.737642.8153140.80696816251808319326388862235_7.81.251.2597.85443.741725.7451330.44020773125463261737439252298_2.34.106.1534.97826.183084.5768251.69796769647508285637731093263.dcm\n",
      "data/1.90.737.1504.21669.726150.3735247.50728139832231716511005155132_1.46.204.1025.61729.580920.2777235.86379478965828848726558312258_2.90.422.5610.14624.379758.8041829.54897498235548600350004654443.dcm\n",
      "data/2.14.622.2571.87987.607468.1034307.71151371707956010502928909841_1.19.872.1510.16349.390417.1841743.34452856825498837994182972556_2.19.455.1737.12041.942119.2782985.10210242739318825025109014657.dcm\n",
      "data/2.17.265.4680.97104.567575.8996498.78222608474059795947741882649_2.60.277.1003.83515.379528.8520305.11766343860810614445253051411_2.76.618.1311.10966.998299.7895466.47343057584993727071217284972.dcm\n",
      "data/2.22.685.2058.11141.750503.2988373.39991155560481379422752146066_1.47.646.8695.33749.622980.2292833.19189290202877616116682551588_5.47.864.3724.41473.107307.7397212.19090539457393732317665561277.dcm\n",
      "data/2.40.201.1924.50803.302072.1880877.56662781559528665514538481654_7.79.564.2163.68285.405974.8583554.62581389892809484921373451498_2.18.908.4101.79483.659750.4956374.53941584896628451892623974403.dcm\n",
      "data/2.41.730.7640.81475.390705.1498777.60061619441014619898833494387_9.32.558.1632.35311.289135.5169772.59783536133376193141554188494_2.16.731.2653.65463.449091.8917667.41222623441020182497739876237.dcm\n",
      "data/2.42.430.2110.42643.365448.1038804.78687932282882449837608376023_3.86.122.8163.93326.767469.3581652.79497696311183665610617239639_5.31.139.1651.65917.236474.3843609.99274194946806339038368874230.dcm\n",
      "data/2.80.345.4015.28936.295577.5188306.99432345414255857834442099266_9.57.110.3833.83570.471283.3965604.62566804698593308292970319150_3.13.169.7366.41516.717836.1817932.90266571263599295950210107745.dcm\n",
      "data/3.17.602.4973.93181.360511.5358674.14765645670939985618796999452_9.50.773.6456.35757.628429.1555881.84263930875576921349362301308_6.19.974.4531.40752.876487.7832288.35350796048620204285337081262.dcm\n",
      "data/3.71.480.9507.30952.566829.4935047.71692562490340412987856362979_1.21.391.2396.22207.733597.3350816.28084333787885324572490315659_5.44.484.1565.35078.472503.4142455.41444692526209061326993613919.dcm\n",
      "data/3.73.163.3601.61941.366995.8053770.48317946519277592198293935433_3.46.365.5214.53892.404976.5691605.29333290598016069111328609624_1.10.155.4258.96000.462929.2300254.39388613540561666285264298548.dcm\n",
      "data/3.73.868.4495.38353.721716.4956268.99430566555480960362134623615_1.17.150.8419.71103.125928.2110322.62043688860718910963353749445_8.49.456.1075.67599.420348.1459696.26556372360413487178550006995.dcm\n",
      "data/3.95.188.4834.14393.117173.9401768.79622955040829299805678127099_1.10.135.2137.90574.654471.1177685.47977662923654865364383712637_2.43.894.2823.54083.824748.1689114.52854405033586617974016841040.dcm\n",
      "data/3.99.548.5198.66620.749835.2875696.16974180913879893412868347606_8.31.205.9851.34447.543615.6510257.24956916969234918159048976071_1.11.244.5813.25017.154237.8972197.10385977410736142018192648289.dcm\n",
      "data/4.18.232.2462.12004.167322.4890659.96710689574063721565209478339_1.12.132.8397.90029.722208.3375529.98323350099395856927194532597_7.43.194.2532.19555.984100.4655679.20909524581407096942960578198.dcm\n",
      "data/4.23.244.6092.14838.495562.8121353.52578960096792419416885144148_6.19.378.6440.60533.560558.1086728.66761975031877591768674946117_8.35.482.6513.72149.216735.2320889.19154119468637915995905581434.dcm\n",
      "data/4.26.977.2506.77646.633177.8038530.13910170415322721787414037831_2.48.314.1897.15529.838703.1343477.87379748657108673706575982510_1.55.199.1280.86449.807558.2331688.90055422376738262657710346972.dcm\n",
      "data/4.40.397.6515.87824.159841.3031917.94542702737917032970580466801_2.52.103.1468.37601.870764.1061416.24951914310205728505912819708_3.77.809.4393.70336.519402.2428001.17290348135240359814126417094.dcm\n",
      "data/4.40.963.1908.61648.625283.4129686.13275493173266257514625704516_1.13.792.7336.59667.674796.7343041.36082973286212502059022867908_1.15.346.1312.78412.689367.8385976.16975057291649603355414773865.dcm\n",
      "data/4.41.154.9950.45219.768665.1384949.85755756721497071523589976792_7.23.521.8767.46290.115774.2884581.26614546494236189953880130970_1.34.182.4910.30031.210358.6054294.26294079043434500059119062896.dcm\n",
      "data/4.63.443.5164.94685.362168.4896896.58519310643160463251551694564_1.15.387.4759.14370.943417.4001212.96507381927585527790954131483_5.95.128.4478.68688.863063.5279346.13512545678679686780381603645.dcm\n",
      "data/4.69.627.1479.81269.343997.6707592.67810989906088774419692022013_6.40.324.7744.58148.151585.5317550.87857907664413219387255703121_1.11.949.1282.51562.103841.4339302.15434316088621603164348573941.dcm\n",
      "data/4.77.107.1760.73761.102525.3122184.87177081850852375858879178034_7.73.730.4555.71902.583221.1169213.82476067342322495959076398706_9.73.110.2672.26212.193909.6810131.20673191872885425210920143484.dcm\n",
      "data/4.77.939.9602.76199.164354.8771665.54966214039704715866556961013_3.96.203.5623.14458.536123.9923452.32605908197158403490129812583_1.13.122.7584.87360.909434.2488129.94176012338520824434242075633.dcm\n",
      "data/5.13.926.4608.62805.747391.7912296.93859781412425987583981875526_2.55.463.3753.66415.339963.1159851.59400782421098727501673637189_3.84.236.1821.99762.199817.6030085.49260656528601022353229570793.dcm\n",
      "data/5.17.241.7401.62947.339273.8835388.99532272202750425306637122687_7.29.141.7602.46506.431244.8849953.86705008228246361839744806494_8.40.407.1300.82192.402084.2684414.42634327661690686734764624135.dcm\n",
      "data/5.22.306.4664.79223.194550.1885592.58250529532453444716263481983_8.13.212.4104.71849.512907.7813573.54417018957189279463951149871_3.43.152.1458.36018.182336.1059562.69372091447582557221009107232.dcm\n",
      "data/5.25.382.8723.25148.228196.2844956.18966184103060565671957021244_4.27.432.3973.81195.195310.5661287.28599621740083427205817568323_5.93.870.3071.26633.128263.6065812.44624660978477753296739911405.dcm\n",
      "data/5.35.500.1375.47629.197116.5794493.59587231661076745538263168838_1.32.790.2230.12951.852608.1276140.59867180182442057707377189483_8.63.524.4562.31304.166446.9665720.97090300305601188343443134326.dcm\n",
      "data/5.40.156.1585.41712.842626.5187078.37117375052559731314670602202_8.22.419.8561.93499.564696.1934355.10290669434610132058302050263_5.18.393.4311.43672.257044.9941540.26894939921665209763850798150.dcm\n",
      "data/5.47.195.3910.15434.187195.5068377.42006260512164496175738480597_4.50.127.2951.24748.583797.2266910.53135413515207627583533928784_6.98.885.2735.15426.779697.6670847.17396310471697092662471666011.dcm\n",
      "data/5.58.224.1365.47927.532850.8148877.97002156077315058788712643900_3.11.352.7146.18416.154345.2826945.73481015819987877819506894315_7.26.963.8164.47276.400448.7475274.95281891480256453567982945708.dcm\n",
      "data/5.63.420.7582.51807.142583.7532835.49115394536906674654582145323_1.41.104.7435.16723.606940.5593507.88908567915557205279421861991_7.58.225.7976.30161.191725.1960098.38133552672994006821288862540.dcm\n",
      "data/5.77.101.1188.85451.197549.9030146.44753382930882926234245961582_6.34.149.4526.42895.579359.2122835.12099223005081607029687481892_3.87.502.2104.66931.374106.2811561.18252026099860933232721824899.dcm\n",
      "data/5.79.401.7360.10405.896525.2742356.28710507931897860880502982094_3.16.725.9718.53752.374786.1632544.16217234352954456256562918458_3.91.132.8684.99477.314491.1817609.15274156840454913899334143967.dcm\n",
      "data/5.88.352.3897.21124.951357.1194811.15661357489538218807881532388_1.15.541.7806.57151.839178.1557663.76130122310270012397114781530_5.11.245.6037.51616.454606.5328066.13074922771872330885410515900.dcm\n",
      "data/5.90.117.5752.84205.144991.5902010.63795981152590161868604724884_2.20.698.2558.17877.123703.8007134.43358291830620376572213919800_6.11.669.1300.10477.160982.4240844.32919154901672126566776806469.dcm\n",
      "data/5.91.457.8318.88432.944112.6120730.14795696493690188437726490372_7.68.613.3209.92563.388518.6820779.47525281261482143202430177041_5.72.114.3260.95309.826779.8219919.12708414640493532400468420576.dcm\n",
      "data/6.15.163.6084.27366.247409.2544126.85202225583966920590874000799_2.70.888.5646.25863.870583.4671345.99819148068996578559065472917_3.55.504.3352.93400.642782.2853015.89590445015302385339760849293.dcm\n",
      "data/6.15.511.8459.21472.123512.7628921.99556983157948236436167924925_4.60.982.4272.16926.170069.1563713.74481738450679922497007165081_1.12.123.5253.36369.456598.8346057.41472431147021555014077097480.dcm\n",
      "data/6.40.828.6489.64509.485309.8150162.92137606228423791633136749768_1.10.400.6617.45356.835464.4258431.30008885544656323401092189429_1.11.187.9973.86364.596634.2778477.17312574051626058476675189721.dcm\n",
      "data/6.42.784.1513.33656.580248.3064168.48534219372363415899624431895_7.64.955.8263.18575.409446.3640855.51882253620436712390570662146_2.86.966.1249.12896.142851.7012656.52807079842961239965702982579.dcm\n",
      "data/6.51.961.9802.14551.711576.4881796.17525135720251786575167100641_9.42.991.3047.82059.713522.3207774.19249771284850965432004139976_1.17.931.3862.19647.803320.4644299.70049228361960395582749788046.dcm\n",
      "data/6.52.405.8969.54175.708674.1619703.10953156656680063565416410622_8.70.982.8358.54028.639521.4758821.12849450980112551136488922213_2.58.975.4091.11057.787327.7561809.30310114175110672065424160610.dcm\n",
      "data/6.54.662.4702.13897.297564.5001709.26857758684759221586887876313_5.63.356.6827.39817.399472.9924354.37094696257108222798156405079_9.71.932.9956.13033.502383.6255985.66331193490320727859148703237.dcm\n",
      "data/6.61.175.2327.33734.183160.4829262.14726470646693610781751824957_5.78.642.6761.72711.523745.2852150.55323438382051512355250816979_1.10.766.2144.37713.557635.1562439.10238599233725863371517190889.dcm\n",
      "data/6.65.334.1225.15774.762121.3180231.18603946373904960111199226445_1.12.703.9044.21716.404796.9307980.95363717109158832804920000422_6.28.771.3106.37178.609505.6695247.21195255683909877450976530305.dcm\n",
      "data/6.66.648.6502.29956.942361.8635216.88784061074834924575344731618_1.12.257.1269.72544.926497.3917908.55909786667439060912057374221_8.31.316.4857.55858.138865.1007709.77498605583581585373740049653.dcm\n",
      "data/6.80.775.7556.19239.192699.1825714.87076623317754286274184534697_8.13.989.7153.55784.813890.9255973.19438927855826438073735203625_1.36.534.9331.98857.922221.5974485.72794994635972440137852095847.dcm\n",
      "data/6.82.757.8595.11577.851319.1805630.42781191565635798945358909279_1.12.340.1601.36414.698006.1746675.17828744482416608407538690808_8.66.930.3958.85540.736504.5893079.52774207666540537828954489688.dcm\n",
      "data/6.83.518.5177.48182.345100.8306761.34281969396893331291053528420_6.56.270.8134.30856.155751.4247617.79007716620653022415356363204_4.82.527.1212.26227.454819.5870202.76689373061364734599229546869.dcm\n",
      "data/7.12.123.4157.91860.248575.8286697.38621201650858432271906778257_5.38.113.9390.16860.261289.1833221.12820069214712500060636221432_5.15.304.9356.26312.113496.5334786.56370221351474717123076467144.dcm\n",
      "data/7.29.170.2127.44264.660635.6107266.33554414114594534531048655153_6.64.462.8728.34554.435617.1700102.11473082888750410806245488921_1.18.463.7596.83434.496207.1193109.18566906561230028594222282921.dcm\n",
      "data/7.30.155.5941.91159.716066.5585135.52707035856874961494772910210_4.39.842.4863.95712.974842.4395984.18837010443014610174673535855_3.79.192.7817.13052.775115.9723906.45128822617499585582708938319.dcm\n",
      "data/7.33.133.3027.79930.205419.8916854.62196162212110375517377719752_5.88.682.4795.75980.858383.2945881.31137533085929489196275110128_5.63.584.7898.11985.537879.3988007.74636346956422888142376118702.dcm\n",
      "data/7.34.129.3958.38253.212375.6010961.28901921167124136402138637605_7.69.286.6927.33259.567530.8606526.56318810043658411952526813050_9.54.218.5145.97024.859446.6267091.71572873817294588040186701959.dcm\n",
      "data/7.41.930.1008.24395.127131.2375763.73519423700966976269633219017_2.19.445.1255.10246.512341.1441471.92445729369699238486189681285_9.27.190.1818.40323.931593.8477989.14787455980710428980056071016.dcm\n",
      "data/7.52.120.1223.69446.892666.6571970.38472257484952301153641931524_4.68.469.9972.36056.919029.6507439.21903211917666353042348620251_5.31.789.1641.64628.430609.3706314.66231843829282066784003902524.dcm\n",
      "data/7.54.207.8951.81708.562316.2853073.41172144376790956082039618807_3.31.142.1188.50797.361477.7397984.62967671485329940714688237862_4.88.724.6925.63004.750855.4693263.77844019106667799963757734252.dcm\n",
      "data/7.64.130.1481.62295.977960.8300262.34719059629194315482234907646_4.63.823.4412.90100.204819.8329307.89928227084769839948262014749_6.41.325.2770.92369.732443.4046722.61167716765441716445221990905.dcm\n",
      "data/7.65.389.9925.87925.886034.5142659.77536266814977636987579334328_1.13.976.9456.69999.376837.1834365.69731000308041036460844813722_4.90.138.8774.99366.222778.8291888.58017553371927436792503378663.dcm\n",
      "data/7.73.813.7361.21581.809945.1617886.10665117178530299451140763425_6.41.728.1825.78569.525263.4202198.50973240226792917648678838837_1.15.330.7044.71387.915379.6045792.33507511331138284663876792409.dcm\n",
      "data/7.99.424.6402.95166.683728.1052567.55698766510541669767241416888_4.52.213.6556.93384.159507.8821053.57229903749953983569691633561_3.25.331.3387.42557.573813.8534834.10725884375590773554858713762.dcm\n",
      "data/7.99.551.4120.99697.876324.9923622.10396463669849949414900613532_2.12.586.2738.79272.847515.7123326.68051952306544941569302733232_4.12.129.8555.60674.173171.4219511.83178256844164388718750538117.dcm\n",
      "data/8.12.485.3226.12740.974101.9560515.14517489361363299251517195692_9.16.831.3840.11797.383832.5764476.82664768537810901673700617498_5.69.498.3775.69268.206261.5865262.18757243961455678123348300848.dcm\n",
      "data/8.45.795.3078.34500.175949.1550957.29755422141886868101529811449_4.93.732.9009.69689.299220.3406258.74590122008897183420404768425_8.90.195.1188.33277.559972.1617680.32116855567954828523874786880.dcm\n",
      "data/8.62.327.1326.92180.349525.6393139.70028386126524309069487570605_5.83.696.7179.45794.435149.9774084.33349148393473717954737482536_9.30.167.2445.29223.425222.7274192.39543224928152176553512423963.dcm\n",
      "data/8.62.640.9937.44129.889189.1592336.30853649234154540047567456053_7.13.911.6756.79760.182442.1909062.20624813297839314062092252460_5.97.700.5591.68451.615742.3409207.81362814973548372335909280276.dcm\n",
      "data/8.65.621.6272.45629.542598.3519466.53190987112210555278910070704_6.84.216.6297.59518.780120.7309032.11501517893392815748571560873_5.26.911.9845.10733.664451.7460756.10287058740216774881626040487.dcm\n",
      "data/8.93.344.8961.18142.770022.6551784.93820756462093463741380912599_7.63.267.9995.45300.415401.4392426.62257006672734591187563694465_1.15.228.7547.25618.690569.9888012.30983141657368406195145010938.dcm\n",
      "data/9.10.818.5154.63645.412070.6018927.63199635959868537694569781302_8.94.388.1529.69208.778672.1221686.21219922981316243737908403248_1.35.108.7660.32735.491857.8455650.54541238437556883737828826118.dcm\n",
      "data/9.14.932.8674.42233.437803.3999667.44672470805396662938935803565_6.56.843.7980.71733.181916.4677936.84662570716371949503565751700_5.16.166.3567.13366.112099.3228509.26188105211809443107546600531.dcm\n",
      "data/9.29.255.2472.78866.124996.7641581.65727742578197068494918935977_7.21.635.1326.24995.403414.1826556.13437553138525793225594535249_8.15.256.2533.15545.777270.7734286.70103752139443260335915448928.dcm\n",
      "data/9.40.912.1316.10621.684032.9997253.75372405161750441216911183681_1.58.506.6361.88371.490167.8385513.39017063985357250147775079059_2.86.191.1740.93080.309965.3347025.14318088782241563901702380986.dcm\n",
      "data/9.41.728.3708.41955.117300.7966818.63824097217632303927790610549_5.15.261.2745.19031.102046.8477070.29322840472483330382038480420_6.22.268.7495.27222.839120.8129341.65712490137503290336504624687.dcm\n",
      "data/9.63.780.4174.15394.787627.7623863.54390443086026534950323039708_6.18.233.7038.40737.107573.5963498.70765980555448890157957005644_1.10.827.1808.93065.673159.5682913.40370999244622660628125180529.dcm\n",
      "data/9.70.129.4720.95619.345530.2348354.16644627673931296195094068483_1.14.439.7469.64567.268248.9238260.76089624392180540317208335864_1.17.692.9092.57858.953206.8821239.30389549610419339208660241301.dcm\n",
      "data/9.81.557.7748.18983.141302.7322637.82503832984007696050344553683_8.40.188.9003.54088.778581.1709993.86956196184612240798683967207_9.89.667.1763.77367.256762.8821491.26498986297019309957304169266.dcm\n",
      "data/9.89.170.3959.47238.780496.1523268.11658060860634230728347976332_2.10.176.2810.19901.631656.2613097.86525402485669565528106609781_7.40.147.9922.15486.611009.4310113.52094275593719774149056087801.dcm\n",
      "data/9.90.101.1010.51820.359933.9890868.87518787153834657052462821070_1.14.188.4159.12372.175796.5335316.70970474650448134216072957731_3.37.487.7285.69457.503956.3215879.75979103174350018005642719667.dcm\n",
      "data/9.93.933.1485.65621.325603.4939840.96122600681902659620721832951_7.95.508.3357.36991.944399.9151677.73995317267225996290451785089_6.75.802.4499.17112.984674.6396184.97503933562433054480057675636.dcm\n",
      "labels/28743102-e626-46b1-b5f1-d312c82e1bcb.csv\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-images-idx3-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-labels-idx1-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-images-idx3-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-labels-idx1-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from boto3 import client\n",
    "\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/1.11.344.6148.65065.152707.6306186.96124460631032360342854182473_5.50.165.1847.21251.931697.4943068.66587612922852477819742239754_9.59.156.4421.74552.215908.6904659.49034716993854402263648069793.dcm\n",
      "data/1.12.746.8025.62058.949442.1929181.53704693946484206476797649267_1.43.318.8932.46424.646527.5125264.34607190288155359632618069574_1.10.438.7074.32125.900008.4092280.70162125893606125565043933402.dcm\n",
      "data/1.12.967.5116.19356.946072.2432445.47831750788890784530891947041_7.73.122.6517.38425.389142.3671342.37329354064982022344298925837_1.94.287.6068.64042.801707.8730888.96213932843756638999515284232.dcm\n",
      "data/1.13.120.6964.99330.189205.6937115.13568674261194149132466639708_8.41.552.3169.48654.890784.1114012.14201826718081841047037652106_1.12.716.5329.19210.710458.9194349.92481456069811815581169388576.dcm\n",
      "data/1.13.142.7833.71939.935224.5464397.45905719824188091537499465124_4.25.566.4222.23306.762121.7943945.56687295583391761904186824676_1.16.435.9740.47447.416936.9741465.54444623486982581631972438676.dcm\n",
      "data/1.13.730.2419.85151.270968.4545256.25655911813086142567489641138_9.67.784.1519.63975.412791.1359465.57892300036664370288960805405_4.91.998.5134.92640.360898.4356616.12956076032076596955093898554.dcm\n",
      "data/1.14.353.2545.64494.651716.5371244.77837942775428522953806803267_3.38.156.9697.93995.870567.8100718.89961970534134074904953855418_3.77.462.7705.63194.974911.7766471.68085427517446792980950163519.dcm\n",
      "data/1.14.734.5383.13866.180108.7737045.24634452567539222745306846777_3.47.512.4308.88844.978974.8333351.93114562641818086253127085393_5.78.165.8753.87981.158522.9691017.31219635449818643820871103152.dcm\n",
      "data/1.14.874.5100.26957.464350.8344901.93156563516173311603948916689_9.99.136.1548.43905.344612.6492351.54543418923596905421189792785_9.39.224.9074.45936.831843.8831969.81109334288071326555323115630.dcm\n",
      "data/1.15.265.1299.61548.644955.7522286.52765376899817147761300983841_6.27.836.4337.11323.102088.2032355.48998052066371699819544384429_5.84.813.7442.26906.249641.7882071.42722539157927238158755261919.dcm\n",
      "data/1.16.117.5476.18310.454186.7761787.17947069217026626425096639748_2.49.462.1933.95988.534814.2381078.36302764730346005779500669285_2.67.931.4897.33379.559142.2328999.81218523322021525217065183734.dcm\n",
      "data/1.17.100.4863.92087.103614.7923897.40055186019181082792752862294_7.47.348.3890.49607.624780.9546773.95295363476040061679063308759_1.77.168.8708.16432.574999.4147770.11188502437450089848062001791.dcm\n",
      "data/1.17.463.8466.80670.918101.7064650.24586464634054378847708061374_5.49.296.6036.73255.310104.1807651.81463627707862460523697566921_3.70.791.8327.21758.119627.7163844.28050427410947465046798606603.dcm\n",
      "data/1.18.159.1371.61297.200412.4276488.74308152215431411286670342663_4.70.305.9394.93977.488751.3302541.10240460210961895757760595553_8.72.954.3902.64376.849756.5215898.74464889701846710141264766217.dcm\n",
      "data/1.18.907.3314.99823.414751.1585319.21852280100687743961466149501_1.13.213.4013.67084.240721.9694884.46746232454156551632077318369_1.10.473.1436.77765.111776.3389285.86021203145131218647273600165.dcm\n",
      "data/1.23.391.1731.38836.304784.2189747.72997408754147828291359224489_4.48.312.5847.67211.378696.6193045.59155958045226193523753599374_2.28.395.9177.16663.530731.1560364.73632503968610976745594051876.dcm\n",
      "data/1.60.189.2485.28370.744066.3192887.99536658409698265281922587092_4.62.143.1766.49452.390831.3652060.16908970487932721084260947354_5.13.739.6323.95176.911483.1047870.19058515666082043809459233223.dcm\n",
      "data/1.61.409.3848.15061.953607.2576674.82226917260491564586240519360_9.14.560.8353.45545.642219.7752569.12226218888015320681782118185_2.66.406.7563.78029.542325.2137084.17926805987453147793329018713.dcm\n",
      "data/1.65.474.4256.35307.106331.7368614.47092078273566977953428273050_2.51.812.5127.64842.534421.1963231.16270780506902189158429347396_4.38.164.1704.36318.682740.3889586.10136393472786550904565913473.dcm\n",
      "data/1.81.663.7193.17035.737642.8153140.80696816251808319326388862235_7.81.251.2597.85443.741725.7451330.44020773125463261737439252298_2.34.106.1534.97826.183084.5768251.69796769647508285637731093263.dcm\n",
      "data/1.90.737.1504.21669.726150.3735247.50728139832231716511005155132_1.46.204.1025.61729.580920.2777235.86379478965828848726558312258_2.90.422.5610.14624.379758.8041829.54897498235548600350004654443.dcm\n",
      "data/2.14.622.2571.87987.607468.1034307.71151371707956010502928909841_1.19.872.1510.16349.390417.1841743.34452856825498837994182972556_2.19.455.1737.12041.942119.2782985.10210242739318825025109014657.dcm\n",
      "data/2.17.265.4680.97104.567575.8996498.78222608474059795947741882649_2.60.277.1003.83515.379528.8520305.11766343860810614445253051411_2.76.618.1311.10966.998299.7895466.47343057584993727071217284972.dcm\n",
      "data/2.22.685.2058.11141.750503.2988373.39991155560481379422752146066_1.47.646.8695.33749.622980.2292833.19189290202877616116682551588_5.47.864.3724.41473.107307.7397212.19090539457393732317665561277.dcm\n",
      "data/2.40.201.1924.50803.302072.1880877.56662781559528665514538481654_7.79.564.2163.68285.405974.8583554.62581389892809484921373451498_2.18.908.4101.79483.659750.4956374.53941584896628451892623974403.dcm\n",
      "data/2.41.730.7640.81475.390705.1498777.60061619441014619898833494387_9.32.558.1632.35311.289135.5169772.59783536133376193141554188494_2.16.731.2653.65463.449091.8917667.41222623441020182497739876237.dcm\n",
      "data/2.42.430.2110.42643.365448.1038804.78687932282882449837608376023_3.86.122.8163.93326.767469.3581652.79497696311183665610617239639_5.31.139.1651.65917.236474.3843609.99274194946806339038368874230.dcm\n",
      "data/2.80.345.4015.28936.295577.5188306.99432345414255857834442099266_9.57.110.3833.83570.471283.3965604.62566804698593308292970319150_3.13.169.7366.41516.717836.1817932.90266571263599295950210107745.dcm\n",
      "data/3.17.602.4973.93181.360511.5358674.14765645670939985618796999452_9.50.773.6456.35757.628429.1555881.84263930875576921349362301308_6.19.974.4531.40752.876487.7832288.35350796048620204285337081262.dcm\n",
      "data/3.71.480.9507.30952.566829.4935047.71692562490340412987856362979_1.21.391.2396.22207.733597.3350816.28084333787885324572490315659_5.44.484.1565.35078.472503.4142455.41444692526209061326993613919.dcm\n",
      "data/3.73.163.3601.61941.366995.8053770.48317946519277592198293935433_3.46.365.5214.53892.404976.5691605.29333290598016069111328609624_1.10.155.4258.96000.462929.2300254.39388613540561666285264298548.dcm\n",
      "data/3.73.868.4495.38353.721716.4956268.99430566555480960362134623615_1.17.150.8419.71103.125928.2110322.62043688860718910963353749445_8.49.456.1075.67599.420348.1459696.26556372360413487178550006995.dcm\n",
      "data/3.95.188.4834.14393.117173.9401768.79622955040829299805678127099_1.10.135.2137.90574.654471.1177685.47977662923654865364383712637_2.43.894.2823.54083.824748.1689114.52854405033586617974016841040.dcm\n",
      "data/3.99.548.5198.66620.749835.2875696.16974180913879893412868347606_8.31.205.9851.34447.543615.6510257.24956916969234918159048976071_1.11.244.5813.25017.154237.8972197.10385977410736142018192648289.dcm\n",
      "data/4.18.232.2462.12004.167322.4890659.96710689574063721565209478339_1.12.132.8397.90029.722208.3375529.98323350099395856927194532597_7.43.194.2532.19555.984100.4655679.20909524581407096942960578198.dcm\n",
      "data/4.23.244.6092.14838.495562.8121353.52578960096792419416885144148_6.19.378.6440.60533.560558.1086728.66761975031877591768674946117_8.35.482.6513.72149.216735.2320889.19154119468637915995905581434.dcm\n",
      "data/4.26.977.2506.77646.633177.8038530.13910170415322721787414037831_2.48.314.1897.15529.838703.1343477.87379748657108673706575982510_1.55.199.1280.86449.807558.2331688.90055422376738262657710346972.dcm\n",
      "data/4.40.397.6515.87824.159841.3031917.94542702737917032970580466801_2.52.103.1468.37601.870764.1061416.24951914310205728505912819708_3.77.809.4393.70336.519402.2428001.17290348135240359814126417094.dcm\n",
      "data/4.40.963.1908.61648.625283.4129686.13275493173266257514625704516_1.13.792.7336.59667.674796.7343041.36082973286212502059022867908_1.15.346.1312.78412.689367.8385976.16975057291649603355414773865.dcm\n",
      "data/4.41.154.9950.45219.768665.1384949.85755756721497071523589976792_7.23.521.8767.46290.115774.2884581.26614546494236189953880130970_1.34.182.4910.30031.210358.6054294.26294079043434500059119062896.dcm\n",
      "data/4.63.443.5164.94685.362168.4896896.58519310643160463251551694564_1.15.387.4759.14370.943417.4001212.96507381927585527790954131483_5.95.128.4478.68688.863063.5279346.13512545678679686780381603645.dcm\n",
      "data/4.69.627.1479.81269.343997.6707592.67810989906088774419692022013_6.40.324.7744.58148.151585.5317550.87857907664413219387255703121_1.11.949.1282.51562.103841.4339302.15434316088621603164348573941.dcm\n",
      "data/4.77.107.1760.73761.102525.3122184.87177081850852375858879178034_7.73.730.4555.71902.583221.1169213.82476067342322495959076398706_9.73.110.2672.26212.193909.6810131.20673191872885425210920143484.dcm\n",
      "data/4.77.939.9602.76199.164354.8771665.54966214039704715866556961013_3.96.203.5623.14458.536123.9923452.32605908197158403490129812583_1.13.122.7584.87360.909434.2488129.94176012338520824434242075633.dcm\n",
      "data/5.13.926.4608.62805.747391.7912296.93859781412425987583981875526_2.55.463.3753.66415.339963.1159851.59400782421098727501673637189_3.84.236.1821.99762.199817.6030085.49260656528601022353229570793.dcm\n",
      "data/5.17.241.7401.62947.339273.8835388.99532272202750425306637122687_7.29.141.7602.46506.431244.8849953.86705008228246361839744806494_8.40.407.1300.82192.402084.2684414.42634327661690686734764624135.dcm\n",
      "data/5.22.306.4664.79223.194550.1885592.58250529532453444716263481983_8.13.212.4104.71849.512907.7813573.54417018957189279463951149871_3.43.152.1458.36018.182336.1059562.69372091447582557221009107232.dcm\n",
      "data/5.25.382.8723.25148.228196.2844956.18966184103060565671957021244_4.27.432.3973.81195.195310.5661287.28599621740083427205817568323_5.93.870.3071.26633.128263.6065812.44624660978477753296739911405.dcm\n",
      "data/5.35.500.1375.47629.197116.5794493.59587231661076745538263168838_1.32.790.2230.12951.852608.1276140.59867180182442057707377189483_8.63.524.4562.31304.166446.9665720.97090300305601188343443134326.dcm\n",
      "data/5.40.156.1585.41712.842626.5187078.37117375052559731314670602202_8.22.419.8561.93499.564696.1934355.10290669434610132058302050263_5.18.393.4311.43672.257044.9941540.26894939921665209763850798150.dcm\n",
      "data/5.47.195.3910.15434.187195.5068377.42006260512164496175738480597_4.50.127.2951.24748.583797.2266910.53135413515207627583533928784_6.98.885.2735.15426.779697.6670847.17396310471697092662471666011.dcm\n",
      "data/5.58.224.1365.47927.532850.8148877.97002156077315058788712643900_3.11.352.7146.18416.154345.2826945.73481015819987877819506894315_7.26.963.8164.47276.400448.7475274.95281891480256453567982945708.dcm\n",
      "data/5.63.420.7582.51807.142583.7532835.49115394536906674654582145323_1.41.104.7435.16723.606940.5593507.88908567915557205279421861991_7.58.225.7976.30161.191725.1960098.38133552672994006821288862540.dcm\n",
      "data/5.77.101.1188.85451.197549.9030146.44753382930882926234245961582_6.34.149.4526.42895.579359.2122835.12099223005081607029687481892_3.87.502.2104.66931.374106.2811561.18252026099860933232721824899.dcm\n",
      "data/5.79.401.7360.10405.896525.2742356.28710507931897860880502982094_3.16.725.9718.53752.374786.1632544.16217234352954456256562918458_3.91.132.8684.99477.314491.1817609.15274156840454913899334143967.dcm\n",
      "data/5.88.352.3897.21124.951357.1194811.15661357489538218807881532388_1.15.541.7806.57151.839178.1557663.76130122310270012397114781530_5.11.245.6037.51616.454606.5328066.13074922771872330885410515900.dcm\n",
      "data/5.90.117.5752.84205.144991.5902010.63795981152590161868604724884_2.20.698.2558.17877.123703.8007134.43358291830620376572213919800_6.11.669.1300.10477.160982.4240844.32919154901672126566776806469.dcm\n",
      "data/5.91.457.8318.88432.944112.6120730.14795696493690188437726490372_7.68.613.3209.92563.388518.6820779.47525281261482143202430177041_5.72.114.3260.95309.826779.8219919.12708414640493532400468420576.dcm\n",
      "data/6.15.163.6084.27366.247409.2544126.85202225583966920590874000799_2.70.888.5646.25863.870583.4671345.99819148068996578559065472917_3.55.504.3352.93400.642782.2853015.89590445015302385339760849293.dcm\n",
      "data/6.15.511.8459.21472.123512.7628921.99556983157948236436167924925_4.60.982.4272.16926.170069.1563713.74481738450679922497007165081_1.12.123.5253.36369.456598.8346057.41472431147021555014077097480.dcm\n",
      "data/6.40.828.6489.64509.485309.8150162.92137606228423791633136749768_1.10.400.6617.45356.835464.4258431.30008885544656323401092189429_1.11.187.9973.86364.596634.2778477.17312574051626058476675189721.dcm\n",
      "data/6.42.784.1513.33656.580248.3064168.48534219372363415899624431895_7.64.955.8263.18575.409446.3640855.51882253620436712390570662146_2.86.966.1249.12896.142851.7012656.52807079842961239965702982579.dcm\n",
      "data/6.51.961.9802.14551.711576.4881796.17525135720251786575167100641_9.42.991.3047.82059.713522.3207774.19249771284850965432004139976_1.17.931.3862.19647.803320.4644299.70049228361960395582749788046.dcm\n",
      "data/6.52.405.8969.54175.708674.1619703.10953156656680063565416410622_8.70.982.8358.54028.639521.4758821.12849450980112551136488922213_2.58.975.4091.11057.787327.7561809.30310114175110672065424160610.dcm\n",
      "data/6.54.662.4702.13897.297564.5001709.26857758684759221586887876313_5.63.356.6827.39817.399472.9924354.37094696257108222798156405079_9.71.932.9956.13033.502383.6255985.66331193490320727859148703237.dcm\n",
      "data/6.61.175.2327.33734.183160.4829262.14726470646693610781751824957_5.78.642.6761.72711.523745.2852150.55323438382051512355250816979_1.10.766.2144.37713.557635.1562439.10238599233725863371517190889.dcm\n",
      "data/6.65.334.1225.15774.762121.3180231.18603946373904960111199226445_1.12.703.9044.21716.404796.9307980.95363717109158832804920000422_6.28.771.3106.37178.609505.6695247.21195255683909877450976530305.dcm\n",
      "data/6.66.648.6502.29956.942361.8635216.88784061074834924575344731618_1.12.257.1269.72544.926497.3917908.55909786667439060912057374221_8.31.316.4857.55858.138865.1007709.77498605583581585373740049653.dcm\n",
      "data/6.80.775.7556.19239.192699.1825714.87076623317754286274184534697_8.13.989.7153.55784.813890.9255973.19438927855826438073735203625_1.36.534.9331.98857.922221.5974485.72794994635972440137852095847.dcm\n",
      "data/6.82.757.8595.11577.851319.1805630.42781191565635798945358909279_1.12.340.1601.36414.698006.1746675.17828744482416608407538690808_8.66.930.3958.85540.736504.5893079.52774207666540537828954489688.dcm\n",
      "data/6.83.518.5177.48182.345100.8306761.34281969396893331291053528420_6.56.270.8134.30856.155751.4247617.79007716620653022415356363204_4.82.527.1212.26227.454819.5870202.76689373061364734599229546869.dcm\n",
      "data/7.12.123.4157.91860.248575.8286697.38621201650858432271906778257_5.38.113.9390.16860.261289.1833221.12820069214712500060636221432_5.15.304.9356.26312.113496.5334786.56370221351474717123076467144.dcm\n",
      "data/7.29.170.2127.44264.660635.6107266.33554414114594534531048655153_6.64.462.8728.34554.435617.1700102.11473082888750410806245488921_1.18.463.7596.83434.496207.1193109.18566906561230028594222282921.dcm\n",
      "data/7.30.155.5941.91159.716066.5585135.52707035856874961494772910210_4.39.842.4863.95712.974842.4395984.18837010443014610174673535855_3.79.192.7817.13052.775115.9723906.45128822617499585582708938319.dcm\n",
      "data/7.33.133.3027.79930.205419.8916854.62196162212110375517377719752_5.88.682.4795.75980.858383.2945881.31137533085929489196275110128_5.63.584.7898.11985.537879.3988007.74636346956422888142376118702.dcm\n",
      "data/7.34.129.3958.38253.212375.6010961.28901921167124136402138637605_7.69.286.6927.33259.567530.8606526.56318810043658411952526813050_9.54.218.5145.97024.859446.6267091.71572873817294588040186701959.dcm\n",
      "data/7.41.930.1008.24395.127131.2375763.73519423700966976269633219017_2.19.445.1255.10246.512341.1441471.92445729369699238486189681285_9.27.190.1818.40323.931593.8477989.14787455980710428980056071016.dcm\n",
      "data/7.52.120.1223.69446.892666.6571970.38472257484952301153641931524_4.68.469.9972.36056.919029.6507439.21903211917666353042348620251_5.31.789.1641.64628.430609.3706314.66231843829282066784003902524.dcm\n",
      "data/7.54.207.8951.81708.562316.2853073.41172144376790956082039618807_3.31.142.1188.50797.361477.7397984.62967671485329940714688237862_4.88.724.6925.63004.750855.4693263.77844019106667799963757734252.dcm\n",
      "data/7.64.130.1481.62295.977960.8300262.34719059629194315482234907646_4.63.823.4412.90100.204819.8329307.89928227084769839948262014749_6.41.325.2770.92369.732443.4046722.61167716765441716445221990905.dcm\n",
      "data/7.65.389.9925.87925.886034.5142659.77536266814977636987579334328_1.13.976.9456.69999.376837.1834365.69731000308041036460844813722_4.90.138.8774.99366.222778.8291888.58017553371927436792503378663.dcm\n",
      "data/7.73.813.7361.21581.809945.1617886.10665117178530299451140763425_6.41.728.1825.78569.525263.4202198.50973240226792917648678838837_1.15.330.7044.71387.915379.6045792.33507511331138284663876792409.dcm\n",
      "data/7.99.424.6402.95166.683728.1052567.55698766510541669767241416888_4.52.213.6556.93384.159507.8821053.57229903749953983569691633561_3.25.331.3387.42557.573813.8534834.10725884375590773554858713762.dcm\n",
      "data/7.99.551.4120.99697.876324.9923622.10396463669849949414900613532_2.12.586.2738.79272.847515.7123326.68051952306544941569302733232_4.12.129.8555.60674.173171.4219511.83178256844164388718750538117.dcm\n",
      "data/8.12.485.3226.12740.974101.9560515.14517489361363299251517195692_9.16.831.3840.11797.383832.5764476.82664768537810901673700617498_5.69.498.3775.69268.206261.5865262.18757243961455678123348300848.dcm\n",
      "data/8.45.795.3078.34500.175949.1550957.29755422141886868101529811449_4.93.732.9009.69689.299220.3406258.74590122008897183420404768425_8.90.195.1188.33277.559972.1617680.32116855567954828523874786880.dcm\n",
      "data/8.62.327.1326.92180.349525.6393139.70028386126524309069487570605_5.83.696.7179.45794.435149.9774084.33349148393473717954737482536_9.30.167.2445.29223.425222.7274192.39543224928152176553512423963.dcm\n",
      "data/8.62.640.9937.44129.889189.1592336.30853649234154540047567456053_7.13.911.6756.79760.182442.1909062.20624813297839314062092252460_5.97.700.5591.68451.615742.3409207.81362814973548372335909280276.dcm\n",
      "data/8.65.621.6272.45629.542598.3519466.53190987112210555278910070704_6.84.216.6297.59518.780120.7309032.11501517893392815748571560873_5.26.911.9845.10733.664451.7460756.10287058740216774881626040487.dcm\n",
      "data/8.93.344.8961.18142.770022.6551784.93820756462093463741380912599_7.63.267.9995.45300.415401.4392426.62257006672734591187563694465_1.15.228.7547.25618.690569.9888012.30983141657368406195145010938.dcm\n",
      "data/9.10.818.5154.63645.412070.6018927.63199635959868537694569781302_8.94.388.1529.69208.778672.1221686.21219922981316243737908403248_1.35.108.7660.32735.491857.8455650.54541238437556883737828826118.dcm\n",
      "data/9.14.932.8674.42233.437803.3999667.44672470805396662938935803565_6.56.843.7980.71733.181916.4677936.84662570716371949503565751700_5.16.166.3567.13366.112099.3228509.26188105211809443107546600531.dcm\n",
      "data/9.29.255.2472.78866.124996.7641581.65727742578197068494918935977_7.21.635.1326.24995.403414.1826556.13437553138525793225594535249_8.15.256.2533.15545.777270.7734286.70103752139443260335915448928.dcm\n",
      "data/9.40.912.1316.10621.684032.9997253.75372405161750441216911183681_1.58.506.6361.88371.490167.8385513.39017063985357250147775079059_2.86.191.1740.93080.309965.3347025.14318088782241563901702380986.dcm\n",
      "data/9.41.728.3708.41955.117300.7966818.63824097217632303927790610549_5.15.261.2745.19031.102046.8477070.29322840472483330382038480420_6.22.268.7495.27222.839120.8129341.65712490137503290336504624687.dcm\n",
      "data/9.63.780.4174.15394.787627.7623863.54390443086026534950323039708_6.18.233.7038.40737.107573.5963498.70765980555448890157957005644_1.10.827.1808.93065.673159.5682913.40370999244622660628125180529.dcm\n",
      "data/9.70.129.4720.95619.345530.2348354.16644627673931296195094068483_1.14.439.7469.64567.268248.9238260.76089624392180540317208335864_1.17.692.9092.57858.953206.8821239.30389549610419339208660241301.dcm\n",
      "data/9.81.557.7748.18983.141302.7322637.82503832984007696050344553683_8.40.188.9003.54088.778581.1709993.86956196184612240798683967207_9.89.667.1763.77367.256762.8821491.26498986297019309957304169266.dcm\n",
      "data/9.89.170.3959.47238.780496.1523268.11658060860634230728347976332_2.10.176.2810.19901.631656.2613097.86525402485669565528106609781_7.40.147.9922.15486.611009.4310113.52094275593719774149056087801.dcm\n",
      "data/9.90.101.1010.51820.359933.9890868.87518787153834657052462821070_1.14.188.4159.12372.175796.5335316.70970474650448134216072957731_3.37.487.7285.69457.503956.3215879.75979103174350018005642719667.dcm\n",
      "data/9.93.933.1485.65621.325603.4939840.96122600681902659620721832951_7.95.508.3357.36991.944399.9151677.73995317267225996290451785089_6.75.802.4499.17112.984674.6396184.97503933562433054480057675636.dcm\n",
      "labels/28743102-e626-46b1-b5f1-d312c82e1bcb.csv\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-images-idx3-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-labels-idx1-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-images-idx3-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-labels-idx1-ubyte\n",
      "sagemaker/DEMO-pytorch-mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Downloading Data from S3\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from boto3 import client\n",
    "import os\n",
    "os.mkdir(\"data\")\n",
    "os.mkdir(\"labels\")\n",
    "BUCKET_NAME = bucket\n",
    "c = 0\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])\n",
    "    KEY = key['Key']\n",
    "    s3 = boto3.resource('s3')\n",
    "    try:\n",
    "        s3.Bucket(BUCKET_NAME).download_file(KEY, f\"{key['Key']}\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise\n",
    "    c = c+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Converting downloaded data to png\n",
    "\n",
    "# Dcm to Png\n",
    "!pip install pydicom\n",
    "import pydicom as dicom\n",
    "import pydicom\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    try:\n",
    "        print(\"Converting to PNG .........................\")\n",
    "        dicom = dcmread(path, force=True)\n",
    "        print(dicom.SOPInstanceUID, \">>>>>>\", dicom.InstanceNumber, \">>>>>\", dicom.SeriesInstanceUID)\n",
    "        #if voi_lut:\n",
    "        if voi_lut and len(dicom.get(\"VOILUTSequence\", [])):\n",
    "            data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "        else:\n",
    "            data = dicom.pixel_array\n",
    "        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.amax(data) - data\n",
    "        data = data - np.min(data)\n",
    "        data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(e, \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        return \"corrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.rglob at 0x7ff80c460dd0>\n",
      "downloaded/training_dicom7.dcm\n",
      "Converting to PNG .........................\n",
      "5.78.165.8753.87981.158522.9691017.31219635449818643820871103152 >>>>>> None >>>>> 3.47.512.4308.88844.978974.8333351.93114562641818086253127085393\n",
      "1 Done\n",
      "downloaded/training_dicom61.dcm\n",
      "Converting to PNG .........................\n",
      "2.86.966.1249.12896.142851.7012656.52807079842961239965702982579 >>>>>> None >>>>> 7.64.955.8263.18575.409446.3640855.51882253620436712390570662146\n",
      "2 Done\n",
      "downloaded/training_dicom25.dcm\n",
      "Converting to PNG .........................\n",
      "2.16.731.2653.65463.449091.8917667.41222623441020182497739876237 >>>>>> None >>>>> 9.32.558.1632.35311.289135.5169772.59783536133376193141554188494\n",
      "3 Done\n",
      "downloaded/training_dicom43.dcm\n",
      "Converting to PNG .........................\n",
      "1.13.122.7584.87360.909434.2488129.94176012338520824434242075633 >>>>>> None >>>>> 3.96.203.5623.14458.536123.9923452.32605908197158403490129812583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Done\n",
      "downloaded/training_dicom106.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom70.dcm\n",
      "Converting to PNG .........................\n",
      "4.82.527.1212.26227.454819.5870202.76689373061364734599229546869 >>>>>> None >>>>> 6.56.270.8134.30856.155751.4247617.79007716620653022415356363204\n",
      "5 Done\n",
      "downloaded/training_dicom34.dcm\n",
      "Converting to PNG .........................\n",
      "7.43.194.2532.19555.984100.4655679.20909524581407096942960578198 >>>>>> None >>>>> 1.12.132.8397.90029.722208.3375529.98323350099395856927194532597\n",
      "6 Done\n",
      "downloaded/training_dicom16.dcm\n",
      "Converting to PNG .........................\n",
      "5.13.739.6323.95176.911483.1047870.19058515666082043809459233223 >>>>>> None >>>>> 4.62.143.1766.49452.390831.3652060.16908970487932721084260947354\n",
      "7 Done\n",
      "downloaded/training_dicom52.dcm\n",
      "Converting to PNG .........................\n",
      "7.58.225.7976.30161.191725.1960098.38133552672994006821288862540 >>>>>> None >>>>> 1.41.104.7435.16723.606940.5593507.88908567915557205279421861991\n",
      "8 Done\n",
      "downloaded/training_dicom69.dcm\n",
      "Converting to PNG .........................\n",
      "8.66.930.3958.85540.736504.5893079.52774207666540537828954489688 >>>>>> None >>>>> 1.12.340.1601.36414.698006.1746675.17828744482416608407538690808\n",
      "9 Done\n",
      "downloaded/training_dicom87.dcm\n",
      "Converting to PNG .........................\n",
      "5.97.700.5591.68451.615742.3409207.81362814973548372335909280276 >>>>>> None >>>>> 7.13.911.6756.79760.182442.1909062.20624813297839314062092252460\n",
      "10 Done\n",
      "downloaded/training_dicom78.dcm\n",
      "Converting to PNG .........................\n",
      "4.88.724.6925.63004.750855.4693263.77844019106667799963757734252 >>>>>> None >>>>> 3.31.142.1188.50797.361477.7397984.62967671485329940714688237862\n",
      "11 Done\n",
      "downloaded/training_dicom96.dcm\n",
      "Converting to PNG .........................\n",
      "1.17.692.9092.57858.953206.8821239.30389549610419339208660241301 >>>>>> None >>>>> 1.14.439.7469.64567.268248.9238260.76089624392180540317208335864\n",
      "12 Done\n",
      "downloaded/training_dicom65.dcm\n",
      "Converting to PNG .........................\n",
      "1.10.766.2144.37713.557635.1562439.10238599233725863371517190889 >>>>>> None >>>>> 5.78.642.6761.72711.523745.2852150.55323438382051512355250816979\n",
      "13 Done\n",
      "downloaded/training_dicom29.dcm\n",
      "Converting to PNG .........................\n",
      "5.44.484.1565.35078.472503.4142455.41444692526209061326993613919 >>>>>> None >>>>> 1.21.391.2396.22207.733597.3350816.28084333787885324572490315659\n",
      "14 Done\n",
      "downloaded/training_dicom83.dcm\n",
      "Converting to PNG .........................\n",
      "4.12.129.8555.60674.173171.4219511.83178256844164388718750538117 >>>>>> None >>>>> 2.12.586.2738.79272.847515.7123326.68051952306544941569302733232\n",
      "15 Done\n",
      "downloaded/training_dicom47.dcm\n",
      "Converting to PNG .........................\n",
      "5.93.870.3071.26633.128263.6065812.44624660978477753296739911405 >>>>>> None >>>>> 4.27.432.3973.81195.195310.5661287.28599621740083427205817568323\n",
      "16 Done\n",
      "downloaded/training_dicom74.dcm\n",
      "Converting to PNG .........................\n",
      "5.63.584.7898.11985.537879.3988007.74636346956422888142376118702 >>>>>> None >>>>> 5.88.682.4795.75980.858383.2945881.31137533085929489196275110128\n",
      "17 Done\n",
      "downloaded/training_dicom38.dcm\n",
      "Converting to PNG .........................\n",
      "1.15.346.1312.78412.689367.8385976.16975057291649603355414773865 >>>>>> None >>>>> 1.13.792.7336.59667.674796.7343041.36082973286212502059022867908\n",
      "18 Done\n",
      "downloaded/training_dicom92.dcm\n",
      "Converting to PNG .........................\n",
      "8.15.256.2533.15545.777270.7734286.70103752139443260335915448928 >>>>>> None >>>>> 7.21.635.1326.24995.403414.1826556.13437553138525793225594535249\n",
      "19 Done\n",
      "downloaded/training_dicom56.dcm\n",
      "Converting to PNG .........................\n",
      "6.11.669.1300.10477.160982.4240844.32919154901672126566776806469 >>>>>> None >>>>> 2.20.698.2558.17877.123703.8007134.43358291830620376572213919800\n",
      "20 Done\n",
      "downloaded/training_dicom30.dcm\n",
      "Converting to PNG .........................\n",
      "1.10.155.4258.96000.462929.2300254.39388613540561666285264298548 >>>>>> None >>>>> 3.46.365.5214.53892.404976.5691605.29333290598016069111328609624\n",
      "21 Done\n",
      "downloaded/training_dicom12.dcm\n",
      "Converting to PNG .........................\n",
      "3.70.791.8327.21758.119627.7163844.28050427410947465046798606603 >>>>>> None >>>>> 5.49.296.6036.73255.310104.1807651.81463627707862460523697566921\n",
      "22 Done\n",
      "downloaded/training_dicom102.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom21.dcm\n",
      "Converting to PNG .........................\n",
      "2.19.455.1737.12041.942119.2782985.10210242739318825025109014657 >>>>>> None >>>>> 1.19.872.1510.16349.390417.1841743.34452856825498837994182972556\n",
      "23 Done\n",
      "downloaded/training_dicom3.dcm\n",
      "Converting to PNG .........................\n",
      "1.12.716.5329.19210.710458.9194349.92481456069811815581169388576 >>>>>> None >>>>> 8.41.552.3169.48654.890784.1114012.14201826718081841047037652106\n",
      "24 Done\n",
      "downloaded/training_dicom63.dcm\n",
      "Converting to PNG .........................\n",
      "2.58.975.4091.11057.787327.7561809.30310114175110672065424160610 >>>>>> None >>>>> 8.70.982.8358.54028.639521.4758821.12849450980112551136488922213\n",
      "25 Done\n",
      "downloaded/training_dicom9.dcm\n",
      "Converting to PNG .........................\n",
      "5.84.813.7442.26906.249641.7882071.42722539157927238158755261919 >>>>>> None >>>>> 6.27.836.4337.11323.102088.2032355.48998052066371699819544384429\n",
      "26 Done\n",
      "downloaded/training_dicom27.dcm\n",
      "Converting to PNG .........................\n",
      "3.13.169.7366.41516.717836.1817932.90266571263599295950210107745 >>>>>> None >>>>> 9.57.110.3833.83570.471283.3965604.62566804698593308292970319150\n",
      "27 Done\n",
      "downloaded/training_dicom81.dcm\n",
      "Converting to PNG .........................\n",
      "1.15.330.7044.71387.915379.6045792.33507511331138284663876792409 >>>>>> None >>>>> 6.41.728.1825.78569.525263.4202198.50973240226792917648678838837\n",
      "28 Done\n",
      "downloaded/training_dicom108.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom45.dcm\n",
      "Converting to PNG .........................\n",
      "8.40.407.1300.82192.402084.2684414.42634327661690686734764624135 >>>>>> None >>>>> 7.29.141.7602.46506.431244.8849953.86705008228246361839744806494\n",
      "29 Done\n",
      "downloaded/training_dicom72.dcm\n",
      "Converting to PNG .........................\n",
      "1.18.463.7596.83434.496207.1193109.18566906561230028594222282921 >>>>>> None >>>>> 6.64.462.8728.34554.435617.1700102.11473082888750410806245488921\n",
      "30 Done\n",
      "downloaded/training_dicom36.dcm\n",
      "Converting to PNG .........................\n",
      "1.55.199.1280.86449.807558.2331688.90055422376738262657710346972 >>>>>> None >>>>> 2.48.314.1897.15529.838703.1343477.87379748657108673706575982510\n",
      "31 Done\n",
      "downloaded/training_dicom90.dcm\n",
      "Converting to PNG .........................\n",
      "1.35.108.7660.32735.491857.8455650.54541238437556883737828826118 >>>>>> None >>>>> 8.94.388.1529.69208.778672.1221686.21219922981316243737908403248\n",
      "32 Done\n",
      "downloaded/training_dicom18.dcm\n",
      "Converting to PNG .........................\n",
      "4.38.164.1704.36318.682740.3889586.10136393472786550904565913473 >>>>>> None >>>>> 2.51.812.5127.64842.534421.1963231.16270780506902189158429347396\n",
      "33 Done\n",
      "downloaded/training_dicom54.dcm\n",
      "Converting to PNG .........................\n",
      "3.91.132.8684.99477.314491.1817609.15274156840454913899334143967 >>>>>> None >>>>> 3.16.725.9718.53752.374786.1632544.16217234352954456256562918458\n",
      "34 Done\n",
      "downloaded/training_dicom89.dcm\n",
      "Converting to PNG .........................\n",
      "1.15.228.7547.25618.690569.9888012.30983141657368406195145010938 >>>>>> None >>>>> 7.63.267.9995.45300.415401.4392426.62257006672734591187563694465\n",
      "35 Done\n",
      "downloaded/training_dicom10.dcm\n",
      "Converting to PNG .........................\n",
      "2.67.931.4897.33379.559142.2328999.81218523322021525217065183734 >>>>>> None >>>>> 2.49.462.1933.95988.534814.2381078.36302764730346005779500669285\n",
      "36 Done\n",
      "downloaded/training_dicom100.dcm\n",
      "Converting to PNG .........................\n",
      "6.75.802.4499.17112.984674.6396184.97503933562433054480057675636 >>>>>> None >>>>> 7.95.508.3357.36991.944399.9151677.73995317267225996290451785089\n",
      "37 Done\n",
      "downloaded/training_dicom98.dcm\n",
      "Converting to PNG .........................\n",
      "7.40.147.9922.15486.611009.4310113.52094275593719774149056087801 >>>>>> None >>>>> 2.10.176.2810.19901.631656.2613097.86525402485669565528106609781\n",
      "38 Done\n",
      "downloaded/training_dicom1.dcm\n",
      "Converting to PNG .........................\n",
      "1.10.438.7074.32125.900008.4092280.70162125893606125565043933402 >>>>>> None >>>>> 1.43.318.8932.46424.646527.5125264.34607190288155359632618069574\n",
      "39 Done\n",
      "downloaded/training_dicom67.dcm\n",
      "Converting to PNG .........................\n",
      "8.31.316.4857.55858.138865.1007709.77498605583581585373740049653 >>>>>> None >>>>> 1.12.257.1269.72544.926497.3917908.55909786667439060912057374221\n",
      "40 Done\n",
      "downloaded/training_dicom85.dcm\n",
      "Converting to PNG .........................\n",
      "8.90.195.1188.33277.559972.1617680.32116855567954828523874786880 >>>>>> None >>>>> 4.93.732.9009.69689.299220.3406258.74590122008897183420404768425\n",
      "41 Done\n",
      "downloaded/training_dicom49.dcm\n",
      "Converting to PNG .........................\n",
      "5.18.393.4311.43672.257044.9941540.26894939921665209763850798150 >>>>>> None >>>>> 8.22.419.8561.93499.564696.1934355.10290669434610132058302050263\n",
      "42 Done\n",
      "downloaded/training_dicom76.dcm\n",
      "Converting to PNG .........................\n",
      "9.27.190.1818.40323.931593.8477989.14787455980710428980056071016 >>>>>> None >>>>> 2.19.445.1255.10246.512341.1441471.92445729369699238486189681285\n",
      "43 Done\n",
      "downloaded/training_dicom94.dcm\n",
      "Converting to PNG .........................\n",
      "6.22.268.7495.27222.839120.8129341.65712490137503290336504624687 >>>>>> None >>>>> 5.15.261.2745.19031.102046.8477070.29322840472483330382038480420\n",
      "44 Done\n",
      "downloaded/training_dicom58.dcm\n",
      "Converting to PNG .........................\n",
      "3.55.504.3352.93400.642782.2853015.89590445015302385339760849293 >>>>>> None >>>>> 2.70.888.5646.25863.870583.4671345.99819148068996578559065472917\n",
      "45 Done\n",
      "downloaded/training_dicom32.dcm\n",
      "Converting to PNG .........................\n",
      "2.43.894.2823.54083.824748.1689114.52854405033586617974016841040 >>>>>> None >>>>> 1.10.135.2137.90574.654471.1177685.47977662923654865364383712637\n",
      "46 Done\n",
      "downloaded/training_dicom14.dcm\n",
      "Converting to PNG .........................\n",
      "1.10.473.1436.77765.111776.3389285.86021203145131218647273600165 >>>>>> None >>>>> 1.13.213.4013.67084.240721.9694884.46746232454156551632077318369\n",
      "47 Done\n",
      "downloaded/training_dicom50.dcm\n",
      "Converting to PNG .........................\n",
      "6.98.885.2735.15426.779697.6670847.17396310471697092662471666011 >>>>>> None >>>>> 4.50.127.2951.24748.583797.2266910.53135413515207627583533928784\n",
      "48 Done\n",
      "downloaded/training_dicom104.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom41.dcm\n",
      "Converting to PNG .........................\n",
      "1.11.949.1282.51562.103841.4339302.15434316088621603164348573941 >>>>>> None >>>>> 6.40.324.7744.58148.151585.5317550.87857907664413219387255703121\n",
      "49 Done\n",
      "downloaded/training_dicom23.dcm\n",
      "Converting to PNG .........................\n",
      "5.47.864.3724.41473.107307.7397212.19090539457393732317665561277 >>>>>> None >>>>> 1.47.646.8695.33749.622980.2292833.19189290202877616116682551588\n",
      "50 Done\n",
      "downloaded/training_dicom5.dcm\n",
      "Converting to PNG .........................\n",
      "4.91.998.5134.92640.360898.4356616.12956076032076596955093898554 >>>>>> None >>>>> 9.67.784.1519.63975.412791.1359465.57892300036664370288960805405\n",
      "51 Done\n",
      "downloaded/training_dicom26.dcm\n",
      "Converting to PNG .........................\n",
      "5.31.139.1651.65917.236474.3843609.99274194946806339038368874230 >>>>>> None >>>>> 3.86.122.8163.93326.767469.3581652.79497696311183665610617239639\n",
      "52 Done\n",
      "downloaded/training_dicom8.dcm\n",
      "Converting to PNG .........................\n",
      "9.39.224.9074.45936.831843.8831969.81109334288071326555323115630 >>>>>> None >>>>> 9.99.136.1548.43905.344612.6492351.54543418923596905421189792785\n",
      "53 Done\n",
      "downloaded/training_dicom62.dcm\n",
      "Converting to PNG .........................\n",
      "1.17.931.3862.19647.803320.4644299.70049228361960395582749788046 >>>>>> None >>>>> 9.42.991.3047.82059.713522.3207774.19249771284850965432004139976\n",
      "54 Done\n",
      "downloaded/training_dicom107.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom44.dcm\n",
      "Converting to PNG .........................\n",
      "3.84.236.1821.99762.199817.6030085.49260656528601022353229570793 >>>>>> None >>>>> 2.55.463.3753.66415.339963.1159851.59400782421098727501673637189\n",
      "55 Done\n",
      "downloaded/training_dicom80.dcm\n",
      "Converting to PNG .........................\n",
      "4.90.138.8774.99366.222778.8291888.58017553371927436792503378663 >>>>>> None >>>>> 1.13.976.9456.69999.376837.1834365.69731000308041036460844813722\n",
      "56 Done\n",
      "downloaded/training_dicom35.dcm\n",
      "Converting to PNG .........................\n",
      "8.35.482.6513.72149.216735.2320889.19154119468637915995905581434 >>>>>> None >>>>> 6.19.378.6440.60533.560558.1086728.66761975031877591768674946117\n",
      "57 Done\n",
      "downloaded/training_dicom71.dcm\n",
      "Converting to PNG .........................\n",
      "5.15.304.9356.26312.113496.5334786.56370221351474717123076467144 >>>>>> None >>>>> 5.38.113.9390.16860.261289.1833221.12820069214712500060636221432\n",
      "58 Done\n",
      "downloaded/training_dicom53.dcm\n",
      "Converting to PNG .........................\n",
      "3.87.502.2104.66931.374106.2811561.18252026099860933232721824899 >>>>>> None >>>>> 6.34.149.4526.42895.579359.2122835.12099223005081607029687481892\n",
      "59 Done\n",
      "downloaded/training_dicom17.dcm\n",
      "Converting to PNG .........................\n",
      "2.66.406.7563.78029.542325.2137084.17926805987453147793329018713 >>>>>> None >>>>> 9.14.560.8353.45545.642219.7752569.12226218888015320681782118185\n",
      "60 Done\n",
      "downloaded/training_dicom88.dcm\n",
      "Converting to PNG .........................\n",
      "5.26.911.9845.10733.664451.7460756.10287058740216774881626040487 >>>>>> None >>>>> 6.84.216.6297.59518.780120.7309032.11501517893392815748571560873\n",
      "61 Done\n",
      "downloaded/training_dicom79.dcm\n",
      "Converting to PNG .........................\n",
      "6.41.325.2770.92369.732443.4046722.61167716765441716445221990905 >>>>>> None >>>>> 4.63.823.4412.90100.204819.8329307.89928227084769839948262014749\n",
      "62 Done\n",
      "downloaded/training_dicom0.dcm\n",
      "Converting to PNG .........................\n",
      "9.59.156.4421.74552.215908.6904659.49034716993854402263648069793 >>>>>> None >>>>> 5.50.165.1847.21251.931697.4943068.66587612922852477819742239754\n",
      "63 Done\n",
      "downloaded/training_dicom97.dcm\n",
      "Converting to PNG .........................\n",
      "9.89.667.1763.77367.256762.8821491.26498986297019309957304169266 >>>>>> None >>>>> 8.40.188.9003.54088.778581.1709993.86956196184612240798683967207\n",
      "64 Done\n",
      "downloaded/training_dicom66.dcm\n",
      "Converting to PNG .........................\n",
      "6.28.771.3106.37178.609505.6695247.21195255683909877450976530305 >>>>>> None >>>>> 1.12.703.9044.21716.404796.9307980.95363717109158832804920000422\n",
      "65 Done\n",
      "downloaded/training_dicom48.dcm\n",
      "Converting to PNG .........................\n",
      "8.63.524.4562.31304.166446.9665720.97090300305601188343443134326 >>>>>> None >>>>> 1.32.790.2230.12951.852608.1276140.59867180182442057707377189483\n",
      "66 Done\n",
      "downloaded/training_dicom84.dcm\n",
      "Converting to PNG .........................\n",
      "5.69.498.3775.69268.206261.5865262.18757243961455678123348300848 >>>>>> None >>>>> 9.16.831.3840.11797.383832.5764476.82664768537810901673700617498\n",
      "67 Done\n",
      "downloaded/training_dicom39.dcm\n",
      "Converting to PNG .........................\n",
      "1.34.182.4910.30031.210358.6054294.26294079043434500059119062896 >>>>>> None >>>>> 7.23.521.8767.46290.115774.2884581.26614546494236189953880130970\n",
      "68 Done\n",
      "downloaded/training_dicom75.dcm\n",
      "Converting to PNG .........................\n",
      "9.54.218.5145.97024.859446.6267091.71572873817294588040186701959 >>>>>> None >>>>> 7.69.286.6927.33259.567530.8606526.56318810043658411952526813050\n",
      "69 Done\n",
      "downloaded/training_dicom57.dcm\n",
      "Converting to PNG .........................\n",
      "5.72.114.3260.95309.826779.8219919.12708414640493532400468420576 >>>>>> None >>>>> 7.68.613.3209.92563.388518.6820779.47525281261482143202430177041\n",
      "70 Done\n",
      "downloaded/training_dicom93.dcm\n",
      "Converting to PNG .........................\n",
      "2.86.191.1740.93080.309965.3347025.14318088782241563901702380986 >>>>>> None >>>>> 1.58.506.6361.88371.490167.8385513.39017063985357250147775079059\n",
      "71 Done\n",
      "downloaded/training_dicom31.dcm\n",
      "Converting to PNG .........................\n",
      "8.49.456.1075.67599.420348.1459696.26556372360413487178550006995 >>>>>> None >>>>> 1.17.150.8419.71103.125928.2110322.62043688860718910963353749445\n",
      "72 Done\n",
      "downloaded/training_dicom13.dcm\n",
      "Converting to PNG .........................\n",
      "8.72.954.3902.64376.849756.5215898.74464889701846710141264766217 >>>>>> None >>>>> 4.70.305.9394.93977.488751.3302541.10240460210961895757760595553\n",
      "73 Done\n",
      "downloaded/training_dicom103.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom40.dcm\n",
      "Converting to PNG .........................\n",
      "5.95.128.4478.68688.863063.5279346.13512545678679686780381603645 >>>>>> None >>>>> 1.15.387.4759.14370.943417.4001212.96507381927585527790954131483\n",
      "74 Done\n",
      "downloaded/training_dicom4.dcm\n",
      "Converting to PNG .........................\n",
      "1.16.435.9740.47447.416936.9741465.54444623486982581631972438676 >>>>>> None >>>>> 4.25.566.4222.23306.762121.7943945.56687295583391761904186824676\n",
      "75 Done\n",
      "downloaded/training_dicom22.dcm\n",
      "Converting to PNG .........................\n",
      "2.76.618.1311.10966.998299.7895466.47343057584993727071217284972 >>>>>> None >>>>> 2.60.277.1003.83515.379528.8520305.11766343860810614445253051411\n",
      "76 Done\n",
      "downloaded/training_dicom28.dcm\n",
      "Converting to PNG .........................\n",
      "6.19.974.4531.40752.876487.7832288.35350796048620204285337081262 >>>>>> None >>>>> 9.50.773.6456.35757.628429.1555881.84263930875576921349362301308\n",
      "77 Done\n",
      "downloaded/training_dicom64.dcm\n",
      "Converting to PNG .........................\n",
      "9.71.932.9956.13033.502383.6255985.66331193490320727859148703237 >>>>>> None >>>>> 5.63.356.6827.39817.399472.9924354.37094696257108222798156405079\n",
      "78 Done\n",
      "downloaded/training_dicom46.dcm\n",
      "Converting to PNG .........................\n",
      "3.43.152.1458.36018.182336.1059562.69372091447582557221009107232 >>>>>> None >>>>> 8.13.212.4104.71849.512907.7813573.54417018957189279463951149871\n",
      "79 Done\n",
      "downloaded/training_dicom109.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom82.dcm\n",
      "Converting to PNG .........................\n",
      "3.25.331.3387.42557.573813.8534834.10725884375590773554858713762 >>>>>> None >>>>> 4.52.213.6556.93384.159507.8821053.57229903749953983569691633561\n",
      "80 Done\n",
      "downloaded/training_dicom37.dcm\n",
      "Converting to PNG .........................\n",
      "3.77.809.4393.70336.519402.2428001.17290348135240359814126417094 >>>>>> None >>>>> 2.52.103.1468.37601.870764.1061416.24951914310205728505912819708\n",
      "81 Done\n",
      "downloaded/training_dicom73.dcm\n",
      "Converting to PNG .........................\n",
      "3.79.192.7817.13052.775115.9723906.45128822617499585582708938319 >>>>>> None >>>>> 4.39.842.4863.95712.974842.4395984.18837010443014610174673535855\n",
      "82 Done\n",
      "downloaded/training_dicom55.dcm\n",
      "Converting to PNG .........................\n",
      "5.11.245.6037.51616.454606.5328066.13074922771872330885410515900 >>>>>> None >>>>> 1.15.541.7806.57151.839178.1557663.76130122310270012397114781530\n",
      "83 Done\n",
      "downloaded/training_dicom91.dcm\n",
      "Converting to PNG .........................\n",
      "5.16.166.3567.13366.112099.3228509.26188105211809443107546600531 >>>>>> None >>>>> 6.56.843.7980.71733.181916.4677936.84662570716371949503565751700\n",
      "84 Done\n",
      "downloaded/training_dicom19.dcm\n",
      "Converting to PNG .........................\n",
      "2.34.106.1534.97826.183084.5768251.69796769647508285637731093263 >>>>>> None >>>>> 7.81.251.2597.85443.741725.7451330.44020773125463261737439252298\n",
      "85 Done\n",
      "downloaded/training_dicom11.dcm\n",
      "Converting to PNG .........................\n",
      "1.77.168.8708.16432.574999.4147770.11188502437450089848062001791 >>>>>> None >>>>> 7.47.348.3890.49607.624780.9546773.95295363476040061679063308759\n",
      "86 Done\n",
      "downloaded/training_dicom101.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom2.dcm\n",
      "Converting to PNG .........................\n",
      "1.94.287.6068.64042.801707.8730888.96213932843756638999515284232 >>>>>> None >>>>> 7.73.122.6517.38425.389142.3671342.37329354064982022344298925837\n",
      "87 Done\n",
      "downloaded/training_dicom99.dcm\n",
      "Converting to PNG .........................\n",
      "3.37.487.7285.69457.503956.3215879.75979103174350018005642719667 >>>>>> None >>>>> 1.14.188.4159.12372.175796.5335316.70970474650448134216072957731\n",
      "88 Done\n",
      "downloaded/training_dicom20.dcm\n",
      "Converting to PNG .........................\n",
      "2.90.422.5610.14624.379758.8041829.54897498235548600350004654443 >>>>>> None >>>>> 1.46.204.1025.61729.580920.2777235.86379478965828848726558312258\n",
      "89 Done\n",
      "downloaded/training_dicom68.dcm\n",
      "Converting to PNG .........................\n",
      "1.36.534.9331.98857.922221.5974485.72794994635972440137852095847 >>>>>> None >>>>> 8.13.989.7153.55784.813890.9255973.19438927855826438073735203625\n",
      "90 Done\n",
      "downloaded/training_dicom86.dcm\n",
      "Converting to PNG .........................\n",
      "9.30.167.2445.29223.425222.7274192.39543224928152176553512423963 >>>>>> None >>>>> 5.83.696.7179.45794.435149.9774084.33349148393473717954737482536\n",
      "91 Done\n",
      "downloaded/training_dicom77.dcm\n",
      "Converting to PNG .........................\n",
      "5.31.789.1641.64628.430609.3706314.66231843829282066784003902524 >>>>>> None >>>>> 4.68.469.9972.36056.919029.6507439.21903211917666353042348620251\n",
      "92 Done\n",
      "downloaded/training_dicom59.dcm\n",
      "Converting to PNG .........................\n",
      "1.12.123.5253.36369.456598.8346057.41472431147021555014077097480 >>>>>> None >>>>> 4.60.982.4272.16926.170069.1563713.74481738450679922497007165081\n",
      "93 Done\n",
      "downloaded/training_dicom95.dcm\n",
      "Converting to PNG .........................\n",
      "1.10.827.1808.93065.673159.5682913.40370999244622660628125180529 >>>>>> None >>>>> 6.18.233.7038.40737.107573.5963498.70765980555448890157957005644\n",
      "94 Done\n",
      "downloaded/training_dicom33.dcm\n",
      "Converting to PNG .........................\n",
      "1.11.244.5813.25017.154237.8972197.10385977410736142018192648289 >>>>>> None >>>>> 8.31.205.9851.34447.543615.6510257.24956916969234918159048976071\n",
      "95 Done\n",
      "downloaded/training_dicom51.dcm\n",
      "Converting to PNG .........................\n",
      "7.26.963.8164.47276.400448.7475274.95281891480256453567982945708 >>>>>> None >>>>> 3.11.352.7146.18416.154345.2826945.73481015819987877819506894315\n",
      "96 Done\n",
      "downloaded/training_dicom15.dcm\n",
      "Converting to PNG .........................\n",
      "2.28.395.9177.16663.530731.1560364.73632503968610976745594051876 >>>>>> None >>>>> 4.48.312.5847.67211.378696.6193045.59155958045226193523753599374\n",
      "97 Done\n",
      "downloaded/training_dicom42.dcm\n",
      "Converting to PNG .........................\n",
      "9.73.110.2672.26212.193909.6810131.20673191872885425210920143484 >>>>>> None >>>>> 7.73.730.4555.71902.583221.1169213.82476067342322495959076398706\n",
      "98 Done\n",
      "downloaded/training_dicom105.dcm\n",
      "Converting to PNG .........................\n",
      "'FileDataset' object has no attribute 'SOPInstanceUID' >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "'str' object has no attribute 'astype'\n",
      "downloaded/training_dicom6.dcm\n",
      "Converting to PNG .........................\n",
      "3.77.462.7705.63194.974911.7766471.68085427517446792980950163519 >>>>>> None >>>>> 3.38.156.9697.93995.870567.8100718.89961970534134074904953855418\n",
      "99 Done\n",
      "downloaded/training_dicom60.dcm\n",
      "Converting to PNG .........................\n",
      "1.11.187.9973.86364.596634.2778477.17312574051626058476675189721 >>>>>> None >>>>> 1.10.400.6617.45356.835464.4258431.30008885544656323401092189429\n",
      "100 Done\n",
      "downloaded/training_dicom24.dcm\n",
      "Converting to PNG .........................\n",
      "2.18.908.4101.79483.659750.4956374.53941584896628451892623974403 >>>>>> None >>>>> 7.79.564.2163.68285.405974.8583554.62581389892809484921373451498\n",
      "101 Done\n"
     ]
    }
   ],
   "source": [
    "files_ = Path(\"downloaded\").rglob('*.dcm')\n",
    "print(files_)\n",
    "c = 0\n",
    "for i in files_:\n",
    "    try:\n",
    "        print(i)\n",
    "        img = read_xray(i)\n",
    "        with open(\"filename.pkl\", 'wb') as f:\n",
    "            pickle.dump(img, f)\n",
    "        ims = pickle.load(open(\"filename.pkl\", \"rb\"))\n",
    "        norm = (ims.astype(np.float) - ims.min()) * 255.0 / (ims.max() - ims.min())\n",
    "        Image.fromarray(norm.astype(np.uint8)).save(f\"training_data_png/{c}.png\")\n",
    "        c = c + 1\n",
    "        print(c, \"Done\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Getting the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "MNIST.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/MNIST/\"]\n",
    "\n",
    "MNIST(\n",
    "    \"data\",\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://28743102-e626-46b1-b5f1-d312c82e1bcb/sagemaker/DEMO-pytorch-mnist\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `mnist.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of gpus available in the current container.\n",
    "* `SM_CURRENT_HOST`: The name of the current container on the container network.\n",
    "* `SM_HOSTS`: JSON encoded list containing all the hosts .\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (``if __name__=='__main__':``) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshlex\u001b[39;49;00m, \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\u001b[37m# def install(package):\u001b[39;49;00m\n",
      "\u001b[37m#     os.system(\"pip install \" +  package)\u001b[39;49;00m\n",
      "    \n",
      "\u001b[37m# install('pillow')\u001b[39;49;00m\n",
      "\u001b[37m# install('requests')\u001b[39;49;00m\n",
      "\u001b[37m# install('pydicom')\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpydicom\u001b[39;49;00m\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
      "\n",
      "\n",
      "\u001b[37m# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m10\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2_drop = nn.Dropout2d()\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m320\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m50\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv1(x), \u001b[34m2\u001b[39;49;00m))\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv2_drop(\u001b[36mself\u001b[39;49;00m.conv2(x)), \u001b[34m2\u001b[39;49;00m))\n",
      "        x = x.view(-\u001b[34m1\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\n",
      "        x = F.dropout(x, training=\u001b[36mself\u001b[39;49;00m.training)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc2(x)\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir, is_distributed, **kwargs):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    dataset = datasets.MNIST(\n",
      "        \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshlex\u001b[39;49;00m, \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\u001b[37m# def install(package):\u001b[39;49;00m\n",
      "\u001b[37m#     os.system(\"pip install \" +  package)\u001b[39;49;00m\n",
      "    \n",
      "\u001b[37m# install('pillow')\u001b[39;49;00m\n",
      "\u001b[37m# install('requests')\u001b[39;49;00m\n",
      "\u001b[37m# install('pydicom')\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpydicom\u001b[39;49;00m\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
      "\n",
      "\n",
      "\u001b[37m# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m10\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2_drop = nn.Dropout2d()\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m320\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m50\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv1(x), \u001b[34m2\u001b[39;49;00m))\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv2_drop(\u001b[36mself\u001b[39;49;00m.conv2(x)), \u001b[34m2\u001b[39;49;00m))\n",
      "        x = x.view(-\u001b[34m1\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\n",
      "        x = F.dropout(x, training=\u001b[36mself\u001b[39;49;00m.training)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc2(x)\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir, is_distributed, **kwargs):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    dataset = datasets.MNIST(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_data_png\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        train=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        transform=transforms.Compose(\n",
      "            [transforms.ToTensor(), transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))]\n",
      "        ),\n",
      "    )\n",
      "    train_sampler = (\n",
      "        torch.utils.data.distributed.DistributedSampler(dataset) \u001b[34mif\u001b[39;49;00m is_distributed \u001b[34melse\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    )\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\n",
      "        dataset,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=train_sampler \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m,\n",
      "        sampler=train_sampler,\n",
      "        **kwargs\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_test_data_loader\u001b[39;49;00m(test_batch_size, training_dir, **kwargs):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet test data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\n",
      "        datasets.MNIST(\n",
      "            training_dir,\n",
      "            train=\u001b[34mFalse\u001b[39;49;00m,\n",
      "            transform=transforms.Compose(\n",
      "                [transforms.ToTensor(), transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))]\n",
      "            ),\n",
      "        ),\n",
      "        batch_size=test_batch_size,\n",
      "        shuffle=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        **kwargs\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_average_gradients\u001b[39;49;00m(model):\n",
      "    \u001b[37m# Gradient averaging.\u001b[39;49;00m\n",
      "    size = \u001b[36mfloat\u001b[39;49;00m(dist.get_world_size())\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM)\n",
      "        param.grad.data /= size\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\n",
      "    use_cuda = args.num_gpus > \u001b[34m0\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of gpus available - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.num_gpus))\n",
      "    kwargs = {\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_workers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpin_memory\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m} \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m {}\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\n",
      "        host_rank = args.hosts.index(args.current_host)\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mRANK\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(host_rank)\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\n",
      "        logger.info(\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "                args.backend, dist.get_world_size()\n",
      "            )\n",
      "            + \u001b[33m\"\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(dist.get_rank(), args.num_gpus)\n",
      "        )\n",
      "\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m use_cuda:\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir, is_distributed, **kwargs)\n",
      "    test_loader = _get_test_data_loader(args.test_batch_size, args.data_dir, **kwargs)\n",
      "\n",
      "    logger.debug(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(train_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    logger.debug(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of test data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.sampler),\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(test_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    model = Net().to(device)\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m use_cuda:\n",
      "        \u001b[37m# multi-machine multi-gpu case\u001b[39;49;00m\n",
      "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[37m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model)\n",
      "\n",
      "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad()\n",
      "            output = model(data)\n",
      "            loss = F.nll_loss(output, target)\n",
      "            loss.backward()\n",
      "            \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m use_cuda:\n",
      "                \u001b[37m# average gradients manually for multi-machine cpu case only\u001b[39;49;00m\n",
      "                _average_gradients(model)\n",
      "            optimizer.step()\n",
      "            \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m:\n",
      "                logger.info(\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)] Loss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "                        epoch,\n",
      "                        batch_idx * \u001b[36mlen\u001b[39;49;00m(data),\n",
      "                        \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\n",
      "                        \u001b[34m100.0\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader),\n",
      "                        loss.item(),\n",
      "                    )\n",
      "                )\n",
      "        test(model, test_loader, device)\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, test_loader, device):\n",
      "    model.eval()\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            output = model(data)\n",
      "            test_loss += F.nll_loss(output, target, size_average=\u001b[34mFalse\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\n",
      "            pred = output.max(\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
      "\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "    logger.info(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset), \u001b[34m100.0\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "        )\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = torch.nn.DataParallel(Net())\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\u001b[37m# def input_fn(request_body, request_content_type):\u001b[39;49;00m\n",
      "\u001b[37m#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;49;00m\n",
      "\u001b[37m#     assert request_content_type=='application/x-npy'\u001b[39;49;00m\n",
      "\u001b[37m#     # data = json.loads(request_body)['inputs']\u001b[39;49;00m\n",
      "\u001b[37m#     data = request_body\u001b[39;49;00m\n",
      "\u001b[37m#     data = torch.tensor(data, dtype=torch.float32, device=device)\u001b[39;49;00m\n",
      "\u001b[37m#     return data\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[37m# request_body = json.dumps({\"url\":\"http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\"})    \u001b[39;49;00m\n",
      "        input_data = json.loads(request_body)\n",
      "        url = input_data[\u001b[33m'\u001b[39;49;00m\u001b[33murl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mImage url: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00murl\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[37m# resp = requests.get(url, stream=True)\u001b[39;49;00m\n",
      "        \u001b[37m# raw_data = resp.raw\u001b[39;49;00m\n",
      "        image_data = Image.open(requests.get(url, stream=\u001b[34mTrue\u001b[39;49;00m).raw).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "        image_transform = transforms.Compose([\n",
      "            transforms.ToTensor(),\n",
      "            transforms.Resize((\u001b[34m28\u001b[39;49;00m,\u001b[34m28\u001b[39;49;00m)),\n",
      "        ])\n",
      "        \u001b[36mprint\u001b[39;49;00m(image_data)\n",
      "        data = image_transform(image_data)\n",
      "        \u001b[36mprint\u001b[39;49;00m(data.shape)\n",
      "        data = np.asarray(data)\n",
      "        \u001b[36mprint\u001b[39;49;00m(data.shape)\n",
      "        data = torch.tensor(data, dtype=torch.float32, device=device)\n",
      "        \u001b[36mprint\u001b[39;49;00m(data.shape)\n",
      "        \u001b[34mreturn\u001b[39;49;00m data\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcontent_type\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_object, model):\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        prediction = model(input_object)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(predictions, content_type):\n",
      "    \u001b[34massert\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    res = predictions.cpu().numpy().tolist()\n",
      "    output = response_converter(res)\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(res)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mresponse_converter\u001b[39;49;00m(res):\n",
      "    \u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    THIS IS A CUSTOM RESPONSE CCONVERTER\u001b[39;49;00m\n",
      "\u001b[33m    CARPL EXPECTS OUTPUT IN THIS FORMAT:\u001b[39;49;00m\n",
      "\u001b[33m    {\u001b[39;49;00m\n",
      "\u001b[33m        \"response\": {\u001b[39;49;00m\n",
      "\u001b[33m            \"findings\":[\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_A\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_A\u001b[39;49;00m\n",
      "\u001b[33m                },\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_B\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_B\u001b[39;49;00m\n",
      "\u001b[33m                }\u001b[39;49;00m\n",
      "\u001b[33m            ]\u001b[39;49;00m\n",
      "\u001b[33m        }\u001b[39;49;00m\n",
      "\u001b[33m    }\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[34massert\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(res, \u001b[36mlist\u001b[39;49;00m)\n",
      "        \u001b[34massert\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(res[\u001b[34m0\u001b[39;49;00m],\u001b[36mlist\u001b[39;49;00m)\n",
      "\n",
      "        result = []\n",
      "        score = \u001b[36mint\u001b[39;49;00m(np.argmin(res[\u001b[34m0\u001b[39;49;00m]))\n",
      "        \u001b[37m# for e,val in enumerate(res[0]):\u001b[39;49;00m\n",
      "        result.append(\n",
      "            {\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mclass\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mprobability\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:score\n",
      "            }\n",
      "        )\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33mresponse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m : {\u001b[33m\"\u001b[39;49;00m\u001b[33mfindings\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:result}}\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        \u001b[36mprint\u001b[39;49;00m(e) \n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m64\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m1000\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    )\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m100\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "        default=\u001b[34mNone\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    \n",
      "\n",
      "    train(parser.parse_args())\n",
      ",\n",
      "        train=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        transform=transforms.Compose(\n",
      "            [transforms.ToTensor(), transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))]\n",
      "        ),\n",
      "    )\n",
      "    train_sampler = (\n",
      "        torch.utils.data.distributed.DistributedSampler(dataset) \u001b[34mif\u001b[39;49;00m is_distributed \u001b[34melse\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    )\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\n",
      "        dataset,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=train_sampler \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m,\n",
      "        sampler=train_sampler,\n",
      "        **kwargs\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_test_data_loader\u001b[39;49;00m(test_batch_size, training_dir, **kwargs):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet test data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\n",
      "        datasets.MNIST(\n",
      "            training_dir,\n",
      "            train=\u001b[34mFalse\u001b[39;49;00m,\n",
      "            transform=transforms.Compose(\n",
      "                [transforms.ToTensor(), transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))]\n",
      "            ),\n",
      "        ),\n",
      "        batch_size=test_batch_size,\n",
      "        shuffle=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        **kwargs\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_average_gradients\u001b[39;49;00m(model):\n",
      "    \u001b[37m# Gradient averaging.\u001b[39;49;00m\n",
      "    size = \u001b[36mfloat\u001b[39;49;00m(dist.get_world_size())\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM)\n",
      "        param.grad.data /= size\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\n",
      "    use_cuda = args.num_gpus > \u001b[34m0\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of gpus available - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.num_gpus))\n",
      "    kwargs = {\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_workers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpin_memory\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m} \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m {}\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\n",
      "        host_rank = args.hosts.index(args.current_host)\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mRANK\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(host_rank)\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\n",
      "        logger.info(\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "                args.backend, dist.get_world_size()\n",
      "            )\n",
      "            + \u001b[33m\"\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(dist.get_rank(), args.num_gpus)\n",
      "        )\n",
      "\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m use_cuda:\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir, is_distributed, **kwargs)\n",
      "    test_loader = _get_test_data_loader(args.test_batch_size, args.data_dir, **kwargs)\n",
      "\n",
      "    logger.debug(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(train_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    logger.debug(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of test data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.sampler),\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(test_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    model = Net().to(device)\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m use_cuda:\n",
      "        \u001b[37m# multi-machine multi-gpu case\u001b[39;49;00m\n",
      "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[37m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model)\n",
      "\n",
      "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad()\n",
      "            output = model(data)\n",
      "            loss = F.nll_loss(output, target)\n",
      "            loss.backward()\n",
      "            \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m use_cuda:\n",
      "                \u001b[37m# average gradients manually for multi-machine cpu case only\u001b[39;49;00m\n",
      "                _average_gradients(model)\n",
      "            optimizer.step()\n",
      "            \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m:\n",
      "                logger.info(\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)] Loss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "                        epoch,\n",
      "                        batch_idx * \u001b[36mlen\u001b[39;49;00m(data),\n",
      "                        \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\n",
      "                        \u001b[34m100.0\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader),\n",
      "                        loss.item(),\n",
      "                    )\n",
      "                )\n",
      "        test(model, test_loader, device)\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, test_loader, device):\n",
      "    model.eval()\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            output = model(data)\n",
      "            test_loss += F.nll_loss(output, target, size_average=\u001b[34mFalse\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\n",
      "            pred = output.max(\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
      "\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "    logger.info(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset), \u001b[34m100.0\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "        )\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = torch.nn.DataParallel(Net())\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\u001b[37m# def input_fn(request_body, request_content_type):\u001b[39;49;00m\n",
      "\u001b[37m#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;49;00m\n",
      "\u001b[37m#     assert request_content_type=='application/x-npy'\u001b[39;49;00m\n",
      "\u001b[37m#     # data = json.loads(request_body)['inputs']\u001b[39;49;00m\n",
      "\u001b[37m#     data = request_body\u001b[39;49;00m\n",
      "\u001b[37m#     data = torch.tensor(data, dtype=torch.float32, device=device)\u001b[39;49;00m\n",
      "\u001b[37m#     return data\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[37m# request_body = json.dumps({\"url\":\"http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\"})    \u001b[39;49;00m\n",
      "        input_data = json.loads(request_body)\n",
      "        url = input_data[\u001b[33m'\u001b[39;49;00m\u001b[33murl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mImage url: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00murl\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[37m# resp = requests.get(url, stream=True)\u001b[39;49;00m\n",
      "        \u001b[37m# raw_data = resp.raw\u001b[39;49;00m\n",
      "        image_data = Image.open(requests.get(url, stream=\u001b[34mTrue\u001b[39;49;00m).raw).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "        image_transform = transforms.Compose([\n",
      "            transforms.ToTensor(),\n",
      "            transforms.Resize((\u001b[34m28\u001b[39;49;00m,\u001b[34m28\u001b[39;49;00m)),\n",
      "        ])\n",
      "        \u001b[36mprint\u001b[39;49;00m(image_data)\n",
      "        data = image_transform(image_data)\n",
      "        \u001b[36mprint\u001b[39;49;00m(data.shape)\n",
      "        data = np.asarray(data)\n",
      "        \u001b[36mprint\u001b[39;49;00m(data.shape)\n",
      "        data = torch.tensor(data, dtype=torch.float32, device=device)\n",
      "        \u001b[36mprint\u001b[39;49;00m(data.shape)\n",
      "        \u001b[34mreturn\u001b[39;49;00m data\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcontent_type\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_object, model):\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        prediction = model(input_object)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(predictions, content_type):\n",
      "    \u001b[34massert\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    res = predictions.cpu().numpy().tolist()\n",
      "    output = response_converter(res)\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(res)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mresponse_converter\u001b[39;49;00m(res):\n",
      "    \u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    THIS IS A CUSTOM RESPONSE CCONVERTER\u001b[39;49;00m\n",
      "\u001b[33m    CARPL EXPECTS OUTPUT IN THIS FORMAT:\u001b[39;49;00m\n",
      "\u001b[33m    {\u001b[39;49;00m\n",
      "\u001b[33m        \"response\": {\u001b[39;49;00m\n",
      "\u001b[33m            \"findings\":[\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_A\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_A\u001b[39;49;00m\n",
      "\u001b[33m                },\u001b[39;49;00m\n",
      "\u001b[33m                {\u001b[39;49;00m\n",
      "\u001b[33m                    \"name\":\"class_B\",\u001b[39;49;00m\n",
      "\u001b[33m                    \"probability\":score_B\u001b[39;49;00m\n",
      "\u001b[33m                }\u001b[39;49;00m\n",
      "\u001b[33m            ]\u001b[39;49;00m\n",
      "\u001b[33m        }\u001b[39;49;00m\n",
      "\u001b[33m    }\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[34massert\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(res, \u001b[36mlist\u001b[39;49;00m)\n",
      "        \u001b[34massert\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(res[\u001b[34m0\u001b[39;49;00m],\u001b[36mlist\u001b[39;49;00m)\n",
      "\n",
      "        result = []\n",
      "        score = \u001b[36mint\u001b[39;49;00m(np.argmin(res[\u001b[34m0\u001b[39;49;00m]))\n",
      "        \u001b[37m# for e,val in enumerate(res[0]):\u001b[39;49;00m\n",
      "        result.append(\n",
      "            {\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[33m\"\u001b[39;49;00m\u001b[33mclass\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mprobability\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:score\n",
      "            }\n",
      "        )\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33mresponse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m : {\u001b[33m\"\u001b[39;49;00m\u001b[33mfindings\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:result}}\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        \u001b[36mprint\u001b[39;49;00m(e) \n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m64\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m1000\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    )\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m100\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "        default=\u001b[34mNone\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    \n",
      "\n",
      "    train(parser.parse_args())\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters. In this case we are going to run our training job on 2 ```ml.c4.xlarge``` instances. But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)). The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the `mnist.py` script above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker==2.110.0 in /opt/conda/lib/python3.7/site-packages (2.110.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (3.20.3)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.26.24)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (21.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.3.5)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.7.5)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (4.13.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.3.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (0.1.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.110.0) (20.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker==2.110.0) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker==2.110.0) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.24 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker==2.110.0) (1.29.24)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.110.0) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.110.0) (4.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.110.0) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.110.0) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.110.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.110.0) (2.8.2)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (0.3.2)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (1.7.6.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.110.0) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker==2.110.0) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.24->boto3<2.0,>=1.20.21->sagemaker==2.110.0) (1.26.13)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker==2.110.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.110.0\n"
     ]
    }
   ],
   "source": [
    "!pip show sagemaker | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"mnist.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.11.0\",\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},\n",
    "    dependencies=['code/requirements.txt'],\n",
    "    source_dir = \"code\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 09:06:13 Starting - Starting the training job...\n",
      "2022-12-15 09:06:36 Starting - Preparing the instances for trainingProfilerReport-1671095172: InProgress\n",
      ".........\n",
      "2022-12-15 09:08:09 Downloading - Downloading input data...\n",
      "2022-12-15 09:08:36 Training - Training image download completed. Training in progress.\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:30,097 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:30,099 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:30,106 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:30,107 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:30,257 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[35mCollecting pydicom\u001b[0m\n",
      "\u001b[35mDownloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\u001b[0m\n",
      "\u001b[35m 2.0/2.0 MB 26.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.22.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2022.9.24)\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pydicom\u001b[0m\n",
      "\u001b[35mSuccessfully installed pydicom-2.3.1\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:32,159 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:32,159 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:32,161 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:32,171 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:32,181 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:32,188 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-12-15-09-06-12-729\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-09-06-12-729/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_TYPE=ml.c5.2xlarge\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}}\u001b[0m\n",
      "\u001b[35mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[35mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-09-06-12-729/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.c5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-12-15-09-06-12-729\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-09-06-12-729/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20221003-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 mnist.py --backend gloo --epochs 1\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[35mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 1. Number of gpus: 0\u001b[0m\n",
      "\u001b[35mGet train data loader\u001b[0m\n",
      "\u001b[35mGet test data loader\u001b[0m\n",
      "\u001b[35mProcesses 30000/60000 (50%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:30,108 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:30,109 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:30,116 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:30,118 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:30,279 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (9.2.0)\u001b[0m\n",
      "\u001b[34mCollecting pydicom\u001b[0m\n",
      "\u001b[34mDownloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34m 2.0/2.0 MB 31.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 1)) (2022.9.24)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pydicom\u001b[0m\n",
      "\u001b[34mSuccessfully installed pydicom-2.3.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:32,286 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:32,286 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:32,289 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:32,298 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:32,308 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:32,314 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-12-15-09-06-12-729\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-09-06-12-729/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-09-06-12-729/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.c5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-12-15-09-06-12-729\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-09-06-12-729/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20221003-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 mnist.py --backend gloo --epochs 1\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 2 nodes. Current host rank is 0. Number of gpus: 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 30000/60000 (50%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2022-12-15 09:08:34.430 algo-1:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-12-15 09:08:34.422 algo-2:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-12-15 09:08:34.683 algo-2:45 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2022-12-15 09:08:34.684 algo-2:45 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-12-15 09:08:34.685 algo-2:45 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2022-12-15 09:08:34.685 algo-2:45 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2022-12-15 09:08:34.685 algo-2:45 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2022-12-15 09:08:34.697 algo-1:45 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-12-15 09:08:34.699 algo-1:45 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-12-15 09:08:34.699 algo-1:45 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-12-15 09:08:34.700 algo-1:45 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-12-15 09:08:34.700 algo-1:45 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/30000 (21%)] Loss: 2.076445\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [6400/30000 (21%)] Loss: 2.076445\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [6400/30000 (21%)] Loss: 2.075126\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [6400/30000 (21%)] Loss: 2.075126\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [12800/30000 (43%)] Loss: 1.213364\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [12800/30000 (43%)] Loss: 1.213364\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/30000 (43%)] Loss: 1.056658\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/30000 (43%)] Loss: 1.056658\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [19200/30000 (64%)] Loss: 0.908578\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [19200/30000 (64%)] Loss: 0.908578\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [25600/30000 (85%)] Loss: 0.671730\u001b[0m\n",
      "\u001b[35mINFO:__main__:Train Epoch: 1 [25600/30000 (85%)] Loss: 0.671730\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/30000 (64%)] Loss: 0.944071\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [19200/30000 (64%)] Loss: 0.944071\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/30000 (85%)] Loss: 0.846429\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [25600/30000 (85%)] Loss: 0.846429\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[35mTest set: Average loss: 0.3238, Accuracy: 9094/10000 (91%)\u001b[0m\n",
      "\u001b[35mSaving the model.\u001b[0m\n",
      "\u001b[35mINFO:__main__:Test set: Average loss: 0.3238, Accuracy: 9094/10000 (91%)\u001b[0m\n",
      "\u001b[35mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:44,354 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:44,354 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-12-15 09:08:44,354 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3238, Accuracy: 9094/10000 (91%)\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3238, Accuracy: 9094/10000 (91%)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:44,375 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:44,375 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-12-15 09:08:44,375 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-12-15 09:09:00 Uploading - Uploading generated training model\n",
      "2022-12-15 09:09:00 Completed - Training job completed\n",
      "Training seconds: 104\n",
      "Billable seconds: 104\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "### Create endpoint\n",
    "After training, we use the `PyTorch` estimator object to build and deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `mnist.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `mnist.py`. Here we will deploy the model to a single ```ml.m4.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'framework_version': '1.11.0',\n",
       " 'py_version': 'py38',\n",
       " 'role': 'arn:aws:iam::883411003189:role/service-role/AmazonSageMaker-ExecutionRole-20220706T141355',\n",
       " 'instance_count': 2,\n",
       " 'instance_type': 'ml.c5.2xlarge',\n",
       " 'keep_alive_period_in_seconds': None,\n",
       " 'instance_groups': None,\n",
       " 'volume_size': 30,\n",
       " 'volume_kms_key': None,\n",
       " 'max_run': 86400,\n",
       " 'input_mode': 'File',\n",
       " 'metric_definitions': None,\n",
       " 'model_uri': None,\n",
       " 'model_channel_name': 'model',\n",
       " 'code_uri': None,\n",
       " 'code_channel_name': 'code',\n",
       " 'source_dir': 'code',\n",
       " 'git_config': None,\n",
       " 'container_log_level': 20,\n",
       " '_hyperparameters': {'epochs': 1,\n",
       "  'backend': 'gloo',\n",
       "  'sagemaker_submit_directory': 's3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-04-55-05-509/source/sourcedir.tar.gz',\n",
       "  'sagemaker_program': 'mnist.py',\n",
       "  'sagemaker_container_log_level': 20,\n",
       "  'sagemaker_job_name': 'pytorch-training-2022-12-15-04-55-05-509',\n",
       "  'sagemaker_region': 'ap-southeast-1'},\n",
       " 'code_location': None,\n",
       " 'entry_point': 'mnist.py',\n",
       " 'dependencies': ['code/requirements.txt'],\n",
       " 'uploaded_code': UserCode(s3_prefix='s3://sagemaker-ap-southeast-1-883411003189/pytorch-training-2022-12-15-04-55-05-509/source/sourcedir.tar.gz', script_name='mnist.py'),\n",
       " 'tags': None,\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7ff8a2094e10>,\n",
       " 'base_job_name': 'pytorch-training',\n",
       " '_current_job_name': 'pytorch-training-2022-12-15-04-55-05-509',\n",
       " 'output_path': 's3://sagemaker-ap-southeast-1-883411003189/',\n",
       " 'output_kms_key': None,\n",
       " 'latest_training_job': <sagemaker.estimator._TrainingJob at 0x7ff885f55190>,\n",
       " 'jobs': [<sagemaker.estimator._TrainingJob at 0x7ff885f55190>],\n",
       " 'deploy_instance_type': None,\n",
       " '_compiled_models': {},\n",
       " 'subnets': None,\n",
       " 'security_group_ids': None,\n",
       " 'encrypt_inter_container_traffic': False,\n",
       " 'use_spot_instances': False,\n",
       " 'max_wait': None,\n",
       " 'checkpoint_s3_uri': None,\n",
       " 'checkpoint_local_path': None,\n",
       " 'rules': None,\n",
       " 'debugger_hook_config': <sagemaker.debugger.debugger.DebuggerHookConfig at 0x7ff80c0a7d10>,\n",
       " 'tensorboard_output_config': None,\n",
       " 'debugger_rule_configs': [],\n",
       " 'collection_configs': set(),\n",
       " 'enable_sagemaker_metrics': True,\n",
       " '_enable_network_isolation': False,\n",
       " 'profiler_config': <sagemaker.debugger.profiler_config.ProfilerConfig at 0x7ff80c04e450>,\n",
       " 'disable_profiler': False,\n",
       " 'environment': None,\n",
       " 'max_retry_attempts': None,\n",
       " 'profiler_rule_configs': [{'RuleConfigurationName': 'ProfilerReport-1671080105',\n",
       "   'RuleEvaluatorImage': '972752614525.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "   'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       " 'profiler_rules': [ProfilerRule(name='ProfilerReport-1671080105', image_uri='972752614525.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-debugger-rules:latest', instance_type=None, container_local_output_path=None, s3_output_path=None, volume_size_in_gb=None, rule_parameters={'rule_to_invoke': 'ProfilerReport'})],\n",
       " 'debugger_rules': [],\n",
       " 'image_uri': None,\n",
       " 'distribution': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.2xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "You can use the test images to evalute the endpoint. The accuracy of the model depends on how many it is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls data/MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "data_dir = \"data/MNIST/raw\"\n",
    "with gzip.open(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "mask = random.sample(range(len(images)), 16)  # randomly select some of the test images\n",
    "mask = np.array(mask, dtype=np.int)\n",
    "data = images[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2529, 8464, 9926, 3929, 6169,  392, 4305, 2118, 4274, 2184, 5513,\n",
       "       3174, 6799, 8376, 3933, 3165])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic = np.random.rand(1,28,28).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(data[0], cmap='gray', interpolation='none')\n",
    "  # plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"Requested unsupported ContentType in content_type application/x-npy\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 142, in transform\n    result = self._run_handler_function(\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 276, in _run_handler_function\n    result = func(*argv_context)\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 259, in _default_transform_fn\n    data = self._run_handler_function(self._input_fn, *(input_data, content_type))\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 272, in _run_handler_function\n    result = func(*argv)\n  File \"/opt/ml/model/code/mnist.py\", line 241, in input_fn\n    raise Exception(f'Requested unsupported ContentType in content_type {content_type}')\nException: Requested unsupported ContentType in content_type application/x-npy\n\". See https://ap-south-1.console.aws.amazon.com/cloudwatch/home?region=ap-south-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2022-10-11-07-17-55-618 in account 023180687239 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d7e8431a499a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raw prediction result:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 )\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"Requested unsupported ContentType in content_type application/x-npy\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 142, in transform\n    result = self._run_handler_function(\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 276, in _run_handler_function\n    result = func(*argv_context)\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 259, in _default_transform_fn\n    data = self._run_handler_function(self._input_fn, *(input_data, content_type))\n  File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 272, in _run_handler_function\n    result = func(*argv)\n  File \"/opt/ml/model/code/mnist.py\", line 241, in input_fn\n    raise Exception(f'Requested unsupported ContentType in content_type {content_type}')\nException: Requested unsupported ContentType in content_type application/x-npy\n\". See https://ap-south-1.console.aws.amazon.com/cloudwatch/home?region=ap-south-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2022-10-11-07-17-55-618 in account 023180687239 for more information."
     ]
    }
   ],
   "source": [
    "response = predictor.predict(np.expand_dims(data, axis=1))\n",
    "print(\"Raw prediction result:\")\n",
    "print(response)\n",
    "print()\n",
    "\n",
    "labeled_predictions = list(zip(range(10), response[0]))\n",
    "print(\"Labeled predictions: \")\n",
    "print(labeled_predictions)\n",
    "print()\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print(\"Most likely answer: {}\".format(labeled_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.content_type = 'application/x-npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name=predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.predict(pic.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-training-2022-10-11-08-07-06-661'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '0957ab6d-569b-477a-aef0-7481a935eecb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '0957ab6d-569b-477a-aef0-7481a935eecb', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Tue, 11 Oct 2022 08:23:34 GMT', 'content-type': 'application/json', 'content-length': '207'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7efc7f467550>}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "custom_attributes = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.\n",
    "endpoint_name = predictor.endpoint_name                                        # Your endpoint name.\n",
    "content_type = \"application/json\"                                        # The MIME type of the input data in the request body.\n",
    "accept = \"application/json\"                                              # The desired MIME type of the inference in the response.\n",
    "payload = json.dumps({\"url\":\"http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\"})                                           # Payload for inference.\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    CustomAttributes=custom_attributes, \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=payload\n",
    "    )\n",
    "\n",
    "print(response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Body': <botocore.response.StreamingBody object at 0x7efc7f467550>,\n",
      " 'ContentType': 'application/json',\n",
      " 'InvokedProductionVariant': 'AllTraffic',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '207',\n",
      "                                      'content-type': 'application/json',\n",
      "                                      'date': 'Tue, 11 Oct 2022 08:23:34 GMT',\n",
      "                                      'x-amzn-invoked-production-variant': 'AllTraffic',\n",
      "                                      'x-amzn-requestid': '0957ab6d-569b-477a-aef0-7481a935eecb'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '0957ab6d-569b-477a-aef0-7481a935eecb',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.load(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-3.0102062225341797,\n",
       "  -2.48018217086792,\n",
       "  -1.5776013135910034,\n",
       "  -2.6531476974487305,\n",
       "  -3.039762020111084,\n",
       "  -1.8981196880340576,\n",
       "  -2.262784481048584,\n",
       "  -4.358467102050781,\n",
       "  -1.3877885341644287,\n",
       "  -3.6531260013580322]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.0102062225341797,\n",
       " -2.48018217086792,\n",
       " -1.5776013135910034,\n",
       " -2.6531476974487305,\n",
       " -3.039762020111084,\n",
       " -1.8981196880340576,\n",
       " -2.262784481048584,\n",
       " -4.358467102050781,\n",
       " -1.3877885341644287,\n",
       " -3.6531260013580322]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.FloatTensor(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic.astype(\"float32\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.tensor(pic, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image.open(req.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(request_body, content_type='application/json'):\n",
    "    logger.info('Deserializing the input data.')\n",
    "    import requests\n",
    "    import numpy as np\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        url = input_data['url']\n",
    "        logger.info(f'Image url: {url}')\n",
    "        # resp = requests.get(url, stream=True)\n",
    "        # raw_data = resp.raw\n",
    "        image_data = Image.open(requests.get(url, stream=True).raw)\n",
    "        \n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(size=28),\n",
    "        ])\n",
    "        # logger.debug(\"image_data - {}\",image_data)\n",
    "        # data = image_transform(image_data)\n",
    "        # # logger.debug(\"data - {}\",data)\n",
    "        # data = np.asarray(data)\n",
    "        # # logger.debug(\"data - {}\",data)\n",
    "        # data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "        # logger.debug(\"data - {}\",data)\n",
    "        return image_transform(image_data)\n",
    "    raise Exception(f'Requested unsupported ContentType in content_type {content_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging,sys\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image url: http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\n",
      "<PIL.Image.Image image mode=L size=353x370 at 0x7EFC7F3B8990>\n",
      "torch.Size([1, 28, 28])\n",
      "(1, 28, 28)\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "request_body = json.dumps({\"url\":\"http://rasbt.github.io/mlxtend/user_guide/data/mnist_data_files/mnist_data_10_0.png\"})    \n",
    "input_data = json.loads(request_body)\n",
    "url = input_data['url']\n",
    "logger.info(f'Image url: {url}')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# resp = requests.get(url, stream=True)\n",
    "# raw_data = resp.raw\n",
    "image_data = Image.open(requests.get(url, stream=True).raw).convert('L')\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28,28)),\n",
    "])\n",
    "print(image_data)\n",
    "data = image_transform(image_data)\n",
    "print(data.shape)\n",
    "data = np.asarray(data)\n",
    "print(data.shape)\n",
    "data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=353x370>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "vscode": {
   "interpreter": {
    "hash": "2ed236227034f4f34b7af70d7e301e7e416b9eea7e7665e4e660cbbba097d900"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
